{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantative analyses of zBrains outputs.\n",
    "Requires zBrains 'proc' and 'analysis' outputs.\n",
    "\n",
    "Parts:\n",
    "1. Packages\n",
    "2. Functions\n",
    "- load_gifti\n",
    "- v_extremelue : get vertices with values greater than a threshold\n",
    "- adjVertices : identify all sets of adjacent vertices with values greater than a threshold\n",
    "- main : take subject, return statistics regarding zBrains outputs\n",
    "3. Run\n",
    "\n",
    "Daniel Mendelson. 21 Jan 2025 \\\n",
    "Working under supervision of Dr. Boris Bernhardt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import nibabel as nib\n",
    "import plotly as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gifti(path_gii, extract = \"vertices\"):\n",
    "    \"\"\"\n",
    "    Load data from GIFTI (.gii) file.\n",
    "    \n",
    "    Parameters:\n",
    "        path_gii : str\n",
    "            Path to the `.gii` file. Intended for `surf.gii` and `func.gii` files.\n",
    "                \n",
    "                .surf.gii : Array with two elements\n",
    "                    Vertex indexed array. Retrieved with `NIFTI_INTENT_POINTSET` option. Structure:\n",
    "                        nVertices x 3 [x, y, z] \n",
    "                        coordinates are in unit `milimeter` (mm)\n",
    "\n",
    "                    Face indexed array. Retrieved with `NIFTI_INTENT_TRIANGLE` option. Structure:\n",
    "                        nFaces x 3 [vertexIndex1, vertexIndex2, vertexIndex3]\n",
    "                            Notes: \n",
    "                                `vertexIndex` corresponds to the index in the above `vertex indexed array`.\n",
    "                                vertices that make each face are adjacent.\n",
    "                \n",
    "                .func.gii : Array with a single element. Structure:\n",
    "                    nVertices x [value]\n",
    "    \n",
    "    Returns:\n",
    "        gii : np.array\n",
    "            gii from the file.\n",
    "\n",
    "    Requires: \n",
    "        nibabel as nib    \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    gii = nib.load(path_gii)\n",
    "\n",
    "    if path_gii.endswith(\".func.gii\"):\n",
    "           return gii.darrays[0].data\n",
    "\n",
    "    elif path_gii.endswith(\".surf.gii\"):\n",
    "        \n",
    "        if extract == \"vertices\":\n",
    "            print (\"[load_gifti] Extracting vertex coordinates from %s\" % path_gii)\n",
    "            return gii.get_arrays_from_intent('NIFTI_INTENT_POINTSET')[0].data # vertex format\n",
    "            \n",
    "        elif extract == \"faces\":\n",
    "            print (\"[load_gifti] Extracting faces from %s\" % path_gii)\n",
    "            return gii.get_arrays_from_intent('NIFTI_INTENT_TRIANGLE')[0].data # face format\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"[load_gifti] `Extract` must be either 'vertices' or 'faces'\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"[load_gifti] File type not supported. Supported types are `.surf.gii` and `.func.gii`\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_extremeValue(path_gii, threshold, output = \"indices\"):\n",
    "    \"\"\"\n",
    "    Returns the number of vertices with values more extreme than a threshold.\n",
    "\n",
    "    Parameters:\n",
    "        path_gii : str\n",
    "            Path to the `.func.gii` file.\n",
    "        threshold : float\n",
    "            Threshold for extreme values.\n",
    "\n",
    "    Returns:\n",
    "        int : Number of vertices with values more extreme than the threshold.\n",
    "    \n",
    "    Future:\n",
    "        Can specify if want one sided or two sided threshold. Default, assumes two sided.\n",
    "\n",
    "    Requires:\n",
    "        numpy as np\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        threshold = float(threshold)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Threshold must be a positive float or integer.\")\n",
    "\n",
    "    values = load_gifti(path_gii)\n",
    "\n",
    "    if output == \"values\": # for .func.gii\n",
    "        out = values[np.abs(values) > np.abs(threshold)]\n",
    "        print(\"[v_extremeValue] Returning values only, no indices.\")\n",
    "\n",
    "    elif output == \"indices\":\n",
    "        out = [index for index in range(len(values)) if np.abs(values[index]) > np.abs(threshold)]\n",
    "        print(\"[v_extremeValue] Returning indices only, no values.\")\n",
    "\n",
    "    elif output == \"both\":\n",
    "        out = (values[np.abs(values) > np.abs(threshold)], [index for index in range(len(values)) if np.abs(values[index]) > np.abs(threshold)])\n",
    "        print(\"[v_extremeValue] Returning both values and indices.\")\n",
    "    else:\n",
    "        raise ValueError(\"[v_extremeValue] Output parameter illdefined. It is currently %s Must be either `values`, `indices` or `both`.\" % output)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjVertices(path_surf_gii, listVertices, test = False):\n",
    "    \"\"\"\n",
    "    Identifies sets of adjacent vertices in a list of vertices of interest.\n",
    "\n",
    "    Parameters:\n",
    "        path_surf_gii : str\n",
    "            Path to `.surf.gii` file with surface face information\n",
    "        vertOfInterest : list\n",
    "            List of vertices of interest.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        listAdjSets : list\n",
    "            List of list of adjacent vertices. Each nested \n",
    "    \"\"\"\n",
    "\n",
    "    def run(faces, v, listVertices, set = [], listAdjSets = []):\n",
    "        \n",
    "        # print(\"VERTEX: %s\" %(v))\n",
    "        overlap = [s for s in listAdjSets if v in s] # if `v` is in any set of listAdjSets, saves overlapping set(s)\n",
    "            \n",
    "        if len(overlap) > 1:\n",
    "            raise ValueError(\"[adjVertices] Vertex %s is in more than one set. This should not happen. Examine code.\" %v)\n",
    "        \n",
    "        if overlap: # if `v` is in a set, remove that set from listAdjSets \n",
    "            # print(f\"\\tVertex %s is in set %s\" %(v, overlap))\n",
    "            set = overlap[0] # define set as the set that `v` is in\n",
    "            listAdjSets.remove(overlap[0]) # remove that set from listAdjSets\n",
    "\n",
    "        else: # add `v` to a new set and continue\n",
    "            set = [v] # define new set with v\n",
    "\n",
    "        #print(\"Set: %s\" %set)\n",
    "        \n",
    "        # find adjacent vertices to `v`\n",
    "        adjV = np.unique(faces[np.any(faces == v, axis=1)]) # 1D array\n",
    "\n",
    "        for i in adjV: # Identify adjacent vertices that are also of interest \n",
    "            if i in listVertices:\n",
    "                #print(f\"\\t %s\" %i)\n",
    "                if i in set: # if in the current set, skip\n",
    "                    #print(f\"\\t%s\\tIn current set %s. Skipping.\" %(i, set))\n",
    "                    continue\n",
    "\n",
    "                elif any(i in s for s in listAdjSets): # if in another set, combine current set with that set\n",
    "                    overlap = [s for s in listAdjSets if i in s]\n",
    "                    \n",
    "                    if len(overlap) > 1:\n",
    "                        raise ValueError(\"[adjVertices] Vertex %s is in more than one set. This should not happen. Examine code.\" %i)\n",
    "                    \n",
    "                    #print(f\"\\t%s\\tIn another set. Combining current set %s with %s.\" %(i, set, set + i))\n",
    "\n",
    "                    old = overlap[0]\n",
    "                    set = set + old\n",
    "                    #print(type(set))\n",
    "                    listAdjSets.remove(old)\n",
    "\n",
    "                    continue\n",
    "            \n",
    "                else: # not in any set, add to the current set\n",
    "                    #print(f\"\\t%s\\tNew. Appending to current set %s.\" %(i, set))\n",
    "                    set.append(i)\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        listAdjSets.append(set)\n",
    "        #print(\"List of sets: %s\" %listAdjSets)\n",
    "\n",
    "        return listAdjSets\n",
    "\n",
    "\n",
    "    faces = load_gifti(path_surf_gii, extract = \"faces\")\n",
    "    \n",
    "    set = [] # list of a single set of adjacent vertices\n",
    "    listAdjSets = [] # list of sets of adjacent vertices\n",
    "\n",
    "    if test == True:\n",
    "            print(\"[adjVertices] Testing for first 10 vertices of interest only.\")\n",
    "            \n",
    "            for v in listVertices[:40]:\n",
    "                listAdjSets = run(faces, v, listVertices, set, listAdjSets)\n",
    "                \n",
    "    else:\n",
    "        for v in listVertices:\n",
    "            listAdjSets = run(faces, v, listVertices, set, listAdjSets)\n",
    "\n",
    "    print(\"[adjVertices] COMPLETE. Num sets: %s, Max length: %s, Longest set: %s, List of sets: %s\" %(len(listAdjSets), max(map(len, listAdjSets)), max(listAdjSets, key=len), listAdjSets))\n",
    "    # order listAdjSets by length of sets\n",
    "    listAdjSets.sort(key = len, reverse = True)\n",
    "    return listAdjSets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(name, path_func_gii, path_surf_gii, threshold = 1.96, save_sets = True, save_path = None, test = False):\n",
    "    \"\"\"\n",
    "    Steps: \n",
    "        1. Get vertices where z above threshold (get_extremeZ)\n",
    "        2. Get list of adjacent vertices to those vertices (count_adjVertices, requires 'vertices of interest')\n",
    "        3. Return data of interest from these results (e.g., number of vertices, number of sets, maximum length of set, etc.)\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "\n",
    "    Requires:\n",
    "        datetime as dt\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"[main] Extracting zBrains analysis data.\\n\\tThreshold: {threshold}\\n\\tfunc.gii: {path_func_gii}\\n\\tsurf.gii: {path_surf_gii}\")\n",
    "    # 1. Get vertices with value > threshold\n",
    "    v_extreme = v_extremeValue(path_gii = path_func_gii, threshold = threshold, output = \"indices\") # Returns list of vertices\n",
    "\n",
    "    # 2. Get list of adjacent vertices to those vertices\n",
    "    adjSets = adjVertices(path_surf_gii, v_extreme, test = test) # Returns list of lists of adjacent vertices\n",
    "\n",
    "    # 3. Return data of interest\n",
    "    ## Extract data of interest\n",
    "    num_vertices = len(v_extreme)\n",
    "    num_sets = len(adjSets)\n",
    "    max_set_length = max(map(len, adjSets))\n",
    "\n",
    "    ## Save data\n",
    "    \n",
    "    if save_sets == True:\n",
    "        date = dt.datetime.now().strftime(\"%d%b%Y\")\n",
    "        out_name = save_path + \"/\" + name + \"_SetsOfAdjVofInterest_\" + date + \".txt\"\n",
    "        print(\"[main] Saving sets for %s to %s\" %(name, out_name))\n",
    "        with open(out_name, \"w\") as f:\n",
    "            for s in adjSets:\n",
    "                f.write(\"%s\\n\" %s)\n",
    "\n",
    "    ## Return data\n",
    "    out = [num_vertices, num_sets, max_set_length]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of subject IDs and corresponding sessions of interest\n",
    "sheet_path = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/Epilepsy_7T/zBrainsAnalyses/data/pt_13Jan2025_ages.xlsx\"\n",
    "pt_sheet = pd.read_excel(sheet_path, sheet_name = \"Sheet1\")\n",
    "\n",
    "ID_colName = '7T_ID'\n",
    "session_colName = 'sT_ses_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = \"/data/mica3/BIDS_PNI/derivatives/zbrains_7T_3T_HC_8Jan2025\"\n",
    "set_save_path = \"/Users/danielmendelson/Documents/Boris_projects/code/output\"\n",
    "\n",
    "threshold = 1.96\n",
    "\n",
    "# Declare output dataframe\n",
    "out_df_save_path = \"/host/verges/data/tank/daniel/zBrainsAnalyses/output\"\n",
    "out_df = pd.DataFrame(columns = [\n",
    "    \"scanner\", \"ID\", \"session\", \n",
    "    \"hemisphere\", \"region\", \"feature\", \n",
    "    \"surface\", \"smoothing\", \"analysis\", \n",
    "    \"num_vertices\", \"num_sets\", \"max_set_length\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/mica3/BIDS_PNI/derivatives/zbrains_7T_3T_HC_8Jan2025/sub-PNE003/ses-a1/norm-z/cortex/sub-PNE003_ses-a1_hemi-L_surf-fsLR-32k_label-midthickness_feature-T1map_smooth-10mm_analysis-regional.func.gii\n",
      "/data/mica3/BIDS_PNI/derivatives/zbrains_7T_3T_HC_8Jan2025/sub-PNE003/ses-a1/structural/sub-PNE003_ses-a1_hemi-L_space-nativepro_surf-fsnative_label-midthickness.surf.gii\n"
     ]
    }
   ],
   "source": [
    "subject = \"PNE003\"\n",
    "session = \"a1\"\n",
    "\n",
    "region  = \"cortex\"\n",
    "#regions = [\"cortex\", \"hippocampus\", \"subcortex\"]\n",
    "\n",
    "hemi = \"L\"\n",
    "hemis = [\"L\", \"R\"]\n",
    "\n",
    "surface = \"midthickness\"\n",
    "#surfaces = [\"midthickness\", \"white\"]\n",
    "\n",
    "feature = \"T1map\"\n",
    "features = [\"ADC-FA-T1map-volume\", \"ADC\", \"FA\", \"T1map\", \"volume\"]\n",
    "\n",
    "smoothing = \"10\"\n",
    "\n",
    "analysis = \"regional\"\n",
    "#analyses = [\"regional\", \"asymmetry\"]\n",
    "\n",
    "print(func_path)\n",
    "print(surf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject PNC019, session: 1\n",
      "[main] Extracting zBrains analysis data.\n",
      "\tThreshold: 1.96\n",
      "\tfunc.gii: /Users/danielmendelson/Documents/Boris_projects/data/PNE003/zBrains/ses-a1/norm-z/cortex/sub-PNC019_ses-1_hemi-L_surf-fsLR-32k_label-midthickness_feature-T1map_smooth-10mm_analysis-regional.func.gii\n",
      "\tsurf.gii: /Users/danielmendelson/Documents/Boris_projects/data/PNE003/zBrains/ses-a1/structural/sub-PNC019_ses-1_hemi-L_space-nativepro_surf-fsnative_label-midthickness.surf.gii\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/danielmendelson/Documents/Boris_projects/data/PNE003/zBrains/ses-a1/norm-z/cortex/sub-PNC019_ses-1_hemi-L_surf-fsLR-32k_label-midthickness_feature-T1map_smooth-10mm_analysis-regional.func.gii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/loadsave.py:101\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/danielmendelson/Documents/Boris_projects/data/PNE003/zBrains/ses-a1/norm-z/cortex/sub-PNC019_ses-1_hemi-L_surf-fsLR-32k_label-midthickness_feature-T1map_smooth-10mm_analysis-regional.func.gii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m     surf_path \u001b[38;5;241m=\u001b[39m wd \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/structural/sub-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_ses-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_hemi-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_space-nativepro_surf-fsnative_label-midthickness.surf.gii\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (subject, \u001b[38;5;28mstr\u001b[39m(session), hemi)\n\u001b[1;32m     20\u001b[0m     analysis_name \u001b[38;5;241m=\u001b[39m subject \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(session) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m hemi\n\u001b[0;32m---> 22\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m main(\n\u001b[1;32m     23\u001b[0m         path_func_gii\u001b[38;5;241m=\u001b[39mfunc_path, \n\u001b[1;32m     24\u001b[0m         path_surf_gii\u001b[38;5;241m=\u001b[39msurf_path, \n\u001b[1;32m     25\u001b[0m         name\u001b[38;5;241m=\u001b[39manalysis_name, \n\u001b[1;32m     26\u001b[0m         save_sets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     27\u001b[0m         save_path\u001b[38;5;241m=\u001b[39mset_save_path, \n\u001b[1;32m     28\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold, \n\u001b[1;32m     29\u001b[0m         test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     32\u001b[0m     out_df \u001b[38;5;241m=\u001b[39m out_df\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscanner\u001b[39m\u001b[38;5;124m\"\u001b[39m: scanner, \n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: subject, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_set_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     40\u001b[0m         }, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANALYSES COMPLETE.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(name, path_func_gii, path_surf_gii, threshold, save_sets, save_path, test)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[main] Extracting zBrains analysis data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mfunc.gii: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_func_gii\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124msurf.gii: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_surf_gii\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 1. Get vertices with value > threshold\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m v_extreme \u001b[38;5;241m=\u001b[39m v_extremeValue(path_gii \u001b[38;5;241m=\u001b[39m path_func_gii, threshold \u001b[38;5;241m=\u001b[39m threshold, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Returns list of vertices\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 2. Get list of adjacent vertices to those vertices\u001b[39;00m\n\u001b[1;32m     20\u001b[0m adjSets \u001b[38;5;241m=\u001b[39m adjVertices(path_surf_gii, v_extreme, test \u001b[38;5;241m=\u001b[39m test) \u001b[38;5;66;03m# Returns list of lists of adjacent vertices\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m, in \u001b[0;36mv_extremeValue\u001b[0;34m(path_gii, threshold, output)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold must be a positive float or integer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m values \u001b[38;5;241m=\u001b[39m load_gifti(path_gii)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# for .func.gii\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     out \u001b[38;5;241m=\u001b[39m values[np\u001b[38;5;241m.\u001b[39mabs(values) \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(threshold)]\n",
      "Cell \u001b[0;32mIn[28], line 32\u001b[0m, in \u001b[0;36mload_gifti\u001b[0;34m(path_gii, extract)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_gifti\u001b[39m(path_gii, extract \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertices\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Load data from GIFTI (.gii) file.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     gii \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(path_gii)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path_gii\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.func.gii\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     35\u001b[0m            \u001b[38;5;28;01mreturn\u001b[39;00m gii\u001b[38;5;241m.\u001b[39mdarrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/loadsave.py:103\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/danielmendelson/Documents/Boris_projects/data/PNE003/zBrains/ses-a1/norm-z/cortex/sub-PNC019_ses-1_hemi-L_surf-fsLR-32k_label-midthickness_feature-T1map_smooth-10mm_analysis-regional.func.gii'"
     ]
    }
   ],
   "source": [
    "# Loop through participants and RUN\n",
    "for subject in pt_sheet[ID_colName]:\n",
    "    # NOTE: SESSION OUGHT TO HAVE prefix '0' or 'a' in data sheet\n",
    "    session = pt_sheet.loc[pt_sheet[ID_colName] == subject, session_colName].values[0].item()\n",
    "    print(\"Subject %s, session: %s\" %(subject, session))\n",
    "\n",
    "    scanner = \"7T\" if \"PNE\" in subject or \"PNC\" in subject or \"PNA\" in subject else \"3T\" # identifier scanner from ID label\n",
    "    #print(\"scanner: %s\" %scanner) \n",
    "\n",
    "    hemi = \"L\" # can eventually iterate through hemispheres\n",
    "\n",
    "    wd_subject = wd + \"/sub-\" + subject + \"/ses-\" + str(session)\n",
    "    func_path = wd_subject + \"/norm-z/%s/sub-%s_ses-%s_hemi-%s_surf-fsLR-32k_label-%s_feature-%s_smooth-%smm_analysis-%s.func.gii\" % (region, subject, str(session), hemi, surface, feature, smoothing, analysis)\n",
    "    surf_path = wd_subject + \"/structural/sub-%s_ses-%s_hemi-%s_space-nativepro_surf-fsnative_label-%s.surf.gii\" % (subject, str(session), hemi, surface) # n.b. different naming for hippocampal surfaces\n",
    "\n",
    "    analysis_name = subject + \"-\" + str(session) + \"_\" + hemi + \"_\" + region + \"_\" + surface + \"_\" + feature + \"_\" + smoothing + \"mm_\" + analysis\n",
    "\n",
    "    metrics = main(\n",
    "        path_func_gii=func_path, \n",
    "        path_surf_gii=surf_path, \n",
    "        name=analysis_name, \n",
    "        save_sets=True, \n",
    "        save_path=set_save_path, \n",
    "        threshold=threshold, \n",
    "        test=True\n",
    "        )\n",
    "    \n",
    "    out_df = out_df.append({\n",
    "        \"scanner\": scanner, \n",
    "        \"ID\": subject, \n",
    "        \"session\": session, \n",
    "        \"hemisphere\": hemi,\n",
    "        \"region\": region,\n",
    "        \"feature\": feature,\n",
    "        \"surface\": surface,\n",
    "        \"smoothing\": smoothing,\n",
    "        \"analysis\": analysis,\n",
    "        \"num_vertices\": metrics[0], \n",
    "        \"num_sets\": metrics[1], \n",
    "        \"max_set_length\": metrics[2]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "print(\"ANALYSES COMPLETE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "date = dt.datetime.now().strftime(\"%d%b%Y\")\n",
    "out_df.to_csv(out_df_save_path + \"/zBrains_quantAnal_\" + date + \".csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
