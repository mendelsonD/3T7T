{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6e2da",
   "metadata": {},
   "source": [
    "# Comparisons between sessions\n",
    "Compare repeated imaging of same subject at same field strength \n",
    " - Questions:\n",
    "    - How do maps compare between sessions? [help understand differences between 3T and 7T, are they due to raw data? If due to raw data then would expect]\n",
    "    - What is the reliability of MR features between sessions? How do field strength differences compare to differences expected by repeated acquisitions?\n",
    "    - Is this reliability moderated by sex/gender, time between sessions, patient grouping, MR strength?\n",
    " - Outputs of interest:\n",
    "    - Subj by vertex matrix plots with columns being different sessions and rows having matched subject-MR strength combos\n",
    "    - Correlation between vertex values between sessions\n",
    "\n",
    "Steps:    \n",
    "0. CSV file with all participants and paths to smoothed data (see main.ipynb)\n",
    "1. Make one df with list of all participant-features available per session number\n",
    "1. Compute statistics on these dfs (cor between rows with the same ID-study)\n",
    "1. Plot matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import datetime\n",
    "import matplotlib.pyplot as plot\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "#sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "\n",
    "import tTsTGrpUtils as tsutil\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "import demo\n",
    "importlib.reload(demo)\n",
    "\n",
    "#from genUtils import id, gen, t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv, created from demographics processing (see main.ipynb)\n",
    "# run parameters\n",
    "\n",
    "# details of demographics file\n",
    "demographics = { # should include UID\n",
    "    \"pth\" : \"/host/verges/tank/data/daniel/3T7T/z/outputs/03b_demoPths_clean_16Sep2025-104025.csv\",\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\", # scan date\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "# specify root directories\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "px_grps = { # specify patient group labels to compare to controls\n",
    "    'allPX' : ['TLE_U', 'MFCL', 'FLE_R', 'MFCL_bTLE', 'UKN_L', 'mTLE_R', 'mTLE_L', 'FLE_L', 'UKN_U', 'TLE_L', 'TLE_R'],\n",
    "    'TLE' : ['TLE_L', 'TLE_R', 'TLE_U', 'mTLE_R', 'mTLE_L'],\n",
    "    'TLE_L': ['TLE_L', 'mTLE_L', 'bTLE_L'],\n",
    "    'TLE_R': ['TLE_R', 'mTLE_R', 'bTLE_R'],\n",
    "    'FCD' : ['FLE_R', 'FLE_L'],\n",
    "    'MFCL' : ['MFCL', 'bTLE'],\n",
    "    'UKN' : ['UKN_L', 'UKN_U']\n",
    "}\n",
    "\n",
    "# Make list of dict items for group definitions\n",
    "groups = [\n",
    "    {'TLE_L': px_grps['TLE_L']},\n",
    "    {'TLE_R': px_grps['TLE_R']},\n",
    "    ctrl_grp\n",
    "]\n",
    "\n",
    "ses_specs  = { # session comparions ses_specs. Includes paths, what maps to run, statistics to compute, moderators, etc. NOTE. All moderators listed should be in demographics dictionary\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/3T7T/z\", # output directory for smoothed cortical maps\n",
    "    'prjDir_outs' : \"/outputs/btwSES\",\n",
    "    'prjDir_out_figs': \"/outputs/btwSES/figures\",\n",
    "    'prjDir_maps' : \"/maps\",\n",
    "    \n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-5k'],\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white', 'swm1.0mm'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map', 'flair', 'ADC', 'FA'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['0p5mm'],\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map', 'flair', 'ADC', 'FA'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "    \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'cor': True,\n",
    "    'moderators': [demographics['age'], demographics['sex'], demographics['date'], demographics['grp'], 'Seizure onset (yr)'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(demo)\n",
    "reimport = True\n",
    "if 'df_demo' not in locals() or df_demo is None or reimport:\n",
    "    df_demo = pd.read_csv(demographics['pth'])\n",
    "    print(f\"df_demo loaded from {demographics['pth']}\")\n",
    "\n",
    "\n",
    "df_demo[demographics['date']] = pd.to_datetime(df_demo[demographics['date']], errors='coerce', dayfirst=True) # format the date column\n",
    "df_demo['ID_study'] = df_demo.apply(lambda row: row[demographics['ID_3T']] if row['study'] == '3T' else (row[demographics['ID_7T']] if row['study'] == '7T' else np.nan), axis=1) # create column assigning appropriate study ID for that row\n",
    "demographics['col_studyID'] = 'ID_study' # add to demographics dict\n",
    "print(df_demo[['UID','MICS_ID', 'PNI_ID', 'study', 'ID_study', 'SES', 'Date', 'grp_detailed']])\n",
    "df_demo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b343f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY OF PARTICIPANTS/<TABLE 1>\n",
    "demo.grp_summary(df_demo, col_grp='grp_detailed', save_pth=None)\n",
    "print(\"-\"*100)\n",
    "print(\"MEDIAN AGE by group\")\n",
    "df_demo.groupby(['grp_detailed', 'study'])['age'].median().sort_index(level='grp_detailed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9417a3",
   "metadata": {},
   "source": [
    "# ANALYSIS ses_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b2572",
   "metadata": {},
   "source": [
    "# 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da2d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column in df_demo that provides a session number per participant. Should order by scan date\n",
    "# each UID-study combination should have a session number starting at 1 and increasing by 1 for each additional session, ordered by date\n",
    "df_demo = df_demo.sort_values(by=['UID', 'study', 'Date'])\n",
    "df_demo['ses_number'] = df_demo.groupby(['UID', 'study']).cumcount() + 1\n",
    "demographics['col_sesNum'] = 'ses_number' # add to demographics dict for later use\n",
    "#pd.set_option('display.max_rows', None)\n",
    "df_demo[['UID', 'study', 'Date', 'ses_number']].loc[0:25,:]\n",
    "\n",
    "# create a table counting  the number of sessions per study. this should return a n_unique_studies by n_unique_sessions table\n",
    "df_demo_sessions = df_demo.groupby(['study', 'ses_number']).size().unstack(fill_value=0)\n",
    "df_demo_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through specifications and session number, read in maps and keep df_demo with rows only from the session. The index of the df_maps should be 'UID'_'STUDY'_'STUDYID'_'SES'ArithmeticError\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "save = True\n",
    "save_pth = f\"{['prjDir_root']}{ses_specs['prjDir_outs']}\"\n",
    "save_name = \"01a_maps\"\n",
    "test = False\n",
    "verbose = True\n",
    "\n",
    "print(f\"Creating a dictionary items with session number as an iterated item rather than study (each combo of: ses_number-feature-label-surface-smoothing).\\n\\tNote. Not seperating participant groups yet.\")\n",
    "\n",
    "dl = tsutil.extractMap_SES(df_mapPaths = df_demo, col_sesNum = demographics['col_sesNum'], col_studyID = demographics['col_studyID'],\n",
    "                            coi = ses_specs['moderators'], save_pth = f\"{ses_specs['prjDir_root']}{ses_specs['prjDir_outs']}\", \n",
    "                            save_name = save_name, verbose = verbose, test=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP MATRICES # TODO. adatpt for sessions\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# create pngs\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_SES/raw\"\n",
    "tsutil.plotMatrices(dl = dl, key = 'df_maps', sessions = [1,2], show=False, save_pth=fig_dir, test=False) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_SES\") # group pngs of same comparisons with different smoothing to single pdf\n",
    "\n",
    "print(\"Should visually inspect maps, identifying feature-ID-SES combinations that are outliers. Mark for removal [editing <path/to/file name.xlsx> and rerun from step 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b64e",
   "metadata": {},
   "source": [
    "# Within study, vertex-wise statistics (z-, w- scores)\n",
    "- compares _all_ participants to controls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56551277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import smmothed maps\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = True\n",
    "save_name = \"05a_stats_winStudy\"\n",
    "\n",
    "if 'dl' not in globals() or dl is None or reimport == True:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/btwSES/01a_maps_19Sep2025-102425.pkl\"\n",
    "    dl = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "    \n",
    "tsutil.print_dict(dl, df_print=False)\n",
    "\n",
    "# calculate statistics\n",
    "dl_winComp = tsutil.winComp(dl = dl, demographics = demographics, ctrl_grp = ctrl_grp, z = ses_specs['z'], w = ses_specs['w'], \n",
    "                            covars = ses_specs['covars'], col_grp = ses_specs['col_grp'],\n",
    "                            save = True, save_pth = ses_specs['prjDir_root'] + ses_specs['prjDir_outs'], save_name = save_name,\n",
    "                            verbose = True, dlPrint = True, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924452",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp/raw\"\n",
    "tsutil.plotMatrices(dl = dl_winComp, key = 'df_z', name_append=\"stat-z\", show=False, save_pth=fig_dir, test=False) # visualize z score maps\n",
    "tsutil.plotMatrices(dl = dl_winComp, key = 'df_w', name_append=\"stat-w\", show=False, save_pth=fig_dir, test=False) # visualize w score maps\n",
    "tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef774a1",
   "metadata": {},
   "source": [
    "# Select group of interest and ipsi/contra flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary list based on previous dl.\n",
    "# New dl will have the same number of dictionary items (one for each study, ft, label, surf, smth, region combination).\n",
    "#   Keys of each dictionary items may change. One df for each combination of [group[len(goi)] x lateralization[_R, _L, _ic] + 1 (ctrl)] x stat[<_z>, <_w>]] \n",
    "#   If df_{stat} is none, nothing regarding this statistic will be added to dict item.\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "goi = [\"TLE\"] # group(s) of interest. Store main diagnosis abrev in list to allow for multiple groups\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_stats_winStudy_17Sep2025-163602.pkl\"\n",
    "if 'dl_winComp' not in globals(): reimport = True\n",
    "elif dl_winComp is None: reimport = True\n",
    "if reimport: dl_winComp = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "dl_grp_ic = tsutil.grp_flip(dl = dl_winComp, demographics = demographics, \n",
    "                    goi = goi, col_grp = ses_specs['col_grp'],\n",
    "                    save_pth = ses_specs['prjDir_root'] + ses_specs['prjDir_outs'], save_name = \"05b_stats_winStudy_grp\", test=test, verbose=verbose, dlPrint=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb52c",
   "metadata": {},
   "source": [
    "# Within study Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "save = True\n",
    "\n",
    "stats = []\n",
    "if ses_specs['z']: # statistics to compute d-scores for\n",
    "    stats.append('z')\n",
    "if ses_specs['w']:\n",
    "    stats.append('w')\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_18Sep2025-125541.pkl\"\n",
    "if 'dl_grp_ic' not in globals(): reimport = True\n",
    "elif dl_grp_ic is None: reimport = True\n",
    "if reimport: dl_grp_ic = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "winD = tsutil.winD(dl = dl_grp_ic, stats = stats, ipsiTo = ses_specs.get('ipsiTo', 'L'), \n",
    "                   save = save, save_pth = ses_specs['prjDir_root'] + ses_specs['prjDir_outs'], save_name = \"05c_stats_winD\",\n",
    "                   verbose = verbose, test = test, dlPrint = toPrint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e0b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrices\n",
    "importlib.reload(tsutil)\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD/raw\"\n",
    "tsutil.plotMatrices(dl = winD[83], key = 'df_d', show=False, save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.plotMatrices(dl = winD[83], key = 'df_d_ic', show=False, save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir = save_pth, output = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847ea6",
   "metadata": {},
   "source": [
    "# Between study: D-score differences\n",
    "- Identify pairs of dictionary items\n",
    "- Extract d scoring statitics and compute:\n",
    "- raw d dif\n",
    "- d dif / ctrl d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "verbose = True\n",
    "\n",
    "# import \n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05c_stats_winD_2025Sep18-154003.pkl\"\n",
    "if 'winD' not in globals(): reimport = True\n",
    "elif winD is None: reimport = True\n",
    "if reimport: dl = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "comps = tsutil.btwD(dl = winD,\n",
    "                    save = save, save_pth = ses_specs['prjDir_root'] + ses_specs['prjDir_outs'], save_name = \"05d_stats_btwStudy\",\n",
    "                    verbose = verbose, test = test, dlPrint = toPrint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c0e6b",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
