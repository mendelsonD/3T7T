{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import utils_plots as uplots\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/host/verges/tank/data/daniel/3T7T/z/code/analyses/hippunfold_toolbox/\")\n",
    "from hippunfold_toolbox import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "test = False # for quick testing\n",
    "\n",
    "# Data paths\n",
    "root = \"/host/verges/tank/data/daniel/3T7T/z/outputs/\"\n",
    "pth_05c_winD = \"05c_stats_winD_20Oct2025-110828.pkl\" # Has all data from above maps as well. D score btw px and ctrl z-scores\n",
    "pth_05d_btwD = \"05d_btwD_20Oct2025-114530.pkl\" # difference in D scores between studies\n",
    "\n",
    "\n",
    "#dl_winD = tsutil.loadPickle(root + pth_05c_winD)\n",
    "dl_btwD = tsutil.loadPickle(root + pth_05d_btwD)\n",
    "dl_winD = tsutil.loadPickle(root + pth_05c_winD)\n",
    "demo = \"/host/verges/tank/data/daniel/3T7T/z/outputs/03c_demoPths_clean_18Oct2025-153812.csv\"\n",
    "#qc_table = \"/host/verges/tank/data/daniel/3T7T/z/outputs/old_QCtables/03a_qc_table_09Oct2025-094401.csv\"\n",
    "df_demo = pd.read_csv(demo)\n",
    "#qc_table = pd.read_csv(qc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770320ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge QC table with df_demo, matching on UID, study, ID, SES, Date\n",
    "#df_demo = df_demo.merge(qc_table, on=['UID', 'study', 'SES', 'Date'], how='left')\n",
    "\n",
    "df_demo['UID_ID_SES_3T'] = df_demo.apply(lambda row: f\"{row['UID']}_{row['MICS_ID']}_{row['SES']}\", axis=1)\n",
    "df_demo['UID_ID_SES_7T'] = df_demo.apply(lambda row: f\"{row['UID']}_{row['PNI_ID']}_{row['SES']}\", axis=1)\n",
    "df_demo_3T = df_demo[df_demo['study'] == '3T']\n",
    "df_demo_7T = df_demo[df_demo['study'] == '7T']\n",
    "df_demo_3T.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88275d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsutil.print_dict(dl_winD)\n",
    "dl_winD_filt = tsutil.filt_dl(dl_winD, 'feature', 'T1map')\n",
    "\n",
    "lens_ctrl = []\n",
    "lens_tle = []\n",
    "for item in dl_winD_filt:\n",
    "    ctrl_ids = item['ctrl_IDs']\n",
    "    tle_r_ids = item['TLE_R_IDs']\n",
    "    tle_l_ids = item['TLE_L_IDs']\n",
    "\n",
    "    len_ctrl = len(ctrl_ids)\n",
    "    len_tle = len(tle_r_ids) + len(tle_l_ids)\n",
    "    lens_ctrl.append(len_ctrl)\n",
    "    lens_tle.append(len_tle)\n",
    "\n",
    "# find index of max length\n",
    "max_len_ctrl = max(lens_ctrl)\n",
    "max_len_tle = max(lens_tle)\n",
    "idx_max_ctrl = lens_ctrl.index(max_len_ctrl)\n",
    "idx_max_tle = lens_tle.index(max_len_tle)\n",
    "print(lens_ctrl)\n",
    "print(lens_tle)\n",
    "print(f\"Max ctrl len: {max_len_ctrl} at index {idx_max_ctrl}\")\n",
    "print(f\"Max TLE len: {max_len_tle} at index {idx_max_tle}\")\n",
    "\n",
    "tsutil.printItemMetadata(dl_winD_filt[0], idx = 0)\n",
    "tsutil.printItemMetadata(dl_winD_filt[1], idx = 1)\n",
    "tsutil.printItemMetadata(dl_winD_filt[44], idx = 44)\n",
    "tsutil.printItemMetadata(dl_winD_filt[45], idx =45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_IDs_3T = dl_winD[0]['ctrl_IDs']\n",
    "ctrl_IDs_7T = dl_winD[1]['ctrl_IDs']\n",
    "\n",
    "TLE_IDs_3T = dl_winD[44]['TLE_L_IDs'] + dl_winD[44]['TLE_R_IDs']\n",
    "TLE_IDs_7T = dl_winD[45]['TLE_L_IDs'] + dl_winD[45]['TLE_R_IDs']\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d921f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_IDs_7T + TLE_IDs_7T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b14b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo_3T = df_demo[df_demo['study'] == '3T']\n",
    "df_demo_7T = df_demo[df_demo['study'] == '7T']\n",
    "\n",
    "df_demo_final_3T = df_demo_3T[df_demo_3T['UID_ID_SES_3T'].isin(ctrl_IDs_3T + TLE_IDs_3T)]\n",
    "df_demo_final_7T = df_demo_7T[df_demo_7T['UID_ID_SES_7T'].isin(ctrl_IDs_7T + TLE_IDs_7T)]\n",
    "\n",
    "df_demo_final = df_demo_final_3T[['UID', 'MICS_ID', 'PNI_ID', 'age', 'sex', 'education','ethnicity', 'grp', 'grp_detailed', 'Histopatholgy', \n",
    "                                 'Drug resistant epilepsy at time of EMU admission', 'Seizure onset (yr)', 'Dx at EMU discharge ']]\n",
    "\n",
    "dateDif_d = pd.Series(dtype=float)\n",
    "dateDif_wks = pd.Series(dtype=float)\n",
    "dateDif_yrs = pd.Series(dtype=float)\n",
    "for uid in df_demo_final_3T['UID']:\n",
    "    Date_3T = df_demo_final_3T[df_demo_final_3T['UID'] == uid]['Date'].values[0]\n",
    "    Date_7T = df_demo_final_7T[df_demo_final_7T['UID'] == uid]['Date'].values[0]\n",
    "    date_diff_days = np.abs((pd.to_datetime(Date_7T,dayfirst = True) - pd.to_datetime(Date_3T, dayfirst = True)).days)\n",
    "    date_diff_wks = date_diff_days / 7\n",
    "    date_diff_yrs = date_diff_days / 365.25\n",
    "    #print(f\"UID: {uid}, Date 3T: {Date_3T}, Date 7T: {Date_7T}, Date Difference (days): {date_diff_days}\")\n",
    "    dateDif_d[uid] = date_diff_days\n",
    "    dateDif_wks[uid] = date_diff_wks\n",
    "    dateDif_yrs[uid] = date_diff_yrs\n",
    "#print(dateDif)\n",
    "df_demo_final['dateDif'] = df_demo_final['UID'].map(dateDif)\n",
    "df_demo_final['dateDif_wks'] = df_demo_final['UID'].map(dateDif_wks)\n",
    "df_demo_final['dateDif_yrs'] = df_demo_final['UID'].map(dateDif_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c830c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with grp_detailed == \"TLE_BL\"\n",
    "df_demo_final = df_demo_final[df_demo_final['grp_detailed'] != 'TLE_BL']\n",
    "df_demo_final[df_demo_final['grp'] == 'CTRL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note age at 3T\n",
    "# based on this df, create a summary statistics table\n",
    "# for categorical variables, show counts and percentages\n",
    "# Create summary statistics for both numerical and categorical variables\n",
    "\n",
    "# Create summary statistics grouped by 'grp' column\n",
    "print(\"=== SUMMARY STATISTICS BY GROUP ===\")\n",
    "\n",
    "summary_stats = []\n",
    "\n",
    "for grp in df_demo_final['grp'].unique():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"GROUP: {grp}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    grp_data = df_demo_final[df_demo_final['grp'] == grp]\n",
    "    print(f\"Total participants: {len(grp_data)}\")\n",
    "    \n",
    "    print(f\"\\n--- NUMERICAL VARIABLES ---\")\n",
    "    numerical_cols = grp_data.select_dtypes(include=[np.number]).columns\n",
    "    num_stats = grp_data[numerical_cols].describe()\n",
    "    print(num_stats)\n",
    "    \n",
    "    print(f\"\\n--- CATEGORICAL VARIABLES ---\")\n",
    "    categorical_cols = grp_data.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if col != 'grp':  # Skip the grouping variable itself\n",
    "            print(f\"\\n{col}:\")\n",
    "            value_counts = grp_data[col].value_counts(dropna=False)\n",
    "            percentages = grp_data[col].value_counts(normalize=True, dropna=False) * 100\n",
    "            summary_df = pd.DataFrame({\n",
    "                'Count': value_counts,\n",
    "                'Percentage': percentages.round(1)\n",
    "            })\n",
    "            print(summary_df)\n",
    "            \n",
    "            # Store for CSV export\n",
    "            for idx, row in summary_df.iterrows():\n",
    "                summary_stats.append({\n",
    "                    'Group': grp,\n",
    "                    'Variable': col,\n",
    "                    'Value': idx,\n",
    "                    'Count': row['Count'],\n",
    "                    'Percentage': row['Percentage']\n",
    "                })\n",
    "\n",
    "# Add numerical statistics to summary_stats\n",
    "for grp in df_demo_final['grp'].unique():\n",
    "    grp_data = df_demo_final[df_demo_final['grp'] == grp]\n",
    "    numerical_cols = grp_data.select_dtypes(include=[np.number]).columns\n",
    "    num_stats = grp_data[numerical_cols].describe()\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        for stat in num_stats.index:\n",
    "            summary_stats.append({\n",
    "                'Group': grp,\n",
    "                'Variable': col,\n",
    "                'Value': f'{stat}',\n",
    "                'Count': num_stats.loc[stat, col],\n",
    "                'Percentage': ''\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "summary_stats_df = pd.DataFrame(summary_stats)\n",
    "summary_stats_df.to_csv('/host/verges/tank/data/daniel/3T7T/z/outputs/summary_statistics_by_group.csv', index=False)\n",
    "print(f\"\\nSummary statistics saved to: /host/verges/tank/data/daniel/3T7T/z/outputs/summary_statistics_by_group.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d19f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with jut TLE\n",
    "demo_TLE_3T = df_demo_3T[df_demo_3T['UID_ID_SES_3T'].isin(TLE_IDs_3T)]\n",
    "demo_TLE_7T = df_demo_7T[df_demo_7T['UID_ID_SES_7T'].isin(TLE_IDs_7T)]\n",
    "\n",
    "# Combine the TLE dataframes from both studies\n",
    "demo_TLE = pd.concat([demo_TLE_3T, demo_TLE_7T], ignore_index=True)\n",
    "demo_TLE = demo_TLE[demo_TLE['grp_detailed'] != 'TLE_BL']\n",
    "demo_TLE['ID'] = demo_TLE.apply(lambda row: row['MICS_ID'] if row['study'] == '3T' else row['PNI_ID'], axis=1)\n",
    "demo_TLE.columns\n",
    "# save to df\n",
    "demo_TLE.to_csv('/host/verges/tank/data/daniel/3T7T/z/outputs/001_demo_TLE_volPths.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ff581",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_TLE.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fff4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
