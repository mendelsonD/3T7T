{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics\n",
    "\n",
    "a. Identify IDs with 3T and 7T  \n",
    "b. Extract clinical information for epilepsy patients  \n",
    "c. Extract demographic information for all participants  \n",
    "\n",
    "\n",
    "Note participant grouping:\n",
    "- CTRL : no known epilepsy (identified by ID code: 3T: HC; 7T: PNC, Pilot)\n",
    "\n",
    "- (m)TLE : temporal lobe epilepsy\n",
    "    - TLE_L : TLE left lateralized (including L>R)\n",
    "    - TLE_R : TLE right lateralized (including R>L)\n",
    "    - TLE_U : TLE with unknown lateralization\n",
    "    - mTLE_L : mTLE left lateralized\n",
    "    - mTLE_R : mTLE right lateralized\n",
    "- FLE : focal epilepsy that is not in temporal lobe\n",
    "    - FLE_L\n",
    "    - FLE_R\n",
    "- UKN : Focal epilepsy with focus in unknown lobe\n",
    "    - UKN_L : Unknown lobe with known L lateralization\n",
    "    - UKN_R : Unknown lobe with known R lateralization\n",
    "    - UKN_U : Unknown lobe with unknown lateralization\n",
    "- MFCL : multifocal epilepsy\n",
    "    - MFCL : multifocal epilepsy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "#sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "from Utils import id, gen, t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Utils.t1' from '/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code/Utils/t1.py'>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(id)\n",
    "importlib.reload(gen)\n",
    "importlib.reload(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dupSES(df, uniqCols, mergeCols):\n",
    "    \"\"\"\n",
    "    Identify and resolve repeated session codes for the same participant at the same study\n",
    "\n",
    "    Input:\n",
    "        df: DataFrame containing the session data\n",
    "        uniqCols: List of columns whose combination should be unique in each row\n",
    "        mergeCols: List of columns whose values may need merging (eg., scanDate)\n",
    "\n",
    "    Return:\n",
    "        DataFrame with resolved repeated sessions\n",
    "    \"\"\"\n",
    "    \n",
    "    if df.duplicated(subset=uniqCols).any():\n",
    "        n_repeated = df.duplicated(subset=uniqCols, keep=False).groupby([df[c] for c in uniqCols]).any().sum()\n",
    "        print(f\"[dupSES] WARNING: There are {n_repeated} participant-study combinations with repeated rows:\")\n",
    "        dup_rows = df[df.duplicated(subset=uniqCols, keep=False)]\n",
    "        grouped = dup_rows.groupby(['MICS_ID', 'PNI_ID', 'study', 'SES']).size().reset_index(name='count')\n",
    "        for _, row in grouped.iterrows():\n",
    "            # Get all rows for this individual/session\n",
    "            rows = dup_rows[\n",
    "                (dup_rows['MICS_ID'] == row['MICS_ID']) &\n",
    "                (dup_rows['PNI_ID'] == row['PNI_ID']) &\n",
    "                (dup_rows['study'] == row['study']) &\n",
    "                (dup_rows['SES'] == row['SES'])\n",
    "            ]\n",
    "            merge_info = []\n",
    "            for col in mergeCols:\n",
    "                vals = rows[col].dropna().unique()\n",
    "                # Conflict resolution logic\n",
    "                if len(vals) > 1:\n",
    "                    # If column name contains 'date', resolve by earliest date\n",
    "                    if 'date' in col.lower():\n",
    "                        # Try to parse dates, fallback to string sort if fails\n",
    "                        try:\n",
    "                            parsed = pd.to_datetime(vals, errors='coerce', dayfirst=True) # d.m.y format\n",
    "                            chosen = vals[parsed.argmin()] if parsed.notna().any() else sorted(vals)[0]\n",
    "                        except Exception:\n",
    "                            chosen = sorted(vals)[0]\n",
    "                        method = \"earliest date\"\n",
    "                    else:\n",
    "                        # Default: use first value (could add more strategies)\n",
    "                        chosen = sorted(vals)[0]\n",
    "                        method = \"first (sorted) value\"\n",
    "                    # Update all rows for this group to use the chosen value\n",
    "                    df.loc[\n",
    "                        (df['MICS_ID'] == row['MICS_ID']) &\n",
    "                        (df['study'] == row['study']) &\n",
    "                        (df['SES'] == row['SES']),\n",
    "                        col\n",
    "                    ] = chosen\n",
    "                else:\n",
    "                    chosen = vals[0] if len(vals) > 0 else None\n",
    "                    method = \"unique/no conflict\"\n",
    "                merge_info.append(f\"{col}={list(vals)} -> {chosen} ({method})\")\n",
    "            merge_str = \"; \".join(merge_info)\n",
    "            print(f\"\\t[{row['MICS_ID']}={row['PNI_ID']}-{row['study']}] ses-{row['SES']} (x{row['count']}): {merge_str}\")\n",
    "        \n",
    "        df = df.drop_duplicates(subset=uniqCols, keep='first').reset_index(drop=True) # remove duplicated rows\n",
    "\n",
    "    return df\n",
    "\n",
    "def rmvNADate(df, dateCol):\n",
    "    \"\"\"\n",
    "    Remove rows with missing scan date from the DataFrame.\n",
    "\n",
    "    Input:\n",
    "        df: DataFrame to process\n",
    "        dateCol: Name of the date column to check for missing values\n",
    "    \"\"\"\n",
    "    n_missing_dates = df[dateCol].isna().sum()\n",
    "    if n_missing_dates != 0:\n",
    "        missing_dates = df[df[dateCol].isna()]\n",
    "        print(missing_dates[['MICS_ID', 'study', dateCol]])\n",
    "        count_7T = (missing_dates['study'] == '7T').sum()\n",
    "        count_3T = (missing_dates['study'] == '3T').sum()\n",
    "        print(f\"\\n[rmvNADate] WARNING. {n_missing_dates} rows have missing scan dates:\\n\\t{count_7T} from 7T\\n\\t{count_3T} from 3T\")\n",
    "        print(\"[rmvNADate] Removing the following participants (study of the removed row):\")\n",
    "        missing_ids = missing_dates['MICS_ID'].unique()\n",
    "        df = df.dropna(subset=[dateCol])\n",
    "        for mid in missing_ids:\n",
    "            # there should be at least one row with each study code\n",
    "            studies = df[df['MICS_ID'] == mid]['study'].unique() # remaining studies for that ID\n",
    "            if len(studies) < len(df['study'].unique()): # if this has ID has fewer unique studies than those present in the data, remove all rows for that ID\n",
    "                print(f\"\\t{mid} (removed study: {studies})\")\n",
    "                df = df[df['MICS_ID'] != mid]\n",
    "    else:\n",
    "        print(\"\\n[rmvNADate] No rows with missing scan dates found.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def mergeCols(df):\n",
    "    \"\"\"\n",
    "    Merge columns with similar names (case-insensitive, ignoring whitespace) by prioritizing non-null values.\n",
    "    For each group of similar columns, select the column with the shortest name (or lowercase if tied),\n",
    "    and fill its missing values with values from the other columns in the group (row-wise).\n",
    "    Drops the other columns in the group.\n",
    "\n",
    "    Special logic: If both 'date' and 'scanDate' columns exist (case-insensitive), merge them into a single 'date' column,\n",
    "    preferring non-null and earliest date values, and print out the merge process.\n",
    "\n",
    "    Input:\n",
    "        df: DataFrame with potential duplicate/similar columns\n",
    "\n",
    "    Output:\n",
    "        df: DataFrame with merged columns\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Normalize column names: lower case, strip whitespace\n",
    "    def norm(col):\n",
    "        return re.sub(r'\\s+', '', col).lower()\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    norm_map = {}\n",
    "    for col in cols:\n",
    "        key = norm(col)\n",
    "        norm_map.setdefault(key, []).append(col)\n",
    "\n",
    "    # Special handling for 'date' and 'scanDate'\n",
    "    date_cols = [c for c in cols if norm(c) in ('date', 'scandate')]\n",
    "    if len(date_cols) >= 2:\n",
    "        # Only proceed if both columns exist\n",
    "        main_col = [c for c in date_cols if norm(c) == 'date']\n",
    "        scan_col = [c for c in date_cols if norm(c) == 'scandate']\n",
    "        if main_col and scan_col:\n",
    "            main_col = main_col[0]\n",
    "            scan_col = scan_col[0]\n",
    "            # If 'date' column does not exist, create it\n",
    "            if 'date' not in df.columns:\n",
    "                df['date'] = np.nan\n",
    "            # Only operate on rows where values differ and both are not null\n",
    "            mask = (df[main_col].notna() & df[scan_col].notna() & (df[main_col] != df[scan_col]))\n",
    "            if mask.any():\n",
    "                print(f\"[mergeCols] Merging '{main_col}' and '{scan_col}' into 'date' for rows where values differ\")\n",
    "                for idx, row in df[mask].iterrows():\n",
    "                    val1 = row[main_col]\n",
    "                    val2 = row[scan_col]\n",
    "                    d1 = pd.to_datetime(val1, errors='coerce', dayfirst=True)\n",
    "                    d2 = pd.to_datetime(val2, errors='coerce', dayfirst=True)\n",
    "                    chosen = None\n",
    "                    method = \"\"\n",
    "                    if pd.notna(d1) and pd.notna(d2):\n",
    "                        if d1 <= d2:\n",
    "                            chosen = val1\n",
    "                            method = \"earliest (date)\"\n",
    "                        else:\n",
    "                            chosen = val2\n",
    "                            method = \"earliest (scanDate)\"\n",
    "                    elif pd.notna(d1):\n",
    "                        chosen = val1\n",
    "                        method = \"date only\"\n",
    "                    elif pd.notna(d2):\n",
    "                        chosen = val2\n",
    "                        method = \"scanDate only\"\n",
    "                    else:\n",
    "                        chosen = val1 if pd.notna(val1) else val2\n",
    "                        method = \"non-date fallback\"\n",
    "                    df.at[idx, 'date'] = chosen\n",
    "                    # Use .get to avoid KeyError for missing columns\n",
    "                    mics_id = row.get('MICS_ID', 'NA')\n",
    "                    pni_id = row.get('PNI_ID', 'NA')\n",
    "                    study = row.get('study', 'NA')\n",
    "                    ses = row.get('SES', 'NA')\n",
    "                    print(f\"\\t[mergeCols] [{mics_id}={pni_id}-{study}] ses-{ses}: {main_col}={val1}, {scan_col}={val2} -> {chosen}\")\n",
    "            # For all other rows, fill 'date' with available value (prefer main_col, then scan_col)\n",
    "            for idx, row in df.iterrows():\n",
    "                if pd.isna(df.at[idx, 'date']):\n",
    "                    val1 = row[main_col]\n",
    "                    val2 = row[scan_col]\n",
    "                    df.at[idx, 'date'] = val1 if pd.notna(val1) else val2\n",
    "            # Drop both original columns except 'date'\n",
    "            drop_cols = [c for c in [main_col, scan_col] if c != 'date']\n",
    "            df.drop(columns=drop_cols, inplace=True)\n",
    "            # Remove from norm_map so not merged again\n",
    "            for c in drop_cols:\n",
    "                norm_map.pop(norm(c), None)\n",
    "            if main_col != 'date':\n",
    "                norm_map.pop(norm(main_col), None)\n",
    "            if scan_col != 'date':\n",
    "                norm_map.pop(norm(scan_col), None)\n",
    "\n",
    "    # Merge other similar columns\n",
    "    for group in norm_map.values():\n",
    "        if len(group) > 1:\n",
    "            # Skip if group contains both 'date' and 'scanDate' (already handled)\n",
    "            if set([norm(c) for c in group]) == set(['date', 'scandate']):\n",
    "                continue\n",
    "            # Choose the column with shortest name, or lowercase if tied\n",
    "            group_sorted = sorted(group, key=lambda x: (len(x), x.lower()))\n",
    "            main_col = group_sorted[0]\n",
    "            other_cols = [c for c in group if c != main_col]\n",
    "            print(f\"[mergeCols] Merging columns: {group} -> '{main_col}' (date/scandate in group: {any(norm(c) in ['date', 'scandate'] for c in group)})\")\n",
    "            # Fill missing values in main_col from other columns, row-wise\n",
    "            df[main_col] = df[group].bfill(axis=1).iloc[:, 0]\n",
    "            # Drop the other columns\n",
    "            df.drop(columns=other_cols, inplace=True)\n",
    "    return df\n",
    "\n",
    "def carryVals(df, var):\n",
    "    \"\"\"\n",
    "    Carry forward and backward fill demographic variables for each participant.\n",
    "\n",
    "    For each participant (grouped by 'MICS_ID'), if multiple unique non-null values are found for the variable:\n",
    "      - Use the value with the shortest number of characters.\n",
    "      - If there is a tie, use the first value encountered.\n",
    "      - Print a warning indicating all found values and which one was used, including study and session number if available.\n",
    "\n",
    "    Input:\n",
    "        df: DataFrame containing demographic information\n",
    "        var: Column name to carry forward/backward fill\n",
    "\n",
    "    Output:\n",
    "        df: DataFrame with the variable filled per participant\n",
    "    \"\"\"\n",
    "    df[var] = df.groupby('MICS_ID')[var].transform(lambda x: x.ffill().bfill())\n",
    "    # Check for multiple unique values for the same ID\n",
    "    dupes = df.groupby('MICS_ID')[var].nunique()\n",
    "    multi_val_ids = dupes[dupes > 1].index\n",
    "    for mid in multi_val_ids:\n",
    "        vals = df[df['MICS_ID'] == mid][var].dropna().unique()\n",
    "        # Choose value with shortest number of characters, if tie, use first\n",
    "        vals_sorted = sorted(vals, key=lambda v: (len(str(v)), str(v)))\n",
    "        chosen = vals_sorted[0]\n",
    "        pni_id = df[df['MICS_ID'] == mid]['PNI_ID'].iloc[0] if 'PNI_ID' in df.columns else ''\n",
    "        study = df[df['MICS_ID'] == mid]['study'].iloc[0] if 'study' in df.columns else ''\n",
    "        ses = df[df['MICS_ID'] == mid]['SES'].iloc[0] if 'SES' in df.columns else ''\n",
    "        used_idx = list(vals).index(chosen) + 1\n",
    "        print(f\"\\t[carryVals] WARNING: [{mid}={pni_id} Study: {study}-ses{ses}] {var} : {' | '.join(map(str, vals))} --> {chosen}\")\n",
    "    \n",
    "    # Use the chosen value for each group\n",
    "    def choose_val(x):\n",
    "        non_nulls = x.dropna()\n",
    "        if len(non_nulls.unique()) > 1:\n",
    "            vals_sorted = sorted(non_nulls.unique(), key=lambda v: (len(str(v)), str(v)))\n",
    "            return vals_sorted[0]\n",
    "        elif len(non_nulls) > 0:\n",
    "            return non_nulls.iloc[0]\n",
    "        else:\n",
    "            return x\n",
    "    df[var] = df.groupby('MICS_ID')[var].transform(choose_val)\n",
    "    return df\n",
    "\n",
    "def group(df, ID_col=\"MICS_ID\", out_col=\"grp\", save_pth=None, MFCL_col=\"Epilepsy classification:Focal,Generalized\", lobe_col=\"Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)\", lat_col=\"Lateralization of epileptogenic focus\"):\n",
    "    \"\"\"\n",
    "    Requires pandas as pd\n",
    "\n",
    "    Inputs:\n",
    "    df: str or pd.DataFrame\n",
    "        demographics data\n",
    "    ID_col: str\n",
    "        Column name for the ID\n",
    "    out_col: str\n",
    "        Column name for the output group classification. \n",
    "        Options: 'grp' returns high-level grouping. All other col_names return detailed grouping.\n",
    "    MFCL_col: str\n",
    "        Column name for the multifocal classification\n",
    "    lobe_col: str  \n",
    "        Column name for the lobe classification\n",
    "    lat_col: str\n",
    "        Column name for the lateralization classification\n",
    "\n",
    "    Outputs:\n",
    "    df: pd.DataFrame\n",
    "        DataFrame with the group classification added\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    print(\"[group] Identifying participant groups\")\n",
    "    # check if df is a string (path) or dataframe\n",
    "    if isinstance(df, str):\n",
    "        # check if file exists\n",
    "        if not os.path.isfile(df):\n",
    "            raise ValueError(f\"[group] Error: {df} does not exist.\")\n",
    "        \n",
    "        # read in file\n",
    "        df = pd.read_csv(df, dtype=str)\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"[group] Error: df must be a string (path) or dataframe\")\n",
    "\n",
    "    df[out_col] = df.apply(\n",
    "        lambda row: f\"PATTERN NOT RECOGNIZED: lobe={row.get(lobe_col, None)}, lat={row.get(lat_col, None)}, MFCL={row.get(MFCL_col, None)}\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    if ID_col == \"MICS_ID\":\n",
    "        ctrl_ptrn = [\"HC\"]\n",
    "    elif ID_col == \"PNI_ID\":\n",
    "        ctrl_ptrn = [\"Pilot\", \"PNC\"]\n",
    "    else:\n",
    "        raise ValueError(\"[group] Error: ID_col must be 'MICS_ID' or 'PNI_ID'\")\n",
    "\n",
    "    \n",
    "    if out_col == \"grp\":\n",
    "        print(\"\\tReturning highlevel grouping to column: \", out_col)\n",
    "       \n",
    "        df.loc[df[ID_col].astype(str).str.contains('|'.join(ctrl_ptrn), na=False), out_col] = 'CTRL'\n",
    "        \n",
    "        # TLE and mTLE: L, left, R, right, unclear\n",
    "        df.loc[\n",
    "            (df[lobe_col].astype(str).str.lower().isin(['tle', 'mtle'])) & \n",
    "            (df[lat_col].astype(str).str.lower().str.contains('l|left|r|right|l>r|r>l|bl|bilateral|unclear', na=False)), \n",
    "            out_col\n",
    "        ] = 'TLE'\n",
    "        \n",
    "        # FLE: L, R, right, unclear\n",
    "        df.loc[\n",
    "            (df[lobe_col] == 'FLE') & \n",
    "            (df[lat_col].astype(str).str.contains('l|r|right|unclear', case=False, na=False)), \n",
    "            out_col\n",
    "        ] = 'FLE'\n",
    "        \n",
    "        # PLE: L, R, right, unclear\n",
    "        df.loc[\n",
    "            ((df[lobe_col] == 'PLE')) &\n",
    "            (df[lat_col].astype(str).str.contains('l|r|right|unclear', case=False, na=False)),\n",
    "            out_col\n",
    "        ] = 'PLE'\n",
    "\n",
    "        # PQLE: L, R, right, unclear\n",
    "        df.loc[\n",
    "            ((df[lobe_col] == 'PQLE')) &\n",
    "            (df[lat_col].astype(str).str.contains('l|r|right|unclear', case=False, na=False)),\n",
    "            out_col\n",
    "        ] = 'PQLE'\n",
    "\n",
    "        # Unclear: L, R, right, unclear\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & (df[lat_col] == 'L'), out_col] = 'UKN'\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & ((df[lat_col] == 'R') | (df[lat_col].astype(str).str.lower() == 'right')), out_col] = 'UKN'\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & (df[lat_col].astype(str).str.contains('unclear', na=False)), out_col] = 'UKN'\n",
    "        \n",
    "        # Multifocal\n",
    "        df.loc[(df[MFCL_col] == 'Multifocal'), out_col] = 'MFCL'\n",
    "    \n",
    "    else:  \n",
    "        print(\"\\tReturning detailed grouping to column: \", out_col) \n",
    "        \n",
    "        df.loc[df[ID_col].astype(str).str.contains('|'.join(ctrl_ptrn), na=False), out_col] = 'CTRL'\n",
    "        \n",
    "        # Combine TLE and mTLE, label as TLE\n",
    "        df.loc[\n",
    "            (df[lobe_col].astype(str).str.lower().isin(['tle', 'mtle'])) & (df[lat_col] == 'L'),\n",
    "            out_col\n",
    "        ] = 'TLE_L'\n",
    "        df.loc[\n",
    "            (df[lobe_col].astype(str).str.lower().isin(['tle', 'mtle'])) & ((df[lat_col] == 'R') | (df[lat_col].astype(str).str.lower() == 'right')),\n",
    "            out_col\n",
    "        ] = 'TLE_R'\n",
    "        df.loc[\n",
    "            (df[lobe_col].astype(str).str.lower().isin(['tle', 'mtle'])) & (df[lat_col].astype(str).str.contains('unclear', na=False)),\n",
    "            out_col\n",
    "        ] = 'TLE_U'\n",
    "\n",
    "        df.loc[(df[lobe_col] == 'FLE') & (df[lat_col] == 'L'), out_col] = 'FLE_L'\n",
    "        df.loc[(df[lobe_col] == 'FLE') & ((df[lat_col] == 'R') | (df[lat_col].astype(str).str.lower() == 'right')), out_col] = 'FLE_R'\n",
    "\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & (df[lat_col] == 'L'), out_col] = 'UKN_L'\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & ((df[lat_col] == 'R') | (df[lat_col].astype(str).str.lower() == 'right')), out_col] = 'UKN_R'\n",
    "        df.loc[(df[lobe_col].astype(str).str.contains('unclear', na=False)) & (df[lat_col].astype(str).str.contains('unclear', na=False)), out_col] = 'UKN_U'\n",
    "        \n",
    "        df.loc[(df[MFCL_col] == 'Multifocal'), out_col] = 'MFCL'\n",
    "        df.loc[(df[lobe_col] == 'TLE') & (df[lat_col] == 'L>R'), out_col] = 'TLE_L'\n",
    "        df.loc[(df[lobe_col] == 'TLE') & (df[lat_col] == 'R>L'), out_col] = 'TLE_R'\n",
    "        df.loc[(df[lobe_col] == 'TLE') & (df[lat_col] == 'BL'), out_col] = 'TLE_BL'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def grpChk(df, grp_cols=['grp', 'grp_detailed']):\n",
    "    \"\"\"\n",
    "    Check that all cases are assigned a group.\n",
    "    If not, print warning\n",
    "\n",
    "    Input:\n",
    "        df: DataFrame to check\n",
    "        grp_col: List of group columns to check\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    for col in grp_cols:\n",
    "        df_missing = df[df[col] == ''][[\"MICS_ID\", \"PNI_ID\", \"SES\", col]]\n",
    "        if not df_missing.empty:\n",
    "            missing.append(df_missing)  # Use append, not extend\n",
    "\n",
    "    if len(missing) > 0:\n",
    "        missing_df = pd.concat(missing)\n",
    "        print(\"[grpChk] The following cases are missing group assignments:\")\n",
    "        print(missing_df[[\"MICS_ID\", \"PNI_ID\", \"SES\", \"grp\", \"grp_detailed\", \n",
    "            \"Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)\", \n",
    "            \"Lateralization of epileptogenic focus\"]])\n",
    "        return False\n",
    "    else:\n",
    "        print(\"[grpChk] All assigned a group\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sheets, save_pth=None, save_name=\"demo\"):\n",
    "    \"\"\"\n",
    "    Run all functions to generate demographic data for 3T-7T participants.\n",
    "\n",
    "    input:\n",
    "        sheets: list of dictionarys with source sheet information (path to sheet, key columns to extract\n",
    "        save_pth: path to save the output demographic file\n",
    "\n",
    "    outputs:\n",
    "        list of IDs with paired 3T-7T data\n",
    "        sheet with each row as separate session and with associated demographic information\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\") # on mac\n",
    "    #sys.path.append(\"/host/verges/tank/data/daniel/\") # on lab computer\n",
    "    from Utils import id, t1\n",
    "    import tTsTGrpUtils as tsutil\n",
    "    \n",
    "    import importlib\n",
    "    importlib.reload(id)\n",
    "    importlib.reload(t1)\n",
    "    importlib.relaod(tsutil)\n",
    "    \n",
    "    out = id.ids3T7T(sheets, save_pth=None) # determine participants with 3T and 7T data\n",
    "    id_cols = out.columns\n",
    "\n",
    "    out = id.id_visits(sheets, out, save_pth=None) # get all sessions for these participants\n",
    "    \n",
    "    print(\"[main] There are \", out['MICS_ID'].nunique(), \"  unique participants and \", out.shape[0], \" rows in datasheet.\")\n",
    "    #out.to_csv(f\"{save_pth}/demo_debug_1-idVisits.csv\", index=False)\n",
    "   \n",
    "    out = t1.demo(sheets, out, save_pth=None) # add demographic info\n",
    "    out.to_csv(f\"{save_pth}/demo_debug_2-demo.csv\", index=False) # debug\n",
    "\n",
    "    out = rmvNADate(out, 'Date') # remove rows with missing scan dates. If only data from one study remains after this removal, then remove participant completely.\n",
    "    print(out.columns)\n",
    "    if 'scanDate' in out.columns:\n",
    "        out = out.drop(columns=['scanDate'])\n",
    "\n",
    "    out = dupSES(out, uniqCols=['MICS_ID', 'PNI_ID', 'study', 'SES'], mergeCols=['Date']) # merge repeated sessions\n",
    "    print(\"[main] After cleaning for missing scan dates, there are \", out['MICS_ID'].nunique(), \" unique participants with a total of \", out.shape[0], \" sessions (3T:\",(out['study'] == '3T').sum(),\", 7T:\", (out['study'] == '7T').sum(),\") in input datasheet.\")\n",
    "    #out.to_csv(f\"{save_pth}/demo_debug_3-rmvNADate.csv\", index=False) # debug\n",
    "    \n",
    "    # save out\n",
    "    if save_pth is not None:\n",
    "        import datetime\n",
    "\n",
    "        save_name_tmp = f\"{save_pth}/ids3T7T_{datetime.datetime.now().strftime('%d%b%Y')}.csv\"\n",
    "        toSave = out[id_cols].drop_duplicates()\n",
    "        toSave.to_csv(save_name_tmp, index=False)\n",
    "        print(\"[main] Saved list of paired ids to: \", save_name_tmp)\n",
    "\n",
    "    dob_col = None\n",
    "    for sheet in sheets: # find DOB from sheet dictionary. If multiple sheets have DOB, use the first one found\n",
    "        if 'DOB' in sheet and sheet['DOB'] is not None:\n",
    "            dob_col = sheet['DOB']\n",
    "            #print(f\"[main] Found DOB column in sheet {sheet['NAME']}: {dob_col}\")\n",
    "            break\n",
    "\n",
    "    if dob_col is None:\n",
    "        print(\"[main] WARNING. No DOB column found in any input sheet. Age will not be computed.\")\n",
    "    \n",
    "    out = tsutil.stdizeNA(out)\n",
    "    out = mergeCols(out)\n",
    "    print(\"[main] Merged columns with the same name. Current columns (sorted): \\n\\t\", sorted(out.columns.tolist(), key=lambda x: x.lower()))\n",
    "\n",
    "    # Fill missing demo variables for each participant, warn if multiple unique values exist\n",
    "    demo_vars = ['dob', 'sex', 'gender', 'handedness', 'ethnicity'] # these demo vars should be key values in the sheet dictionaries\n",
    "    print(\"[main] Filling missing demographic values for variables: \", demo_vars)\n",
    "\n",
    "    for var in demo_vars:\n",
    "        out = carryVals(out, var)\n",
    "\n",
    "    out = t1.dateDif(out, [dob_col, \"Date\"], \"age\", save=False) # compute age\n",
    "    \n",
    "    out = group(out, out_col=\"grp\", ID_col=\"MICS_ID\", save_pth=None) # assign high level groups\n",
    "    out = group(out, out_col=\"grp_detailed\", ID_col=\"MICS_ID\", save_pth=None) # assign detailed groups\n",
    "    # check that all participants assigned a group\n",
    "    grpChk(out, grp_cols=['grp', 'grp_detailed'])\n",
    "\n",
    "    if save_pth is not None:\n",
    "        import datetime\n",
    "\n",
    "        save_name = f\"{save_pth}/{save_name}_{datetime.datetime.now().strftime('%d%b%Y')}.csv\"\n",
    "        out.to_csv(save_name, index=False)\n",
    "        print(\"[main] Saved to: \", save_name)\n",
    "    else:\n",
    "        print(\"[main] WARNING. Not saving demographics sheet to file. To save, please provide a path to save_pth\")\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Make participant demographics sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "\n",
    "# For each sheet, must define NAME, PATH, SHEET, ID_7T, ID_3T. \n",
    "# All other keys are those to be extracted.\n",
    "# The same variables should have the same key names across sheets.\n",
    "\n",
    "PNI = {\n",
    "    'NAME': 'PNI',\n",
    "    'PATH': f'{src_dir}/MICA_PNI_27Aug2025.xlsx', # 7T controls\n",
    "    'SHEET': 'all', # name of sheet in file\n",
    "    'ID_7T': 'ID_PNI', \n",
    "    'ID_3T': 'ID_MICs',\n",
    "    'Ses_7T': 'session',\n",
    "    'Date_7T': 'scanDate',\n",
    "    'study': '7T',\n",
    "    'DOB': 'dob',\n",
    "    'Sex': 'sex',\n",
    "    'Gender': 'gender',\n",
    "    'Hand': 'handedness',\n",
    "    'Eth': 'ethnicity',\n",
    "    'Language': 'language',\n",
    "    'Job': 'employment',\n",
    "    'Edu': 'education',\n",
    "    'LastSz': 'lastSeizure'\n",
    "}\n",
    "\n",
    "MICs = {\n",
    "    'NAME': 'MICs',\n",
    "    'PATH': f'{src_dir}/MICA-MTL-3T_27Aug2025.xlsx', # 3T controls\n",
    "    'SHEET': 'Sheet1', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'Study_name',\n",
    "    'Ses_3T': 'Visit',\n",
    "    'Date_3T': 'Scan_Date (D.M.Y)',\n",
    "    'study': '3T',\n",
    "    'Hand': 'Handed', \n",
    "    'Sex': 'AssignedSex',\n",
    "    'Gender': 'GenderIdentity',\n",
    "    'Height': 'HeightApprox',\n",
    "    'Weight': 'WeightApprox',\n",
    "    'Eth': 'Ethnicity',\n",
    "    'Job': 'Employ',\n",
    "    'Edu': 'YoE',\n",
    "    'LastSz': 'Last seizure'\n",
    "}\n",
    "\n",
    "Clin = {\n",
    "    'NAME': 'Clin',\n",
    "    'PATH': f'{src_dir}/Clinical_27Aug2025.xlsx',\n",
    "    'SHEET': 'clinical-database-detailed', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'participant_id',\n",
    "    'Date_3T': None,\n",
    "    'Gender': 'Gender',\n",
    "    'Hand': 'Handedness',\n",
    "    'Language': 'Language',\n",
    "    'Job': 'Employment',\n",
    "    'Edu': 'Education',\n",
    "    'EpilepsyDxILAE': 'Epilepsy diagnosis based on ILAE',\n",
    "    'EpilepsyClass': 'Epilepsy classification:Focal,Generalized',\n",
    "    'FocusLat': 'Lateralization of epileptogenic focus',\n",
    "    'FocusConfirmed': 'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)',\n",
    "    'EMUDischargeDx': 'Dx at EMU discharge ',\n",
    "    'EMUAdmissionDate': 'EMU admission date(dd-mm-yy)',\n",
    "    'AdmissionDuration': 'Duration of admission',\n",
    "    'EpilepsyRiskFactors': 'Risk factors for epilepsy',\n",
    "    'SeizureOnsetYr': 'Seizure onset (yr)',\n",
    "    'DrugResistant': 'Drug resistant epilepsy at time of EMU admission',\n",
    "    'NumASMsPrior': '# of ASMs prior current EMU admission',\n",
    "    'PrevASMs': 'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission',\n",
    "    'NumASMOnAdmission': '# of ASM on admission',\n",
    "    'ASMsOnAdmission': 'ASMs  on admission (name, doses (mg per day)',\n",
    "    'GeneticTest': 'Genetic test (year,results)',\n",
    "    'FDGPET': 'FDG.PET',\n",
    "    'BaselineMRI': 'Baseline MRI (year,results)',\n",
    "    'InvasiveExplorations': 'Invasive explorations (Y/N)',\n",
    "    'NumSurgicalResections': '# of surgical resection/thermocoagulatin',\n",
    "    'SurgicalResectionDateSite': 'Surgical resection date and site',\n",
    "    'Histopathology': 'Histopatholgy',\n",
    "    'Engel6mo': 'Engel classification (seizure outcomes at the 6 month )',\n",
    "    'Engel1yr': 'Engel classification (seizure outcomes after 1 year from surgical resection)',\n",
    "    'ILAEOutcome1yr': 'ILAE outcome after surgical resection by 1 yr',\n",
    "    'NeuromodDevices': 'Neuromodulation devices'\n",
    "    }\n",
    "\n",
    "\n",
    "sheets = [PNI, MICs, Clin]\n",
    "correspSheets = [PNI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ID_3T7T] Extracting IDs for participants with both 3T and 7T IDs\n",
      "\tLoading: PNI\n",
      "\tSkipping: MICs (missing ID_7T or ID_3T key)\n",
      "\tSkipping: Clin (missing ID_7T or ID_3T key)\n",
      "[id_visits] Extracting visits for IDs in list\n",
      "\tSkipping: Clin (missing Ses_7T and Ses_3T key)\n",
      "\n",
      "\n",
      "\tPNI\n",
      "\t\tExtracting cols: ['ID_MICs', 'ID_PNI', 'scanDate', 'session']\n",
      "\tMICs\n",
      "\t\tExtracting cols: ['Study_name', 'Scan_Date (D.M.Y)', 'Visit']\n",
      "\t\tFinding corresponding ID_7T\n",
      "[main] There are  63   unique participants and  203  rows in datasheet.\n",
      "[demo] Retrieving demographics data.\n",
      "\tOverlapping: ['Sex', 'Gender', 'Hand', 'Eth', 'Language', 'Job', 'Edu', 'LastSz', 'Date_3T']\n",
      "\tPNI\n",
      "\t\tmerge_keys: ['ID_7T', 'ID_3T', 'Ses_7T']\n",
      "\tMICs\n",
      "\t\tmerge_keys: ['ID_3T', 'Ses_3T']\n",
      "\tClin\n",
      "\t\tmerge_keys: ['ID_3T']\n",
      "\tRemoving empty columns: ['YoE', 'WeightApprox', 'AssignedSex', 'Handed', 'Employ', 'Scan_Date (D.M.Y)', 'GenderIdentity', 'HeightApprox', 'Ethnicity'] \n",
      "[rmvNADate] No rows with missing scan dates found.\n",
      "Index(['MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'lastSeizure',\n",
      "       'handedness', 'dob', 'language', 'employment', 'gender', 'sex',\n",
      "       'education', 'ethnicity', 'scanDate', 'Genetic test (year,results)',\n",
      "       'Education', 'ASMs  on admission (name, doses (mg per day)',\n",
      "       'Dx at EMU discharge ', 'ILAE outcome after surgical resection by 1 yr',\n",
      "       'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)',\n",
      "       'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission',\n",
      "       'Employment', 'Seizure onset (yr)', '# of ASM on admission',\n",
      "       'Neuromodulation devices', 'Epilepsy diagnosis based on ILAE',\n",
      "       'Histopatholgy', 'Handedness', 'Duration of admission',\n",
      "       '# of ASMs prior current EMU admission',\n",
      "       'Engel classification (seizure outcomes at the 6 month )',\n",
      "       'Drug resistant epilepsy at time of EMU admission',\n",
      "       'Surgical resection date and site', 'Baseline MRI (year,results)',\n",
      "       'Lateralization of epileptogenic focus', 'Language',\n",
      "       'EMU admission date(dd-mm-yy)',\n",
      "       'Engel classification (seizure outcomes after 1 year from surgical resection)',\n",
      "       'Gender', 'Invasive explorations (Y/N)', 'Risk factors for epilepsy',\n",
      "       'FDG.PET', 'Epilepsy classification:Focal,Generalized'],\n",
      "      dtype='object')\n",
      "[dupSES] WARNING: There are 3 participant-study combinations with repeated rows:\n",
      "\t[HC062=PNC019-7T] ses-a1 (x9): Date=['11.12.2024', '27.02.2025'] -> 11.12.2024 (earliest date)\n",
      "\t[PX071=PNE001-3T] ses-01 (x2): Date=['01.06.2022'] -> 01.06.2022 (unique/no conflict)\n",
      "\t[PX071=PNE001-7T] ses-01 (x4): Date=['01.02.2023', '26.01.2023'] -> 26.01.2023 (earliest date)\n",
      "[main] After cleaning for missing scan dates, there are  63  unique participants with a total of  200  sessions (3T: 94 , 7T: 106 ) in input datasheet.\n",
      "[main] Saved list of paired ids to:  /Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs/ids3T7T_27Aug2025.csv\n",
      "[stdizeNA] Replacing values matching following patterns with standard NA. Patterns: {'', 'missing', 'MISSING', 'na', '?', 'N/A', '-', 'NAN', ' ', 'n/a', 'NULL', '.', 'NaN', 'null', 'NA', '--', 'nan'}\n",
      "\t[PX176=PNE004 study: 7T-sesa1] {Education}: ? --> NaN\n",
      "\t[PX176=PNE004 study: 7T-sesa1] {Employment}: ? --> NaN\n",
      "\t[PX131=PNE040 study: 7T-sesa1] {Education}: missing --> NaN\n",
      "\t[PX131=PNE040 study: 3T-ses01] {Education}: missing --> NaN\n",
      "\t[PX176=PNE004 study: 3T-ses01] {Education}: ? --> NaN\n",
      "\t[PX176=PNE004 study: 3T-ses01] {Employment}: ? --> NaN\n",
      "[stdizeNA] Standardized 6 missing values\n",
      "[mergeCols] Merging columns: ['handedness', 'Handedness'] -> 'handedness' (date/scandate in group: False)\n",
      "[mergeCols] Merging columns: ['language', 'Language'] -> 'language' (date/scandate in group: False)\n",
      "[mergeCols] Merging columns: ['employment', 'Employment'] -> 'employment' (date/scandate in group: False)\n",
      "[mergeCols] Merging columns: ['gender', 'Gender'] -> 'gender' (date/scandate in group: False)\n",
      "[mergeCols] Merging columns: ['education', 'Education'] -> 'education' (date/scandate in group: False)\n",
      "[main] Merged columns with the same name. Current columns (sorted): \n",
      "\t ['# of ASM on admission', '# of ASMs prior current EMU admission', 'ASMs  on admission (name, doses (mg per day)', 'Baseline MRI (year,results)', 'Date', 'dob', 'Drug resistant epilepsy at time of EMU admission', 'Duration of admission', 'Dx at EMU discharge ', 'education', 'employment', 'EMU admission date(dd-mm-yy)', 'Engel classification (seizure outcomes after 1 year from surgical resection)', 'Engel classification (seizure outcomes at the 6 month )', 'Epilepsy classification:Focal,Generalized', 'Epilepsy diagnosis based on ILAE', 'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)', 'ethnicity', 'FDG.PET', 'gender', 'Genetic test (year,results)', 'handedness', 'Histopatholgy', 'ILAE outcome after surgical resection by 1 yr', 'Invasive explorations (Y/N)', 'language', 'lastSeizure', 'Lateralization of epileptogenic focus', 'MICS_ID', 'Neuromodulation devices', 'PNI_ID', 'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission', 'Risk factors for epilepsy', 'Seizure onset (yr)', 'SES', 'sex', 'study', 'Surgical resection date and site']\n",
      "[main] Filling missing demographic values for variables:  ['dob', 'sex', 'gender', 'handedness', 'ethnicity']\n",
      "\t[carryVals] WARNING: [HC130=PNC026 Study: 7T-ses01] gender : F | Woman --> F\n",
      "\t[carryVals] WARNING: [HC140=PNC038 Study: 7T-sesa1] gender : Man | M --> M\n",
      "\t[carryVals] WARNING: [HC152=PNC039 Study: 7T-sesa1] gender : man | M --> M\n",
      "\t[carryVals] WARNING: [PX038=PNE023 Study: 7T-sesa1] gender : Man | M --> M\n",
      "\t[carryVals] WARNING: [PX100=PNE022 Study: 7T-sesa1] gender : Man | M --> M\n",
      "\t[carryVals] WARNING: [PX152=PNE014 Study: 7T-sesa1] gender : M | M (Transgender,AFAB) --> M\n",
      "\t[carryVals] WARNING: [PX223=PNE025 Study: 7T-sesa1] gender : Woman | F --> F\n",
      "\t[carryVals] WARNING: [PX228=PNE035 Study: 7T-sesa1] gender : Man | M --> M\n",
      "\t[carryVals] WARNING: [PX236=PNE034 Study: 7T-sesa1] gender : Woman | F --> F\n",
      "\t[carryVals] WARNING: [PX144=PNE038 Study: 7T-sesa1] handedness : L | R --> L\n",
      "\t[carryVals] WARNING: [PX183=PNE002 Study: 7T-sesa1] handedness : L | R --> L\n",
      "\t[carryVals] WARNING: [HC082=PNC003 Study: 7T-ses01] ethnicity : Japanese  | Japanese --> Japanese\n",
      "\t[carryVals] WARNING: [HC128=PNC025 Study: 7T-sesa1] ethnicity : Chinese | Chlnese --> Chinese\n",
      "[dateDif] Unparseable values in dob: [nan, nan]\n",
      "[dateDif] Column `age` created.\n",
      "[group] Identifying participant groups\n",
      "\tReturning highlevel grouping to column:  grp\n",
      "[group] Identifying participant groups\n",
      "\tReturning detailed grouping to column:  grp_detailed\n",
      "[grpChk] All assigned a group\n",
      "[main] Saved to:  /Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs/demo_27Aug2025.csv\n",
      "\n",
      "\n",
      "====================================\n",
      "No duplicated rows found for ['MICS_ID', 'PNI_ID', 'study', 'SES'].\n",
      "------------------------------------\n",
      "grp_detailed\n",
      "CTRL                                                                                       20\n",
      "TLE_R                                                                                       9\n",
      "TLE_L                                                                                       7\n",
      "FLE_L                                                                                       4\n",
      "UKN_U                                                                                       4\n",
      "FLE_R                                                                                       3\n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                       3\n",
      "TLE_BL                                                                                      3\n",
      "TLE_U                                                                                       2\n",
      "UKN_L                                                                                       2\n",
      "MFCL                                                                                        1\n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                 1\n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal     1\n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                        1\n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                         1\n",
      "UKN_R                                                                                       1\n",
      "Name: MICS_ID, dtype: int64\n",
      "----------------------------------------\n",
      "Total unique cases: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jz/knj2s5ld08xb9qtkljpdcl9r0000gn/T/ipykernel_78804/156988967.py:261: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[var] = df.groupby('MICS_ID')[var].transform(lambda x: x.ffill().bfill())\n",
      "/var/folders/jz/knj2s5ld08xb9qtkljpdcl9r0000gn/T/ipykernel_78804/156988967.py:261: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[var] = df.groupby('MICS_ID')[var].transform(lambda x: x.ffill().bfill())\n",
      "/var/folders/jz/knj2s5ld08xb9qtkljpdcl9r0000gn/T/ipykernel_78804/156988967.py:261: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[var] = df.groupby('MICS_ID')[var].transform(lambda x: x.ffill().bfill())\n",
      "/var/folders/jz/knj2s5ld08xb9qtkljpdcl9r0000gn/T/ipykernel_78804/156988967.py:261: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[var] = df.groupby('MICS_ID')[var].transform(lambda x: x.ffill().bfill())\n"
     ]
    }
   ],
   "source": [
    "save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "demo = main(sheets, save_pth=save_pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "No duplicated rows found for ['MICS_ID', 'PNI_ID', 'study', 'SES'].\n"
     ]
    }
   ],
   "source": [
    "# Duplicate row check\n",
    "\n",
    "print(\"-\"*40)\n",
    "# Find duplicated rows based on MICS_ID, PNI_ID, study, SES\n",
    "dupes = demo.duplicated(subset=['MICS_ID', 'PNI_ID', 'study', 'SES'], keep=False)\n",
    "if dupes.any():\n",
    "    print(\"Duplicated rows based on ['MICS_ID', 'PNI_ID', 'study', 'SES']:\")\n",
    "    display(demo.loc[dupes, ['MICS_ID', 'PNI_ID', 'study', 'SES'] + [col for col in demo.columns if col not in ['MICS_ID', 'PNI_ID', 'study', 'SES']]])\n",
    "else:\n",
    "    print(\"No duplicated rows found for ['MICS_ID', 'PNI_ID', 'study', 'SES'].\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "                                                                                         num_px  \\\n",
      "TOTAL                                                                                        63   \n",
      "CTRL                                                                                         20   \n",
      "TLE_R                                                                                         9   \n",
      "TLE_L                                                                                         7   \n",
      "FLE_L                                                                                         4   \n",
      "UKN_U                                                                                         4   \n",
      "FLE_R                                                                                         3   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                         3   \n",
      "TLE_BL                                                                                        3   \n",
      "TLE_U                                                                                         2   \n",
      "UKN_L                                                                                         2   \n",
      "MFCL                                                                                          1   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                   1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal       1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                          1   \n",
      "UKN_R                                                                                         1   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                           1   \n",
      "\n",
      "                                                                                         num_ses_3T  \\\n",
      "TOTAL                                                                                            94   \n",
      "CTRL                                                                                             38   \n",
      "TLE_R                                                                                            14   \n",
      "TLE_L                                                                                             8   \n",
      "FLE_L                                                                                             5   \n",
      "UKN_U                                                                                             4   \n",
      "FLE_R                                                                                             3   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                             3   \n",
      "TLE_BL                                                                                            3   \n",
      "TLE_U                                                                                             5   \n",
      "UKN_L                                                                                             2   \n",
      "MFCL                                                                                              1   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                       3   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal           1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                              1   \n",
      "UKN_R                                                                                             2   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                               1   \n",
      "\n",
      "                                                                                         num_ses_7T  \\\n",
      "TOTAL                                                                                           106   \n",
      "CTRL                                                                                             58   \n",
      "TLE_R                                                                                             9   \n",
      "TLE_L                                                                                             8   \n",
      "FLE_L                                                                                             5   \n",
      "UKN_U                                                                                             4   \n",
      "FLE_R                                                                                             3   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                             3   \n",
      "TLE_BL                                                                                            5   \n",
      "TLE_U                                                                                             2   \n",
      "UKN_L                                                                                             2   \n",
      "MFCL                                                                                              1   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                       1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal           1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                              1   \n",
      "UKN_R                                                                                             2   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                               1   \n",
      "\n",
      "                                                                                        max_ses_3T  \\\n",
      "TOTAL                                                                                                \n",
      "CTRL                                                                                             4   \n",
      "TLE_R                                                                                            4   \n",
      "TLE_L                                                                                            2   \n",
      "FLE_L                                                                                            2   \n",
      "UKN_U                                                                                            1   \n",
      "FLE_R                                                                                            1   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                            1   \n",
      "TLE_BL                                                                                           1   \n",
      "TLE_U                                                                                            4   \n",
      "UKN_L                                                                                            1   \n",
      "MFCL                                                                                             1   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                      3   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal          1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                             1   \n",
      "UKN_R                                                                                            2   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                              1   \n",
      "\n",
      "                                                                                        max_ses_7T  \\\n",
      "TOTAL                                                                                                \n",
      "CTRL                                                                                             6   \n",
      "TLE_R                                                                                            1   \n",
      "TLE_L                                                                                            2   \n",
      "FLE_L                                                                                            2   \n",
      "UKN_U                                                                                            1   \n",
      "FLE_R                                                                                            1   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                            1   \n",
      "TLE_BL                                                                                           2   \n",
      "TLE_U                                                                                            1   \n",
      "UKN_L                                                                                            1   \n",
      "MFCL                                                                                             1   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                      1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal          1   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                             1   \n",
      "UKN_R                                                                                            2   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                              1   \n",
      "\n",
      "                                                                                        median_ses_3T  \\\n",
      "TOTAL                                                                                                   \n",
      "CTRL                                                                                              2.0   \n",
      "TLE_R                                                                                             1.0   \n",
      "TLE_L                                                                                             1.0   \n",
      "FLE_L                                                                                             1.0   \n",
      "UKN_U                                                                                             1.0   \n",
      "FLE_R                                                                                             1.0   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                             1.0   \n",
      "TLE_BL                                                                                            1.0   \n",
      "TLE_U                                                                                             2.5   \n",
      "UKN_L                                                                                             1.0   \n",
      "MFCL                                                                                              1.0   \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                       3.0   \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal           1.0   \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                              1.0   \n",
      "UKN_R                                                                                             2.0   \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                               1.0   \n",
      "\n",
      "                                                                                        median_ses_7T  \n",
      "TOTAL                                                                                                  \n",
      "CTRL                                                                                              3.0  \n",
      "TLE_R                                                                                             1.0  \n",
      "TLE_L                                                                                             1.0  \n",
      "FLE_L                                                                                             1.0  \n",
      "UKN_U                                                                                             1.0  \n",
      "FLE_R                                                                                             1.0  \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal                                             1.0  \n",
      "TLE_BL                                                                                            2.0  \n",
      "TLE_U                                                                                             1.0  \n",
      "UKN_L                                                                                             1.0  \n",
      "MFCL                                                                                              1.0  \n",
      "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized                                       1.0  \n",
      "PATTERN NOT RECOGNIZED: lobe=PLE, lat=Lateralization of epileptogenic focus, MFCL=Focal           1.0  \n",
      "PATTERN NOT RECOGNIZED: lobe=PQLE, lat=R, MFCL=Focal                                              1.0  \n",
      "UKN_R                                                                                             2.0  \n",
      "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan                                               1.0  \n",
      "Saved participant summary to /Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs/pxSummary_3T7T_28Aug2025.csv\n"
     ]
    }
   ],
   "source": [
    "# Calculate max and median number of sessions per participant for each group and study\n",
    "def max_sessions(df, group, study):\n",
    "    subset = df[(df[grp_ofInterest] == group) & (df['study'] == study)]\n",
    "    if subset.empty:\n",
    "        return 0\n",
    "    return subset.groupby('MICS_ID').size().max()\n",
    "\n",
    "def median_sessions(df, group, study):\n",
    "    subset = df[(df[grp_ofInterest] == group) & (df['study'] == study)]\n",
    "    if subset.empty:\n",
    "        return 0\n",
    "    return subset.groupby('MICS_ID').size().median()\n",
    "\n",
    "# Num of participants by group\n",
    "grp_ofInterest = 'grp_detailed'\n",
    "print(\"-\"*40)\n",
    "# Show number of unique participants per detailed group\n",
    "# Calculate unique participants, number of 3T sessions, and number of 7T sessions per group\n",
    "group_summary = (\n",
    "    demo.groupby(grp_ofInterest)\n",
    "    .agg(\n",
    "        num_px=('MICS_ID', 'nunique'),\n",
    "        num_ses_3T=('study', lambda x: ((x == '3T')).sum()),\n",
    "        num_ses_7T=('study', lambda x: ((x == '7T')).sum()),\n",
    "    )\n",
    ")\n",
    "\n",
    "group_summary['max_ses_3T'] = group_summary.index.map(lambda g: max_sessions(demo, g, '3T'))\n",
    "group_summary['max_ses_7T'] = group_summary.index.map(lambda g: max_sessions(demo, g, '7T'))\n",
    "group_summary['median_ses_3T'] = group_summary.index.map(lambda g: median_sessions(demo, g, '3T'))\n",
    "group_summary['median_ses_7T'] = group_summary.index.map(lambda g: median_sessions(demo, g, '7T'))\n",
    "# Add a total row at the end with sums for participant/session counts, leave median/max empty\n",
    "total_row = {\n",
    "    'num_px': group_summary['num_px'].sum(),\n",
    "    'num_ses_3T': group_summary['num_ses_3T'].sum(),\n",
    "    'num_ses_7T': group_summary['num_ses_7T'].sum(),\n",
    "    'max_ses_3T': '',\n",
    "    'max_ses_7T': '',\n",
    "    'median_ses_3T': '',\n",
    "    'median_ses_7T': ''\n",
    "}\n",
    "\n",
    "group_summary = pd.concat([group_summary, pd.DataFrame([total_row], index=['TOTAL'])])\n",
    "\n",
    "group_summary = group_summary.sort_values('num_px', ascending=False)\n",
    "print(group_summary)\n",
    "# save to csv\n",
    "\n",
    "output_csv = os.path.join(save_pth, f\"pxSummary_3T7T_{pd.Timestamp.now().strftime('%d%b%Y')}.csv\")\n",
    "print(f\"Saved participant summary to {output_csv}\")\n",
    "group_summary.to_csv(output_csv, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get summary statistics by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grp\n",
       "TLE                                                            21\n",
       "CTRL                                                           20\n",
       "FLE                                                             7\n",
       "UKN                                                             7\n",
       "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=Focal           3\n",
       "MFCL                                                            1\n",
       "PATTERN NOT RECOGNIZED: lobe=IGE, lat=IGE, MFCL=Generalized     1\n",
       "PATTERN NOT RECOGNIZED: lobe=nan, lat=nan, MFCL=nan             1\n",
       "PLE                                                             1\n",
       "PQLE                                                            1\n",
       "Name: MICS_ID, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number per group, median age, number of 3T and 7T sessions in each group\n",
    "#demo['grp'].value_counts()\n",
    "# count unique participants per group\n",
    "demo.groupby('grp')['MICS_ID'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MICS_ID</th>\n",
       "      <th>PNI_ID</th>\n",
       "      <th>SES</th>\n",
       "      <th>grp</th>\n",
       "      <th>grp_detailed</th>\n",
       "      <th>Lateralization of epileptogenic focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>PX153</td>\n",
       "      <td>PNE009</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>PX153</td>\n",
       "      <td>PNE009</td>\n",
       "      <td>a2</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>PX153</td>\n",
       "      <td>PNE009</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>PX176</td>\n",
       "      <td>PNE004</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>PX176</td>\n",
       "      <td>PNE004</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>PX200</td>\n",
       "      <td>PNE015</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>PX200</td>\n",
       "      <td>PNE015</td>\n",
       "      <td>a2</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>PX200</td>\n",
       "      <td>PNE015</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_BL</td>\n",
       "      <td>BL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>PX168</td>\n",
       "      <td>PNE010</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>PX168</td>\n",
       "      <td>PNE010</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>PX174</td>\n",
       "      <td>PNE017</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>PX174</td>\n",
       "      <td>PNE017</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>PX174</td>\n",
       "      <td>PNE017</td>\n",
       "      <td>02</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PX189</td>\n",
       "      <td>PNE012</td>\n",
       "      <td>a2</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>PX189</td>\n",
       "      <td>PNE012</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>PX189</td>\n",
       "      <td>PNE012</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>PX198</td>\n",
       "      <td>PNE018</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>PX198</td>\n",
       "      <td>PNE018</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>PX204</td>\n",
       "      <td>PNE019</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>PX204</td>\n",
       "      <td>PNE019</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>PX229</td>\n",
       "      <td>PNE030</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>PX229</td>\n",
       "      <td>PNE030</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_L</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PX043</td>\n",
       "      <td>PNE031</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>PX043</td>\n",
       "      <td>PNE031</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>PX043</td>\n",
       "      <td>PNE031</td>\n",
       "      <td>02</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>PX050</td>\n",
       "      <td>PNE029</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>PX050</td>\n",
       "      <td>PNE029</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>PX050</td>\n",
       "      <td>PNE029</td>\n",
       "      <td>02</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>PX050</td>\n",
       "      <td>PNE029</td>\n",
       "      <td>03</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>PX050</td>\n",
       "      <td>PNE029</td>\n",
       "      <td>04</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PX144</td>\n",
       "      <td>PNE038</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>PX144</td>\n",
       "      <td>PNE038</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>PX144</td>\n",
       "      <td>PNE038</td>\n",
       "      <td>02</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>PX148</td>\n",
       "      <td>PNE013</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>PX148</td>\n",
       "      <td>PNE013</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PX173</td>\n",
       "      <td>PNE006</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>PX173</td>\n",
       "      <td>PNE006</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>PX216</td>\n",
       "      <td>PNE021</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>PX216</td>\n",
       "      <td>PNE021</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>PX224</td>\n",
       "      <td>PNE024</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>PX224</td>\n",
       "      <td>PNE024</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PX225</td>\n",
       "      <td>PNE025</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>PX225</td>\n",
       "      <td>PNE025</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>PX071</td>\n",
       "      <td>PNE001</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>PX071</td>\n",
       "      <td>PNE001</td>\n",
       "      <td>02</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>PX071</td>\n",
       "      <td>PNE001</td>\n",
       "      <td>03</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>PX071</td>\n",
       "      <td>PNE001</td>\n",
       "      <td>04</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>PX190</td>\n",
       "      <td>PNE011</td>\n",
       "      <td>a1</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>PX190</td>\n",
       "      <td>PNE011</td>\n",
       "      <td>01</td>\n",
       "      <td>TLE</td>\n",
       "      <td>TLE_U</td>\n",
       "      <td>unclear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MICS_ID  PNI_ID SES  grp grp_detailed  \\\n",
       "63    PX153  PNE009  a1  TLE       TLE_BL   \n",
       "64    PX153  PNE009  a2  TLE       TLE_BL   \n",
       "141   PX153  PNE009  01  TLE       TLE_BL   \n",
       "57    PX176  PNE004  a1  TLE       TLE_BL   \n",
       "151   PX176  PNE004  01  TLE       TLE_BL   \n",
       "72    PX200  PNE015  a1  TLE       TLE_BL   \n",
       "94    PX200  PNE015  a2  TLE       TLE_BL   \n",
       "160   PX200  PNE015  01  TLE       TLE_BL   \n",
       "65    PX168  PNE010  a1  TLE        TLE_L   \n",
       "146   PX168  PNE010  01  TLE        TLE_L   \n",
       "74    PX174  PNE017  a1  TLE        TLE_L   \n",
       "149   PX174  PNE017  01  TLE        TLE_L   \n",
       "186   PX174  PNE017  02  TLE        TLE_L   \n",
       "67    PX189  PNE012  a2  TLE        TLE_L   \n",
       "68    PX189  PNE012  a1  TLE        TLE_L   \n",
       "154   PX189  PNE012  01  TLE        TLE_L   \n",
       "75    PX198  PNE018  a1  TLE        TLE_L   \n",
       "158   PX198  PNE018  01  TLE        TLE_L   \n",
       "76    PX204  PNE019  a1  TLE        TLE_L   \n",
       "161   PX204  PNE019  01  TLE        TLE_L   \n",
       "86    PX229  PNE030  a1  TLE        TLE_L   \n",
       "179   PX229  PNE030  01  TLE        TLE_L   \n",
       "87    PX043  PNE031  a1  TLE        TLE_R   \n",
       "105   PX043  PNE031  01  TLE        TLE_R   \n",
       "128   PX043  PNE031  02  TLE        TLE_R   \n",
       "84    PX050  PNE029  a1  TLE        TLE_R   \n",
       "106   PX050  PNE029  01  TLE        TLE_R   \n",
       "109   PX050  PNE029  02  TLE        TLE_R   \n",
       "123   PX050  PNE029  03  TLE        TLE_R   \n",
       "135   PX050  PNE029  04  TLE        TLE_R   \n",
       "95    PX144  PNE038  a1  TLE        TLE_R   \n",
       "138   PX144  PNE038  01  TLE        TLE_R   \n",
       "168   PX144  PNE038  02  TLE        TLE_R   \n",
       "69    PX148  PNE013  a1  TLE        TLE_R   \n",
       "139   PX148  PNE013  01  TLE        TLE_R   \n",
       "59    PX173  PNE006  a1  TLE        TLE_R   \n",
       "148   PX173  PNE006  01  TLE        TLE_R   \n",
       "78    PX216  PNE021  a1  TLE        TLE_R   \n",
       "167   PX216  PNE021  01  TLE        TLE_R   \n",
       "80    PX224  PNE024  a1  TLE        TLE_R   \n",
       "174   PX224  PNE024  01  TLE        TLE_R   \n",
       "81    PX225  PNE025  a1  TLE        TLE_R   \n",
       "175   PX225  PNE025  01  TLE        TLE_R   \n",
       "51    PX071  PNE001  01  TLE        TLE_U   \n",
       "125   PX071  PNE001  02  TLE        TLE_U   \n",
       "126   PX071  PNE001  03  TLE        TLE_U   \n",
       "131   PX071  PNE001  04  TLE        TLE_U   \n",
       "66    PX190  PNE011  a1  TLE        TLE_U   \n",
       "155   PX190  PNE011  01  TLE        TLE_U   \n",
       "\n",
       "    Lateralization of epileptogenic focus  \n",
       "63                                     BL  \n",
       "64                                     BL  \n",
       "141                                    BL  \n",
       "57                                     BL  \n",
       "151                                    BL  \n",
       "72                                     BL  \n",
       "94                                     BL  \n",
       "160                                    BL  \n",
       "65                                      L  \n",
       "146                                     L  \n",
       "74                                      L  \n",
       "149                                     L  \n",
       "186                                     L  \n",
       "67                                      L  \n",
       "68                                      L  \n",
       "154                                     L  \n",
       "75                                      L  \n",
       "158                                     L  \n",
       "76                                      L  \n",
       "161                                     L  \n",
       "86                                      L  \n",
       "179                                     L  \n",
       "87                                      R  \n",
       "105                                     R  \n",
       "128                                     R  \n",
       "84                                      R  \n",
       "106                                     R  \n",
       "109                                     R  \n",
       "123                                     R  \n",
       "135                                     R  \n",
       "95                                      R  \n",
       "138                                     R  \n",
       "168                                     R  \n",
       "69                                      R  \n",
       "139                                     R  \n",
       "59                                      R  \n",
       "148                                     R  \n",
       "78                                  right  \n",
       "167                                 right  \n",
       "80                                      R  \n",
       "174                                     R  \n",
       "81                                      R  \n",
       "175                                     R  \n",
       "51                                unclear  \n",
       "125                               unclear  \n",
       "126                               unclear  \n",
       "131                               unclear  \n",
       "66                               unclear   \n",
       "155                              unclear   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all grp=TLE with laterlaization\n",
    "demo[demo['grp'] == 'TLE'][['MICS_ID', 'PNI_ID', 'SES', 'grp', 'grp_detailed', 'Lateralization of epileptogenic focus']].drop_duplicates().sort_values(['grp', 'grp_detailed', 'MICS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grp</th>\n",
       "      <th>study</th>\n",
       "      <th>SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td></td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td></td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>3T</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>3T</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>3T</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CTRL</td>\n",
       "      <td>7T</td>\n",
       "      <td>a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>FLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>FLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>FLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>MFCL</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>MFCL</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>PLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>PLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>PQLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>PQLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>TLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>TLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>TLE</td>\n",
       "      <td>3T</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>TLE</td>\n",
       "      <td>7T</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>UKN</td>\n",
       "      <td>3T</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>UKN</td>\n",
       "      <td>3T</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>UKN</td>\n",
       "      <td>7T</td>\n",
       "      <td>a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>UKN</td>\n",
       "      <td>7T</td>\n",
       "      <td>a2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      grp study SES\n",
       "178          3T  01\n",
       "90           7T  a1\n",
       "101  CTRL    3T  01\n",
       "104  CTRL    3T  02\n",
       "115  CTRL    3T  03\n",
       "170  CTRL    3T  04\n",
       "1    CTRL    7T  01\n",
       "3    CTRL    7T  02\n",
       "2    CTRL    7T  03\n",
       "4    CTRL    7T  04\n",
       "0    CTRL    7T  05\n",
       "14   CTRL    7T  a1\n",
       "33   CTRL    7T  a2\n",
       "36   CTRL    7T  a3\n",
       "130   FLE    3T  01\n",
       "56    FLE    7T  a1\n",
       "61    FLE    7T  a2\n",
       "152  MFCL    3T  01\n",
       "55   MFCL    7T  a1\n",
       "173   PLE    3T  01\n",
       "92    PLE    7T  a1\n",
       "102  PQLE    3T  01\n",
       "79   PQLE    7T  a1\n",
       "105   TLE    3T  01\n",
       "109   TLE    3T  02\n",
       "123   TLE    3T  03\n",
       "131   TLE    3T  04\n",
       "51    TLE    7T  01\n",
       "57    TLE    7T  a1\n",
       "64    TLE    7T  a2\n",
       "140   UKN    3T  01\n",
       "176   UKN    3T  02\n",
       "58    UKN    7T  a1\n",
       "71    UKN    7T  a2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo[['grp', 'study', 'SES']].drop_duplicates().sort_values(['grp', 'study', 'SES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grp   study\n",
       "CTRL  3T       28.284736\n",
       "      7T       28.861054\n",
       "FLE   3T       33.519507\n",
       "      7T       28.969199\n",
       "MFCL  3T       34.135524\n",
       "      7T       34.214921\n",
       "TLE   3T       30.970568\n",
       "      7T       30.781656\n",
       "UKN   3T       31.735797\n",
       "      7T       31.786448\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get median age per study in each group\n",
    "demo.groupby(['grp', 'study'])['age'].median().sort_index(level='grp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'grp_highLvl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'grp_highLvl'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     33\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 35\u001b[0m plot_histogram(demo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrp_highLvl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Distribution by Group\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mplot_histogram\u001b[0;34m(data, group_col, age_col, title)\u001b[0m\n\u001b[1;32m     19\u001b[0m ages \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data[age_col], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Overlay histograms for each group\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m groups \u001b[38;5;241m=\u001b[39m data[group_col]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grp \u001b[38;5;129;01min\u001b[39;00m groups:\n\u001b[1;32m     24\u001b[0m     subset \u001b[38;5;241m=\u001b[39m data[data[group_col] \u001b[38;5;241m==\u001b[39m grp]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'grp_highLvl'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show histograms for each group\n",
    "\n",
    "def plot_histogram(data, group_col, age_col, title):\n",
    "    \"\"\"\n",
    "    Overlay histograms of age distribution for each group in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing the data.\n",
    "    group_col (str): Column name for the group classification.\n",
    "    age_col (str): Column name for the age values.\n",
    "    title (str): Title for the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Convert age column to numeric, coerce errors to NaN\n",
    "    ages = pd.to_numeric(data[age_col], errors='coerce')\n",
    "\n",
    "    # Overlay histograms for each group\n",
    "    groups = data[group_col].unique()\n",
    "    for grp in groups:\n",
    "        subset = data[data[group_col] == grp]\n",
    "        age_vals = pd.to_numeric(subset[age_col], errors='coerce').dropna()\n",
    "        plt.hist(age_vals, bins=10, alpha=0.5, label=grp)\n",
    "\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_histogram(demo, 'grp_highLvl', 'age', 'Age Distribution by Group')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/demo_23May2025.csv\"\n",
    "df = pd.read_csv(df_pth, dtype=str)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'handedness', 'education', 'gender', 'ethnicity', 'employment', 'sex', 'age', 'grp', 'Lateralization of epileptogenic focus', 'Dx at EMU discharge ', 'grp_detailed']\n",
    "df_short = df[columns_to_keep]\n",
    "print(df_short.shape)\n",
    "df_short['age'] = pd.to_numeric(df_short['age'], errors='coerce')\n",
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print rows for HC154\n",
    "df_short[df_short['MICS_ID'] == 'HC154']\n",
    "# remove rows with MICS_ID == 'HC154'\n",
    "df_short = df_short[df_short['MICS_ID'] != 'HC154']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for repeated rows, values in columns other than Date, age and study should be the same. If NaN then replace with the first non-NaN value in the group\n",
    "df_short = (\n",
    "    df_short.groupby('MICS_ID', group_keys=False)\n",
    "    .apply(lambda x: x.ffill().bfill())\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_short = df_short.infer_objects(copy=False)\n",
    "\n",
    "# keep most recent session only (via Date column)\n",
    "df_3T = df_short[df_short['study'] == '3T']\n",
    "df_3T = df_3T.sort_values(by='Date').drop_duplicates(subset='MICS_ID', keep='last')\n",
    "df_3T = df_3T.reset_index(drop=True)\n",
    "df_3T = df_3T.sort_values(by='MICS_ID')\n",
    "\n",
    "\n",
    "df_7T = df_short[df_short['study'] == '7T']\n",
    "df_7T = df_7T.sort_values(by='Date').drop_duplicates(subset='MICS_ID', keep='last')\n",
    "df_7T = df_7T.reset_index(drop=True)\n",
    "df_7T = df_7T.sort_values(by='MICS_ID')\n",
    "\n",
    "print(f\"3T shape: {df_3T.shape}\")\n",
    "print(f\"7T shape: {df_7T.shape}\")\n",
    "print(f\"Unique MICS_IDs in 3T: {df_3T['MICS_ID'].nunique()} (IDs: {df_3T['MICS_ID'].unique()})\")\n",
    "print(f\"Unique MICS_IDs in 7T: {df_7T['MICS_ID'].nunique()} (IDs: {df_7T['MICS_ID'].unique()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.concat([df_3T, df_7T], ignore_index=True)\n",
    "df_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute date difference between 3T and 7T scans by individual\n",
    "df_clean['Date'] = pd.to_datetime(df_clean['Date'], errors='coerce')\n",
    "df_clean['Time between scans (mths)'] = np.nan\n",
    "# for each unique MICS_ID, compute the difference between the 3T and 7T dates. Return this value to both rows\n",
    "for mics_id in df_clean['MICS_ID'].unique():\n",
    "    dates = df_clean[df_clean['MICS_ID'] == mics_id]['Date']\n",
    "    \n",
    "    date_diff_months = abs((dates.max() - dates.min()).days / 30.44)  # average days per month, absolute value\n",
    "    df_clean.loc[df_clean['MICS_ID'] == mics_id, 'Time between scans (mths)'] = date_diff_months\n",
    "\n",
    "df_clean.sort_values(by='MICS_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make histogram of time between scans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_clean['Time between scans (mths)'].dropna(), bins=30, kde=True)\n",
    "plt.title('Time Between 3T and 7T Scans')\n",
    "\n",
    "mean_val = df_clean['Time between scans (mths)'].mean()\n",
    "median_val = df_clean['Time between scans (mths)'].median()\n",
    "\n",
    "plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "plt.axvline(median_val, color='green', linestyle='-.', label=f'Median: {median_val:.2f}')\n",
    "\n",
    "plt.xlabel('Time (months)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(df, stat='mdn', grp='grp', age='age', sex='sex', scan_dif='Time between scans (mths)', edu='education', eth='ethnicity', hand='handedness'):\n",
    "    \"\"\"\n",
    "    Create a summary statistics table for the given DataFrame.\n",
    "    \"\"\"\n",
    "    table = pd.DataFrame(columns=df[grp].unique())\n",
    "\n",
    "    grp_values = list(df[grp].unique()) + ['ALL PX']\n",
    "    for grp_value in grp_values:\n",
    "        if grp_value == 'ALL PX':\n",
    "            sub_df = df[df[grp] != 'CTRL'].copy()\n",
    "        else:\n",
    "            sub_df = df[df[grp] == grp_value].copy()\n",
    "\n",
    "        # counts\n",
    "        n_individuals = sub_df['MICS_ID'].nunique()\n",
    "        table.loc['n', grp_value] = n_individuals\n",
    "\n",
    "        # Ensure numeric for stats\n",
    "        sub_df[age] = pd.to_numeric(sub_df[age], errors='coerce')\n",
    "        sub_df[scan_dif] = pd.to_numeric(sub_df[scan_dif], errors='coerce')\n",
    "\n",
    "        # Numerical: age (per study)\n",
    "        for study in sub_df['study'].unique():\n",
    "            study_mask = sub_df['study'] == study\n",
    "            if stat == 'mdn':\n",
    "                age_mdn = sub_df.loc[study_mask, age].median()\n",
    "                age_iqr = sub_df.loc[study_mask, age].quantile(0.75) - sub_df.loc[study_mask, age].quantile(0.25)\n",
    "                row_label = f'age_{study} (mdn (IQR))'\n",
    "                table.loc[row_label, grp_value] = f\"{age_mdn:.1f} ({age_iqr:.1f})\"\n",
    "            elif stat == 'mean':\n",
    "                age_mean = sub_df.loc[study_mask, age].mean()\n",
    "                age_std = sub_df.loc[study_mask, age].std()\n",
    "                row_label = f'age_{study} (mean (std))'\n",
    "                table.loc[row_label, grp_value] = f\"{age_mean:.1f} ({age_std:.0f})\"\n",
    "\n",
    "        # remove repeated rows based on MICS_ID\n",
    "        sub_df = sub_df.drop_duplicates(subset='MICS_ID')\n",
    "\n",
    "        # Numerical: Time between scans (mths)\n",
    "        if stat == 'mdn':\n",
    "            tbs_mdn = sub_df[scan_dif].median()\n",
    "            tbs_iqr = sub_df[scan_dif].quantile(0.75) - sub_df[scan_dif].quantile(0.25)\n",
    "            row_label = 'Time between scans (mths) (mdn (IQR))'\n",
    "            table.loc[row_label, grp_value] = f\"{tbs_mdn:.1f} ({tbs_iqr:.1f})\"\n",
    "        elif stat == 'mean':\n",
    "            tbs_mean = sub_df[scan_dif].mean()\n",
    "            tbs_std = sub_df[scan_dif].std()\n",
    "            row_label = 'Time between scans (mths) (mean (std))'\n",
    "            table.loc[row_label, grp_value] = f\"{tbs_mean:.1f} ({tbs_std:.1f})\"\n",
    "\n",
    "        # Cat: sex\n",
    "        sub_df.loc[:, sex] = sub_df[sex].str.lower().map({'f': 'female', 'm': 'male'})\n",
    "        n_females = (sub_df[sex] == 'female').sum()\n",
    "        n_males = (sub_df[sex] == 'male').sum()\n",
    "        n_total = sub_df[sex].notna().sum()\n",
    "        pct_females = (n_females / n_total * 100) if n_total > 0 else 0\n",
    "        row_label = 'sex (F:M (% F))'\n",
    "        row_label_count = 'sex (F:M (%F))'\n",
    "        table.loc[row_label_count, grp_value] = f\"{n_females}:{n_males} ({pct_females:.0f}%)\"\n",
    "\n",
    "        # Cat: education\n",
    "        edu_counts = sub_df[edu].value_counts(dropna=False)\n",
    "        edu_str = ', '.join([f\"{k}:{v}\" for k, v in edu_counts.items()])\n",
    "        row_label = 'education (count)'\n",
    "        table.loc[row_label, grp_value] = edu_str\n",
    "\n",
    "        # Cat: Handedness\n",
    "        hand_counts = sub_df[hand].value_counts(dropna=False)\n",
    "        n_left = hand_counts.get('L', 0)\n",
    "        n_right = hand_counts.get('R', 0)\n",
    "        hand_str = f\"{n_left}:{n_right}\"\n",
    "        row_label = 'handedness (L:R)'\n",
    "        table.loc[row_label, grp_value] = hand_str\n",
    "\n",
    "        # Cat: lateralization of epileptogenic focus\n",
    "        if grp_value != 'CTRL':\n",
    "            lat_counts = sub_df['Lateralization of epileptogenic focus'].value_counts(dropna=False)\n",
    "            n_tot = lat_counts.sum()\n",
    "            # Report as L:R:unknown\n",
    "            n_left = lat_counts.get('L', 0)\n",
    "            n_left += lat_counts.get('L ', 0)  # Handle trailing space\n",
    "            n_right = lat_counts.get('R', 0)\n",
    "            n_right += lat_counts.get('R ', 0)  # Handle trailing space\n",
    "            n_right += lat_counts.get('right', 0)  # Handle 'right' case\n",
    "            n_left += lat_counts.get('left', 0)  # Handle 'left' case\n",
    "            # Count L>R or R>L and add to L or R accordingly\n",
    "            n_unclear = lat_counts.get('unclear', 0)\n",
    "            n_unclear += lat_counts.get('unclear ', 0)\n",
    "            \n",
    "            print(f\"Tot: {n_tot}, sum: {n_left + n_right + n_unclear}\")\n",
    "            \n",
    "            if n_left + n_right + n_unclear != n_tot:\n",
    "                print(f\"\\t {n_left + n_right + n_unclear} != {n_tot} for {grp_value}\")\n",
    "                n_bl = lat_counts.get('BL', 0)\n",
    "\n",
    "                if n_bl > 0:\n",
    "                    print(\"BL found in Lateralization of epileptogenic focus\")\n",
    "                    print(f\"R, L counts: {n_right}, {n_left}\")\n",
    "                    # Subset rows with 'BL' in 'Lateralization of epileptogenic focus'\n",
    "                    bl_rows = sub_df[sub_df['Lateralization of epileptogenic focus'] == 'BL']\n",
    "                    # Search 'Dx at EMU discharge ' for 'L>' or 'R>' and add to counts\n",
    "                    n_bl_l = bl_rows['Dx at EMU discharge '].astype(str).str.contains('L>').sum()\n",
    "                    n_bl_r = bl_rows['Dx at EMU discharge '].astype(str).str.contains('R>').sum()\n",
    "                    n_left += n_bl_l\n",
    "                    n_right += n_bl_r\n",
    "                    # Count all other BL cases that are not clearly L> or R>\n",
    "                    n_bl_u = n_bl - (n_bl_l + n_bl_r)\n",
    "                    print(f\"R, L counts: {n_right}, {n_left}\")\n",
    "            else:\n",
    "                n_bl_u = 0\n",
    "\n",
    "            lat_str = f\"{n_left}:{n_right}:{n_bl_u}:{n_unclear}\"\n",
    "        \n",
    "        else:\n",
    "            lat_str = ''\n",
    "        \n",
    "        row_label = 'Lateralization (L:R:BL (unclear dominance):unclear)'\n",
    "        table.loc[row_label, grp_value] = lat_str\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = make_table(df_clean, stat='mean', grp='grp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "t1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
