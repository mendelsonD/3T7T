{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463a8c95",
   "metadata": {},
   "source": [
    "# Get demographics and paths to smoothed maps from sources\n",
    "(steps common to between study and between session comparisons)\n",
    "1. DEMOGRAPHICS  \n",
    "    - Identify IDs with 3T and 7T    \n",
    "    - Extract clinical information for epilepsy patients\n",
    "    - Extract demographic information for all participants\n",
    "2. PATHS TO MAPS\n",
    "    - Smooth maps is necessary, save paths in a master demographics file\n",
    "    - Create a df specifying the errors encountered with map creation/availability\n",
    "3. CLEAN\n",
    "    - Drop NA rows\n",
    "    - Apply QC\n",
    "    - Ensure each participant has data for both studies\n",
    "\n",
    "Note. Do not select sessions at this point. This can vary by nature of analyses and should therefore occur in the analysis file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1372f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import utils_demo as ud\n",
    "import tTsTGrpUtils as tsutil\n",
    "from genUtils import id, gen, t1\n",
    "\n",
    "\n",
    "lab = True\n",
    "save = True\n",
    "verbose = True\n",
    "toPrint = True\n",
    "\n",
    "test = False\n",
    "test_frac = 0.1 # fraction of demo to use for testing if test=True\n",
    "\n",
    "includeBL = False # if should include bilateral TLE patients (with one side higher than other) in analyses\n",
    "\n",
    "if lab: # define root paths to source files\n",
    "    src_dir = \"/host/verges/tank/data/daniel/3T7T/z/data/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "    if save:\n",
    "        save_pth = save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs\"\n",
    "else:\n",
    "    src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "    if save:\n",
    "        save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0aa1bd",
   "metadata": {},
   "source": [
    "# 1. Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b23ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifications\n",
    "\n",
    "PNI = {\n",
    "    'NAME': 'PNI',\n",
    "    'PATH': f'{src_dir}/MICA_PNI_06Oct2025.xlsx', # 7T controls\n",
    "    'SHEET': 'all', # name of sheet in file\n",
    "    'ID_7T': 'ID_PNI', \n",
    "    'ID_3T': 'ID_MICs',\n",
    "    'Ses_7T': 'session',\n",
    "    'Date_7T': 'scanDate',\n",
    "    'study': '7T',\n",
    "    'DOB': 'dob',\n",
    "    'Sex': 'sex',\n",
    "    'Gender': 'gender',\n",
    "    'Hand': 'handedness',\n",
    "    'Eth': 'ethnicity',\n",
    "    'Language': 'language',\n",
    "    'Job': 'employment',\n",
    "    'Edu': 'education',\n",
    "    'LastSz': 'lastSeizure',\n",
    "}\n",
    "\n",
    "MICs = {\n",
    "    'NAME': 'MICs',\n",
    "    'PATH': f'{src_dir}/MICA-MTL-3T_06Oct2025.xlsx', # 3T controls\n",
    "    'SHEET': 'Sheet1', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'Study_name',\n",
    "    'Ses_3T': 'Visit',\n",
    "    'Date_3T': 'Scan_Date (D.M.Y)',\n",
    "    'study': '3T',\n",
    "    'Hand': 'Handed', \n",
    "    'Sex': 'AssignedSex',\n",
    "    'Gender': 'GenderIdentity',\n",
    "    'Height': 'HeightApprox',\n",
    "    'Weight': 'WeightApprox',\n",
    "    'Eth': 'Ethnicity',\n",
    "    'Job': 'Employ',\n",
    "    'Edu': 'YoE',\n",
    "    'LastSz': 'Last seizure'\n",
    "}\n",
    "\n",
    "Clin = {\n",
    "    'NAME': 'Clin',\n",
    "    'PATH': f'{src_dir}/Clinical_06Oct2025.xlsx',\n",
    "    'SHEET': 'clinical-database-detailed', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'participant_id',\n",
    "    'Date_3T': None,\n",
    "    'Gender': 'Gender',\n",
    "    'Hand': 'Handedness',\n",
    "    'Language': 'Language',\n",
    "    'Job': 'Employment',\n",
    "    'Edu': 'Education',\n",
    "    'EpilepsyDxILAE': 'Epilepsy diagnosis based on ILAE',\n",
    "    'EpilepsyClass': 'Epilepsy classification:Focal,Generalized',\n",
    "    'FocusLat': 'Lateralization of epileptogenic focus',\n",
    "    'FocusConfirmed': 'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)',\n",
    "    'EMUDischargeDx': 'Dx at EMU discharge ',\n",
    "    'EMUAdmissionDate': 'EMU admission date(dd-mm-yy)',\n",
    "    'AdmissionDuration': 'Duration of admission',\n",
    "    'EpilepsyRiskFactors': 'Risk factors for epilepsy',\n",
    "    'SeizureOnsetYr': 'Seizure onset (yr)',\n",
    "    'DrugResistant': 'Drug resistant epilepsy at time of EMU admission',\n",
    "    'NumASMsPrior': '# of ASMs prior current EMU admission',\n",
    "    'PrevASMs': 'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission',\n",
    "    'NumASMOnAdmission': '# of ASM on admission',\n",
    "    'ASMsOnAdmission': 'ASMs  on admission (name, doses (mg per day)',\n",
    "    'GeneticTest': 'Genetic test (year,results)',\n",
    "    'FDGPET': 'FDG.PET',\n",
    "    'BaselineMRI': 'Baseline MRI (year,results)',\n",
    "    'InvasiveExplorations': 'Invasive explorations (Y/N)',\n",
    "    'NumSurgicalResections': '# of surgical resection/thermocoagulatin',\n",
    "    'SurgicalResectionDateSite': 'Surgical resection date and site',\n",
    "    'Histopathology': 'Histopatholgy',\n",
    "    'Engel6mo': 'Engel classification (seizure outcomes at the 6 month )',\n",
    "    'Engel1yr': 'Engel classification (seizure outcomes after 1 year from surgical resection)',\n",
    "    'ILAEOutcome1yr': 'ILAE outcome after surgical resection by 1 yr',\n",
    "    'NeuromodDevices': 'Neuromodulation devices'\n",
    "    }\n",
    "\n",
    "sheets = [PNI, MICs, Clin]\n",
    "\n",
    "# QC sheets\n",
    "PNI_QC= { # details of sheet with QC info on 7T surface segmentation\n",
    "    \"STUDY\": \"7T\",\n",
    "    \"PATH\": f\"{src_dir}/7T_processing_26Sept2025.xlsx\",\n",
    "    \"SHEET\": \"Proc_newDays\",\n",
    "    \"ID\": \"Subjec_ID\",\n",
    "    \"SES\": \"Session \",\n",
    "    \"QC_col\": \"Comments \" # NOTE values are free-form strings. Only present for some rows that should be checked myself. Other row's segmentations can be assumed good.\n",
    "}\n",
    "\n",
    "MICs_QC = { # details of sheet with QC info on 3T surface segmentation\n",
    "    \"STUDY\": \"3T\",\n",
    "    \"PATH\": f\"{src_dir}/BIDS_MICs_QC_logs_26Sept2025.xlsx\", \n",
    "    \"SHEET\": \"Sheet1\",\n",
    "    \"ID\": \"ID\",\n",
    "    \"SES\": \"ses\",\n",
    "    \"QC_col\": \"surface quality\" # NOTE 0 < values < 2 0=unacceptable, 2=acceptable\n",
    "}\n",
    "\n",
    "qc_sheets = [PNI_QC, MICs_QC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study details\n",
    "# specify root directories\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "if includeBL:\n",
    "    px_grps = { # specify patient group labels to compare to controls\n",
    "        'allPX' : ['TLE_U', 'MFCL', 'FLE_R', 'MFCL_bTLE', 'UKN_L', 'mTLE_R', 'mTLE_L', 'FLE_L', 'UKN_U', 'TLE_L', 'TLE_R'],\n",
    "        'TLE' : ['TLE_L', 'TLE_R', 'TLE_U', 'mTLE_R', 'mTLE_L'],\n",
    "        'TLE_L': ['TLE_L', 'mTLE_L', 'bTLE_L'],\n",
    "        'TLE_R': ['TLE_R', 'mTLE_R', 'bTLE_R'],\n",
    "        'FCD' : ['FLE_R', 'FLE_L'],\n",
    "        'MFCL' : ['MFCL', 'bTLE'],\n",
    "        'UKN' : ['UKN_L', 'UKN_U']\n",
    "    }\n",
    "else:\n",
    "    px_grps = { # specify patient group labels to compare to controls\n",
    "        'allPX' : ['TLE_U', 'MFCL', 'FLE_R', 'MFCL_bTLE', 'UKN_L', 'mTLE_R', 'mTLE_L', 'FLE_L', 'UKN_U', 'TLE_L', 'TLE_R'],\n",
    "        'TLE' : ['TLE_L', 'TLE_R', 'TLE_U', 'mTLE_R', 'mTLE_L'],\n",
    "        'TLE_L': ['TLE_L', 'mTLE_L'],\n",
    "        'TLE_R': ['TLE_R', 'mTLE_R'],\n",
    "        'FCD' : ['FLE_R', 'FLE_L'],\n",
    "        'MFCL' : ['MFCL', 'bTLE'],\n",
    "        'UKN' : ['UKN_L', 'UKN_U']\n",
    "    }\n",
    "# Make list of dict items for group definitions\n",
    "groups = [\n",
    "    {'TLE_L': px_grps['TLE_L']},\n",
    "    {'TLE_R': px_grps['TLE_R']},\n",
    "    ctrl_grp\n",
    "]\n",
    "\n",
    "specs  = { # all spec values to be in lists to allow for iteration across these values\n",
    "    # directories\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/3T7T/z\", \n",
    "    'prjDir_outs' : \"/outputs\",\n",
    "    'prjDir_out_stats': \"/outputs/stats\",\n",
    "    'prjDir_out_figs': \"/outputs/figures\",\n",
    "    'prjDir_maps' : \"/maps\", # output directory for smoothed cortical maps\n",
    "    'prjDir_dictLists': \"/maps/dictLists\",\n",
    "    'prjDir_mapPths' : \"/output/paths\",\n",
    "    'prjDir_maps_dfs': \"/outputs/dfs/04a_maps_dfs\",\n",
    "    'prjDir_parc_dfs': \"/outputs/dfs/04b_maps_parc\",\n",
    "    'prjDir_winComp_dfs': \"/outputs/dfs/05a_winComp\",\n",
    "    'prjDir_grpFlip_dfs': \"/outputs/dfs/05b_grpFlip\",\n",
    "    'prjDir_winD_dfs': \"/outputs/dfs/05c_winD\",\n",
    "    'prjDir_btwD_dfs': \"/outputs/dfs/05d_btwComp\",\n",
    "\n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-32k'],\n",
    "    'parcellate_ctx': 'glasser', # parcellation to use, or None if no parcellation.\n",
    "    'parc_lbl_ctx': 'glasser_int', # what name to fetch for parcellation values\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['den-0p5mm'],\n",
    "    'parcellate_hipp': 'DK25',\n",
    "    'parc_lbl_hipp': 'idx',\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "    \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'winComp_stats': ['z'], # what stats to run for within study comparisons ('z' for z-scoring, 'w' for w-scoring)\n",
    "\n",
    "    'ipsiTo' : 'L', # what hemisphere for controls ipsi should be mapped to\n",
    "    'newQC': False,\n",
    "    'currentQC_table': \"/host/verges/tank/data/daniel/3T7T/z/outputs/03a_qc_table_16Oct2025-170946.csv\",\n",
    "    'completed_qc_pth': \"/host/verges/tank/data/daniel/3T7T/z/outputs/03a_qc_table_16Oct2025-170946.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call\n",
    "importlib.reload(ud)\n",
    "if save:\n",
    "    df_demo, demo_csv_pth = ud.get_demo(sheets, save_pth=save_pth)\n",
    "else:\n",
    "    df_demo, demo_csv_pth = ud.get_demo(sheets)\n",
    "\n",
    "# details of demographics file\n",
    "demographics = {\n",
    "    \"pth\" : demo_csv_pth,\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "specs['covars'] = [demographics['age'], demographics['sex']],\n",
    "\n",
    "print(f\"Unique participants: {df_demo['UID'].nunique()}\")\n",
    "print(df_demo[['UID','MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'grp_detailed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Make proper Table 1\n",
    "importlib.reload(ud)\n",
    "ud.grp_summary(df_demo, col_grp='grp_detailed', save_pth=save_pth)\n",
    "print(\"-\"*100)\n",
    "print(\"MEDIAN AGE by group\")\n",
    "df_demo.groupby(['grp_detailed', 'study'])['age'].median().sort_index(level='grp_detailed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a2a57",
   "metadata": {},
   "source": [
    "# 2. Path to smoothed maps\n",
    "Strategy: \n",
    "Add paths to relevant maps to df containing demographic information. Each row is one participant at a unique session.\n",
    "\n",
    "Hippocampal maps: identify path to smoothed hippocampal maps, add to row-wise df\n",
    "Cortical maps: take raw maps from micapipe, apply smoothing then save these maps in project directory and add path of the smoothed map to the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Get map paths \n",
    "importlib.reload(tsutil)\n",
    "reimport_src = False\n",
    "\n",
    "if 'df_demo' not in globals() and 'demo_csv_pth' not in globals() or reimport_src:\n",
    "    if 'demo_csv_pth' not in globals():\n",
    "        pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/01b_demo_16Oct2025-163601.csv\"\n",
    "    else:\n",
    "        pth = demo_csv_pth\n",
    "    df_demo = pd.read_csv(pth)\n",
    "    print(f\"[main] Demo file loaded from {pth}\")\n",
    "\n",
    "print(df_demo[['UID','MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'grp_detailed']])\n",
    "# TODO. Create proper log file for function\n",
    "df_pths, dfPths_out_pth, log_pth = tsutil.idToMap(df_demo = df_demo, studies = studies, dict_demo = demographics, specs = specs, \n",
    "                              save = save, save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", save_name = \"02a_mapPths\", \n",
    "                              test=test, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff37eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Map error summary\n",
    "# TODO. Change method to ensure df not highly fragmented\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "pth = dfPths_out_pth\n",
    "\n",
    "if 'df_pths' not in globals() or df_pths is None or reimport_src:\n",
    "    df_pths = pd.read_csv(pth)\n",
    "    print(f\"[main] df_pths loaded from {pth}\")\n",
    "\n",
    "cols = tsutil.get_mapCols(df_pths.columns, split=False, verbose=True)\n",
    "err_summary, ERR_sv_pth = tsutil.countErrors(df_pths, cols, save=specs['prjDir_root'] + specs['prjDir_outs'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ae768",
   "metadata": {},
   "source": [
    "# 3. Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate QC sheet to be completed. Merge completed QC sheet with df_pths\n",
    "importlib.reload(ud)\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "\n",
    "save_name = \"03a_qc_table\"\n",
    "save_pth = specs['prjDir_root'] + specs['prjDir_outs']\n",
    "\n",
    "# a. Create blank QC sheet to complete manually\n",
    "if specs['newQC']: # create new QC sheet\n",
    "    \n",
    "    if 'df_pths' not in globals() or df_pths is None or reimport_src: # load\n",
    "        df_pths_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/02a_mapPths_16Oct2025-170218.csv\"\n",
    "        df_pths = pd.read_csv(df_pths_pth, dtype=str)\n",
    "        print(f\"[main] df_pths loaded from {pth}\")\n",
    "    \n",
    "    qc_sheet, pth = ud.mk_qcSheet(df = df_pths, fts = specs['ft_ctx'] + specs['ft_hipp'], \n",
    "                                  studies = studies, ctx_surf_qc = qc_sheets,\n",
    "                                  save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                                  currentQC = specs['currentQC_table'])\n",
    "else: # load existing QC sheet\n",
    "    qc_sheet_pth = specs['currentQC_table']\n",
    "    qc_sheet = pd.read_csv(qc_sheet_pth, dtype=str)\n",
    "    print(f\"[main] QC sheet loaded from {qc_sheet_pth}\")\n",
    "\n",
    "# Merge QC values for volumes and surfaces\n",
    "if 'dfPths_out_pth' not in globals():\n",
    "    dfPths_out_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/02a_mapPths_16Oct2025-170218.csv\" # should be most recent output of idToMap function\n",
    "\n",
    "df_pths_qc, pth = ud.qc_combine(qc_pth = specs['completed_qc_pth'], \n",
    "                                df_pths_pth = dfPths_out_pth, \n",
    "                                save_pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}\",\n",
    "                                save_name = \"03b_mapPths_QC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
