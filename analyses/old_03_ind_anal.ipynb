{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - zBrains outputs at 3T and 7T in epilepsy\n",
    "1. zBrain/wBrain (surface)  \n",
    "    a. Histograms of vertex wise scores  \n",
    "        i. sub-comparisons with different smoothing kernels  \n",
    "    b. Quantifying extreme vertex groups  \n",
    "        i. number of identified abnormal areas  \n",
    "        ii. size of each abnormal area (number of adjacent extreme vertices)  \n",
    "2. Brainstats (surface)  \n",
    "    a. t-scores for 3T and 7T  \n",
    "    b. cohen's D map between 3T and 7T images  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import vrtx\n",
    "import plots\n",
    "\n",
    "sys.path.append('/host/verges/tank/data/daniel/')  # Replace with the path to Utils\n",
    "from Utils import gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print HHMM_DD-MMM-YYYY\n",
    "date = dt.datetime.now().strftime('%d%b%Y_%H%M')\n",
    "#print(f'Running on {date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(vrtx)\n",
    "importlib.reload(gen)\n",
    "importlib.reload(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "output_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs\"\n",
    "values_dir = \"values\"\n",
    "processed_output_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/fig_stats\"\n",
    "\n",
    "\n",
    "# 3T-7T ID correspondence\n",
    "correps_IDs = {\n",
    "    \"path\": \"/host/verges/tank/data/daniel/3T7T/z/data/pt/IDs_ses_analyses_12Mar.csv\",\n",
    "    \"3T_ID\": \"3T_ID\",\n",
    "    \"7T_ID\": \"7T_ID\",\n",
    "    \"3T_SES\": \"3T_SES\",\n",
    "    \"7T_SES\": \"7T_SES\"\n",
    "}\n",
    "\n",
    "#id_corresp = pd.read_csv(corresp_ID)\n",
    "\n",
    "# Study names\n",
    "MICs = {\"name\": \"MICs\"}\n",
    "\n",
    "PNI = {\"name\": \"PNI\"}\n",
    "\n",
    "#studies = [\"MICs\", \"PNI\"]\n",
    "\n",
    "# zBrain analysis regions\n",
    "cortex = {\n",
    "    \"region\": \"cortex\",\n",
    "    \"surfaces\": [\"midthickness\", \"white\"],\n",
    "    \"resolution\": \"32k\",\n",
    "    \"features\": [\"ADC\", \"T1map\", \"volume\"], # (list) features to extract\n",
    "    #\"smoothing\": [10]\n",
    "    \"smoothing\": [2,5,10]\n",
    "}\n",
    "\n",
    "hippocampus = {\n",
    "    \"region\": \"hippocampus\",\n",
    "    \"surfaces\": [\"midthickness\"],\n",
    "    \"resolution\": \"0p5mm\",\n",
    "    \"features\": [\"ADC\", \"T1map\", \"volume\"], # (list) features to extract\n",
    "    #\"smoothing\": [5]\n",
    "    \"smoothing\": [1,2,5]\n",
    "}\n",
    "\n",
    "subcortex = {\n",
    "    \"region\": \"subcortex\",\n",
    "    \"features\": [\"ADC\", \"T1map\", \"volume\"],\n",
    "    \"smoothing\": [2,5,10]\n",
    "}\n",
    "\n",
    "regions = [cortex, hippocampus, subcortex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of corresponding 3T, 7T aggregate files\n",
    "files_lst = plots.corresp_paths(regions, MICs, PNI, output_dir, values_dir)\n",
    "#print(files_lst)\n",
    "shape = gen.lstOlst_shape(files_lst,print=False)\n",
    "print(f\"raw shape of files_lst (num files, num studies): {shape}\")\n",
    "\n",
    "# get missing files\n",
    "missing = plots.get_missingPths(files_lst)\n",
    "\n",
    "# remove missing files from list\n",
    "for m in missing:\n",
    "    files_lst.remove(m)\n",
    "\n",
    "shape = gen.lstOlst_shape(files_lst,print=False)\n",
    "print(f\"shape of files_lst (num files, num studies): {shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(vrtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary statistics & prepare for group hists\n",
    "- All analysed PX vs all PNE for each file type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary stats for each file type\n",
    "df_summary = pd.DataFrame()\n",
    "clamp_files_lst = []\n",
    "for lst in files_lst:\n",
    "    clamp_lst = []\n",
    "    for file in lst:\n",
    "        print(os.path.basename(file))\n",
    "        df = vrtx.summaryStats(file)\n",
    "        df.insert(df.columns.get_loc(\"study\") + 1, \"region\", os.path.dirname(file).split('/')[-1])\n",
    "        \n",
    "        df_summary = pd.concat([df_summary, df])\n",
    "\n",
    "        # clamp values\n",
    "        df_clamped = vrtx.clamp(file)\n",
    "        \n",
    "        if (df[\"study\"] == \"MICs\").all():\n",
    "            study = \"MICs\"\n",
    "        elif (df[\"study\"] == \"PNI\").all():\n",
    "            study = \"PNI\"\n",
    "\n",
    "        \n",
    "        if (df[\"region\"] == cortex).all():\n",
    "            region = \"cortex\"\n",
    "        elif (df[\"region\"] == hippocampus).all():\n",
    "            region = \"hippocampus\"\n",
    "        elif (df[\"region\"] == subcortex).all():\n",
    "            region = \"subcortex\"\n",
    "        \n",
    "        clamp_name = os.path.basename(file).replace('.csv', '_clamp.csv')\n",
    "        clamp_pth = os.path.join(output_dir,\"values\", study, region, \"clamp\", clamp_name)\n",
    "\n",
    "        df_clamped.to_csv(clamp_pth, index=False)\n",
    "        print(f\"Clamped values saved to {clamp_pth}\")\n",
    "        clamp_lst.append(clamp_pth)\n",
    "    clamp_files_lst.append(clamp_lst)\n",
    "\n",
    "print(clamp_files_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pth = os.path.join(processed_output_dir, f\"sumStats_{date}.csv\")\n",
    "df_summary.to_csv(out_pth, index=False)\n",
    "print  (f\"Summary stats saved to {out_pth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pth = os.path.join(processed_output_dir, f\"sumStats_{date}.csv\")\n",
    "df_summary.to_csv(out_pth, index=False)\n",
    "print  (f\"Summary stats saved to {out_pth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group histograms\n",
    "\n",
    "for files in clamp_files_lst:\n",
    "    # check that base names are the same except for the study\n",
    "    histName_mics = os.path.basename(files[0])\n",
    "    histName_mics = histName_mics.split('_')\n",
    "\n",
    "    histName_pni = os.path.basename(files[1])\n",
    "    histName_pni = histName_pni.split('_')\n",
    "\n",
    "    if histName_mics[1:] != histName_pni[1:]:\n",
    "        print(\"Error: file names do not match. Skipping: \\n\\t%s\\n\\t%s\" %(histName_mics, histName_pni))\n",
    "        continue\n",
    "    else:\n",
    "        #print(\"File names match\")\n",
    "        pass\n",
    "\n",
    "    hemi = histName_mics[1].split('-')[1]\n",
    "    lbl = histName_mics[3].split('-')[1]\n",
    "    feat = histName_mics[4].split('-')[1]\n",
    "    smth = histName_mics[5].split('-')[1]\n",
    "    #print(f\"hemisphere: {hemi}, label: {lbl}, feature: {feat}, smoothing: {smth}\")\n",
    "\n",
    "    title = f\"{feat}, smoothing: {smth} ({hemi}, {lbl})\"\n",
    "    #print(title)\n",
    "\n",
    "\n",
    "    # plot histograms\n",
    "    save_path = \"/host/verges/tank/data/daniel/3T7T/z/outputs/fig_stats/hist_grp\"\n",
    "    save_name = f\"grpHist_{feat}_smth-{smth}_{hemi}_{lbl}_{date}.png\"\n",
    "    save = os.path.join(save_path, save_name)\n",
    "    fig = plots.group_hist(files, labels=[title, \"MICs\",\"PNI\"], save_path=save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge plots (one line per participant)\n",
    "# plot histogram\n",
    "\n",
    "# check that file exists\n",
    "# if not, continue to next file\n",
    "for file in files_lst:\n",
    "        \n",
    "        \n",
    "        # read in data\n",
    "        df_mics = pd.read_csv(mics_file, index_col=False)\n",
    "        df_pni = pd.read_csv(pni_file, index_col=False)\n",
    "        # remove participants with Na in either df\n",
    "        # df_mics = df_mics.dropna()\n",
    "        # df_pni = df_pni.dropna()\n",
    "        \n",
    "        # keep only overlapping participants both dfs\n",
    "        \n",
    "        ## need to remap col names according to 3T-7T ID correspondence\n",
    "\n",
    "        ## keep only overlapping columns\n",
    "        # cols = df_mics.columns.intersection(df_pni.columns)\n",
    "        # df_mics = df_mics[cols]\n",
    "        # df_pni = df_pni[cols]\n",
    "\n",
    "        ## Take histogram for each participant\n",
    "\n",
    "        # print(df_mics.head())\n",
    "        break\n",
    "        # # construct histogram\n",
    "        # fig = plots.ridge(df_mics, matrix_df = df_mics)\n",
    "        # # show histogram\n",
    "        # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        print(path)\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        fig = plots.histStack(df)\n",
    "        # display plot\n",
    "        fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zBrain_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
