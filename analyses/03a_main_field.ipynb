{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6e2da",
   "metadata": {},
   "source": [
    "# Comparisons between MR fields\n",
    "\n",
    "Steps:   \n",
    "1. CLEAN DATA\n",
    "1. SELECT SESSIONS\n",
    "1. ANALYSES\n",
    "    - (visualize unsmoothed, smoothed maps)\n",
    "    - within study TLE vs CTRL comparison\n",
    "        - extract smoother maps\n",
    "        - compute z, w scores (values per participant)\n",
    "        - group and flip\n",
    "        - Cohen's D (compare TLE and control z/w score distributions within each vertex)\n",
    "    - between study 7T vs 3T comparison      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import utils_plots as uplots\n",
    "\n",
    "lab = True\n",
    "save = True\n",
    "verbose = True\n",
    "toPrint = True\n",
    "\n",
    "test = False\n",
    "test_frac = 0.1 # fraction of demo to use for testing if test=True\n",
    "\n",
    "includeBL = False # if should include bilateral TLE patients (with one side higher than other) in analyses\n",
    "\n",
    "if lab: # define root paths to source files\n",
    "    src_dir = \"/host/verges/tank/data/daniel/01_3T7T/z/data/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "    if save:\n",
    "        save_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs\"\n",
    "else:\n",
    "    src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "    if save:\n",
    "        save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "\n",
    "##### ANALYSIS SPECIFICATIONS #####\n",
    "\n",
    "# Demographics details\n",
    "demographics = {\n",
    "    \"df_pths_qc_pth\" : \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/03b_mapPths_QC_26Nov2025-125407.csv\", # NOTE: path to demographics file with merged QC cols produced by 02_demo.ipynb\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "# Study details\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/zbrains_clinical\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/zbrains_clinical\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "# Analysis details\n",
    "specs  = { # all spec values to be in lists to allow for iteration across these values\n",
    "    # directories\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/01_3T7T/z\", \n",
    "    'prjDir_outs' : \"/outputs\",\n",
    "    'prjDir_out_stats': \"/outputs/stats\",\n",
    "    'prjDir_out_figs': \"/outputs/figures\",\n",
    "    'prjDir_maps': \"/maps\", # output directory for smoothed cortical maps\n",
    "    'prjDir_dictLists': \"/maps/dictLists\",\n",
    "    'prjDir_mapPths' : \"/output/paths\",\n",
    "    'prjDir_maps_dfs': \"/outputs/dfs/04a_maps_dfs\",\n",
    "    'prjDir_parc_dfs': \"/outputs/dfs/04b_maps_parc\",\n",
    "    'prjDir_winComp_dfs': \"/outputs/dfs/05a_winComp\",\n",
    "    'prjDir_grpFlip_dfs': \"/outputs/dfs/05b_grpFlip\",\n",
    "    'prjDir_winD_dfs': \"/outputs/dfs/05c_winD\",\n",
    "    'prjDir_btwD_dfs': \"/outputs/dfs/05d_btwComp\",\n",
    "\n",
    "    # downsampling\n",
    "    'ds_study': ['PNI'], # list of study codes to apply downsampling to\n",
    "    'ds_foi': ['T1map'], # features to downsample\n",
    "    'ds_res': [0.8], # resolution (in mm) to downsample volumes to. NOTE. should be same length as ds_foi with each value corresponding to that in ds_foi \n",
    "    'ds_vol_dir': '/downsampled_vols', # name of directory within project dir root\n",
    "\n",
    "    # analysis regions\n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-32k', 'fsLR-5k'],\n",
    "    'parcellate_ctx': 'glasser', # parcellation to use, or None if no parcellation.\n",
    "    'parc_lbl_ctx': 'glasser_int', # what name to fetch for parcellation values\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['den-0p5mm'],\n",
    "    'parcellate_hipp': 'DK25',\n",
    "    'parc_lbl_hipp': 'idx',\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "        \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'winComp_stats': ['z'], # what stats to run for within study comparisons ('z' for z-scoring, 'w' for w-scoring)\n",
    "    'covars': [demographics['age'], demographics['sex']],\n",
    "\n",
    "    'ipsiTo' : 'L', # what hemisphere for controls ipsi should be mapped to\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7415fd6",
   "metadata": {},
   "source": [
    "# Clean data\n",
    "1. [removal]     Ensure that there is at least one QC_surf-vol column with a value above 0\n",
    "1. [amend]      Missing one hemisphere pair, make complimentary hemisphere NA (to prevent unbalanced analyses) \n",
    "1. [removal]     NA for all smoothed maps\n",
    "1. [removal]    Missing one study (3T or 7T) for a given ID-SES combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# LOAD\n",
    "pth = demographics[\"df_pths_qc_pth\"]\n",
    "df_pths = pd.read_csv(pth, dtype=str)\n",
    "print(f\"[main] df_pths loaded from {pth}\")\n",
    "\n",
    "# i. Ensure that all cases have usable data (QC value), data for both hemis present, each subject has data for both studies\n",
    "df_clean, df_cln_pth, df_rmv, df_rmv_pth = tsutil.clean_demoPths(df_pths, nStudies=2, \n",
    "                                                   save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", \n",
    "                                                   save_name = \"03c_demoPths\", verbose=False)\n",
    "# note can cause duplicated rows\n",
    "demographics['df_pths_qc_clean_pth'] = df_cln_pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b2572",
   "metadata": {},
   "source": [
    "# 4. Analysis\n",
    "## a. Downsample 7T - T1maps: check if T1map standard deviation differences are due to resolution and variation in segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample T1maps from 7T study -- see if T1map standard deviation differences are due to resolution\n",
    "# 3 Steps:\n",
    "# i. Downsample 7T maps\n",
    "# ii. Compute feature maps\n",
    "# iii. add map paths to df_pths\n",
    "# TODO can parallelize these functions to speed up computation\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "test = False\n",
    "reimport_src = False\n",
    "df_input_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/03c_demoPths_clean_30Nov2025-094450.csv\"\n",
    "verbose = False\n",
    "override = False # if should override existing downsampled volumes / maps\n",
    "\n",
    "df_volPths_saveName = \"04b_dfPths_dsVols\"\n",
    "df_mapsPths_saveName = \"04c_dfPths_dsMaps\"\n",
    "\n",
    "if 'df_clean' not in globals() or df_clean is None or reimport_src == True:\n",
    "    df_clean = pd.read_csv(df_input_pth, dtype=str)\n",
    "#print(f\"df <{df_clean.shape}> {type(df_clean)} {df_clean.columns}\")\n",
    "\n",
    "if test:\n",
    "    df_clean_iter = df_clean.sample(frac=test_frac, random_state=42)\n",
    "else:\n",
    "    df_clean_iter = df_clean.copy()\n",
    "\n",
    "if test:\n",
    "    print(f\"TEST mode. Using fraction {test_frac} of data: {df_clean_iter.shape[0]} of {df_clean.shape[0]} rows.\")\n",
    "    df_volPths_saveName = \"TEST_\" + df_volPths_saveName\n",
    "    df_mapsPths_saveName = \"TEST_\" + df_mapsPths_saveName\n",
    "\n",
    "# i. Downsample\n",
    "df_clean_iter = tsutil.downsample_df(df = df_clean_iter, studies = studies, specs = specs,\n",
    "                             demographics = demographics,\n",
    "                             df_save_name = df_volPths_saveName,\n",
    "                             override = False, verbose = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "# ii. Map\n",
    "tsutil.get_dsMaps(df = df_clean_iter, \n",
    "                  specs = specs,\n",
    "                  studies = studies,\n",
    "                  demographics = demographics,\n",
    "                  verbose = verbose,\n",
    "                  override = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "df_clean_ds, df_svPth = tsutil.get_dsMaps_pths_iter(df_pths = df_clean_iter, specs = specs, \n",
    "                                                    demographics = demographics, studies=studies,\n",
    "                                                    save_name = df_mapsPths_saveName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a830bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can perform sanity check here to ensure that map values are correct: ie hemispheres are different, values are same compared to zBrains maps\n",
    "# copy path to see ./debug/mapValues.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af51eff",
   "metadata": {},
   "source": [
    "## b. Read in maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1486089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MAPS INTO DICTIONARY LISTS\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "save_name = \"04d_dl_maps\"\n",
    "test = False\n",
    "\n",
    "if 'df_clean_ds' not in globals() or df_clean_ds is None or reimport_src == True:\n",
    "    df_svPth = f\"{specs['prjDir_root'] + specs['prjDir_outs']}/04c_dfPths_dsMaps_26Nov2025-132106.csv\"\n",
    "    df_clean_ds = pd.read_csv(df_svPth, dtype=str)\n",
    "\n",
    "# find all map cols\n",
    "cols_L, cols_R = tsutil.get_mapCols(df_clean_ds.columns, verbose=True)\n",
    "\n",
    "# extract maps as appropriate\n",
    "if specs['ctx']:\n",
    "    ctx_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R,\n",
    "                               specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                               save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                               region = \"cortex\", verbose=True, test = test)\n",
    "else:\n",
    "    ctx_dl = []\n",
    "print(\"-\"*100)\n",
    "if specs['hipp']:\n",
    "    hipp_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R, \n",
    "                                specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                                save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                                region = \"hippocampus\", verbose=True, test = test)\n",
    "else:\n",
    "    hipp_dl = []\n",
    "\n",
    "# Create single dl \n",
    "dl = ctx_dl + hipp_dl\n",
    "\n",
    "len_unsmth = len([d for d in ctx_dl + hipp_dl if d['smth'] == 'NA'])\n",
    "len_smth = len([d for d in ctx_dl + hipp_dl if d['smth'] != 'NA'])\n",
    "print(f\"\\n[main] {len(dl)} dictionary items for this study-feature-label-surface pairs\\n\\t{len_unsmth} with smoothing == NA | {len_unsmth} with smoothing\")\n",
    "\n",
    "if save:\n",
    "    out_pth = tsutil.savePickle(obj = dl, root = save_pth, name = save_name, test = test)\n",
    "\n",
    "if toPrint:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl)\n",
    "\n",
    "# NOTE. columns with no rows are not kept in dictionary list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e345b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 37\n",
    "idx_other = tsutil.get_pair(dl, idx = idx, mtch = ['region', 'surf', 'label', 'feature', 'smth', 'downsampledRed'], difdsRes=True, difStudy = True)\n",
    "tsutil.printItemMetadata(dl[idx], idx=idx)\n",
    "tsutil.printItemMetadata(dl[idx_other], idx = idx_other)\n",
    "tsutil.print_dict(dl, idx = [idx, idx_other], df_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a920d8",
   "metadata": {},
   "source": [
    "## c. Parcellate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b900a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcellate maps\n",
    "importlib.reload(tsutil)\n",
    "reimport_src = False\n",
    "save_name = \"04e_dl_maps_parcel\"\n",
    "test = False\n",
    "verbose = False\n",
    "\n",
    "if 'dl' not in globals() or dl is None or reimport_src:\n",
    "    src_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/04d_dl_maps_30Nov2025-101936.pkl\"\n",
    "    dl = tsutil.loadPickle(src_pth)\n",
    "\n",
    "#tsutil.print_dict(dl)\n",
    "\n",
    "if specs['parcellate_ctx'] is not None or specs['parcellate_hipp'] is not None: # for each item, create a df_parc   \n",
    "    region_parc = [{'region': 'cortex', \n",
    "                    'parcellate': specs.get('parcellate_ctx', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_ctx', None)}, \n",
    "                   \n",
    "                   {'region': 'hippocampus',\n",
    "                    'parcellate': specs.get('parcellate_hipp', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_hipp', None)}]\n",
    "    \n",
    "    # TODO. Also parcellate without summarizing accross parcels\n",
    "    dl_parcel, dl_parc_pth, region_parc = tsutil.parcellate_items(dl, df_keys=['df_maps'], parcellationSpecs = region_parc, df_save_pth = specs['prjDir_root'] + specs['prjDir_parc_dfs'],\n",
    "                                                    stats = ['none', 'mean'],\n",
    "                                                    save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", save_name=save_name,\n",
    "                                                    verbose=verbose, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af778bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_parc = tsutil.loadPickle(\"/host/verges/tank/data/daniel/01_3T7T/z/outputs/04e_dl_maps_parcel_30Nov2025-104901.pkl\")\n",
    "importlib.reload(tsutil)\n",
    "dl_parcel_foi = tsutil.filt_dl(dl_parc, key = 'feature', voi = ['thickness','T1map'])\n",
    "tsutil.print_dict(dl_parcel_foi, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS about vertices within parcels\n",
    "# To help select mean or median summarization\n",
    "\"\"\"\n",
    "# TODO. Appears broken\n",
    "import importlib\n",
    "import utils_parc as up\n",
    "importlib.reload(up)\n",
    "\n",
    "reimport_src = False\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-112622.pkl\"\n",
    "    dl_parcel = tsutil.loadPickle(pth)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04e_parcel_distr\"\n",
    "koi = \"df_maps_parc-dk25\"\n",
    "up.parcel_stats(dl = dl_parcel, key = koi, sv_root = save_pth, test = False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e693c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP MATRICES\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "fig_dir = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/04f_maps_allPt/raw\"\n",
    "uplots.plotMatrices(dl = dl_parcel_foi, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'], \n",
    "                    cor = True, save_pth=fig_dir, test=False) # visualize smoothed maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uplots.plotLine(dl_parcel, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'],\n",
    "            name_append=\"line\", \n",
    "            parc=['glasser', 'DK25'], stat = ['mean', 'mean'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=\"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/04f_maps_allPt/raw\",\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=False)\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_allPt\") # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b64e",
   "metadata": {},
   "source": [
    "# Within study, vertex/parcel-wise statistics (z-, w- scores)\n",
    "- compares _all_ participants to controls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z, w scores within studies (all participants vs control distribution)\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "# import smoothed maps\n",
    "reimport_src = False\n",
    "test = False\n",
    "save_name = \"05a_winStudy\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/04e_dl_maps_parcel_30Nov2025-104901.pkl\"\n",
    "    dl = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "#tsutil.print_dict(dl_parcel, df_print=False)\n",
    "\n",
    "# calculate statistics\n",
    "dl_winComp, dl_winComp_pth  = tsutil.winComp(dl = dl_parcel, demographics = demographics, keys_maps = ['df_maps', 'df_maps_parc-glsr', 'df_maps_parc-glsr_mean', 'df_maps_parc-dk25', 'df_maps_parc-dk25_mean'], \n",
    "                            col_grp = specs['col_grp'], ctrl_grp = ctrl_grp, \n",
    "                            out_df_save_pth = specs['prjDir_root'] + specs['prjDir_winComp_dfs'],\n",
    "                            stat=specs['winComp_stats'], covars = specs['covars'], key_demo = 'df_demo',\n",
    "                            save = True, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                            verbose = True, dlPrint = False, test=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879395f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z, w score maps\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = False\n",
    "test = False\n",
    "fig_dir = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/05a_winComp/raw\"\n",
    "\n",
    "if 'dl_winComp' not in globals() or dl_winComp is None or reimport_src:\n",
    "    pth = dl_winComp_pth\n",
    "    # pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/05a_winStudy_30Nov2025-110838.pkl\"\n",
    "    dl_winComp = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] winComp dict list loaded from {pth}\")\n",
    "\n",
    "# TODO. Add smart plotting based on parameters listed in specs dictionary\n",
    "dfs_toPlot = ['df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z']\n",
    "\n",
    "uplots.plotMatrices(dl = dl_winComp, df_keys = dfs_toPlot, name_append=True, save_pth=fig_dir, test=test) # visualize winCompStat maps\n",
    "uplots.plotLine(dl_winComp, df_keys = dfs_toPlot, \n",
    "            parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=fig_dir,\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=test)\n",
    "\n",
    "# TODO. Allow integration of pdf for large images\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef774a1",
   "metadata": {},
   "source": [
    "# Select group of interest and ipsi/contra flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary list based on previous dl.\n",
    "# New dl will have the same number of dictionary items (one for each study, ft, label, surf, smth, region combination).\n",
    "#   Keys of each dictionary items may change. One df for each combination of [group[len(goi)] x lateralization[_R, _L, _ic] + 1 (ctrl)] x stat[<_z>, <_w>]] \n",
    "#   If df_{stat} is none, nothing regarding this statistic will be added to dict item.\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# import\n",
    "reimport_src = False\n",
    "src_pth = dl_winComp_pth\n",
    "#src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_20Oct2025-084311.pkl\"\n",
    "\n",
    "if 'dl_winComp' not in globals() or dl_winComp is None or reimport_src:\n",
    "    dl_winComp = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "goi  = [\"TLE\"] # Should be high level group eg., TLE. Will find lateralization based on last character of group name in df [L or R]\n",
    "g_exclude = [[\"nTLE\", \"TLE_BL\", \"TLE_U\"]] # group names to exclude if contain same strings as in goi list. should be a list of lists with same length as goi\n",
    "# goi = [\"TLE\"] # ORIG group(s) of interest. Store main diagnosis abrev in list to allow for multiple groups\n",
    "koi = ['df_maps_z', 'df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z'] # keys of dl_winComp to use\n",
    "test = False\n",
    "save_name = \"05b_stats_winStudy_grp\"\n",
    "verbose = True\n",
    "\n",
    "dl_grp_ic = tsutil.grp_flip(dl = dl_winComp, demographics = demographics, \n",
    "                            goi = goi, g_exclude = g_exclude, df_keys = koi,\n",
    "                    col_grp = specs['col_grp'], save_pth_df = specs['prjDir_root'] + specs['prjDir_grpFlip_dfs'],\n",
    "                    save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name, test=test, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(dl_grp_ic, df_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/05b_stats_winStudy_grp_30Nov2025-114034.pkl\"\n",
    "printDl = True\n",
    "\n",
    "test = False\n",
    "dfs_toPlot = ['df_maps_parc-glsr_mean_z_TLE_ic', 'df_maps_parc-dk25_mean_z_TLE_ic']\n",
    "foi = [\"thickness\", \"T1map\"] # features of interest\n",
    "loi = ['midthickness', 'white', 'inner', 'outer'] # surfaces of interest\n",
    "fig_dir = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/05b_winStudy_grp/raw\"\n",
    "\n",
    "\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport_src:\n",
    "    dl_grp_ic = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "dl_interest = [d for d in dl_grp_ic if d['feature'] in foi and d['label'] in loi]\n",
    "\n",
    "if printDl:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl_interest, df_print=False)\n",
    "\n",
    "uplots.plotMatrices(dl = dl_interest, df_keys = dfs_toPlot, \n",
    "                    name_append=True, save_pth=fig_dir, test=test) # visualize z score maps\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStat_ic\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n",
    "uplots.plotLine(dl_interest, df_keys = dfs_toPlot,\n",
    "                name_append=\"line\",\n",
    "                parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "                hlines = [[60,120,240,300], None],\n",
    "                save_pth=fig_dir, spacing = None,\n",
    "                marks=False, alpha = 0.6,\n",
    "                test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb52c",
   "metadata": {},
   "source": [
    "# Within study Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "save = True\n",
    "save_name = \"05c_stats_winD\"\n",
    "\n",
    "koi = ['df_maps_z',  'df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z']\n",
    "goi = ['TLE_ic']\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/05b_stats_winStudy_grp_30Nov2025-114034.pkl\"\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport == True:\n",
    "    dl_grp_ic = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "winD = tsutil.winD(dl = dl_grp_ic, df_keys = koi, save_pth_df = specs['prjDir_root'] + specs['prjDir_winD_dfs'],\n",
    "                   ipsiTo = specs.get('ipsiTo', 'L'), \n",
    "                   save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                   verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1332b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsutil.loadPickle(winD[5]['df_maps_z_d_ic'])\n",
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrices\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "save_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/05c_winD/raw\"\n",
    "uplots.plotMatrices(dl = winD, df_keys = 'df_d', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "uplots.plotMatrices(dl = winD, df_keys = 'df_d_ic', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir = save_pth, output = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/figs/05c_winD\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847ea6",
   "metadata": {},
   "source": [
    "# Between study: D-score differences\n",
    "- Identify pairs of dictionary items\n",
    "- Extract d scoring statitics and compute:\n",
    "- raw d dif\n",
    "- d dif / ctrl d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "verbose = True\n",
    "save_name = \"05d_btwD\"\n",
    "\n",
    "# import \n",
    "pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/05c_stats_winD_30Nov2025-114813.pkl\"\n",
    "if 'winD' not in globals() or winD is None or reimport == True:\n",
    "    winD = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "comps = tsutil.btwD(dl = winD, koi = [\"df_maps_z_d\", \"df_maps_z_d_ic\", \n",
    "                                           \"df_maps_parc-glsr_mean_z_d\", \"df_maps_parc-glsr_mean_z_d_ic\",\n",
    "                                           \"df_maps_parc-dk25_mean_z_d\", \"df_maps_parc-dk25_mean_z_d_ic\"], \n",
    "                    save_pth_df = specs['prjDir_root'] + specs['prjDir_btwD_dfs'],\n",
    "                    save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                    verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(comps, df_print=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
