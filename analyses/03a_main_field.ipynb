{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6e2da",
   "metadata": {},
   "source": [
    "# Comparisons between MR fields\n",
    "\n",
    "Steps:   \n",
    "1. CLEAN DATA\n",
    "1. SELECT SESSIONS\n",
    "1. ANALYSES\n",
    "    - (visualize unsmoothed, smoothed maps)\n",
    "    - within study TLE vs CTRL comparison\n",
    "        - extract smoother maps\n",
    "        - compute z, w scores (values per participant)\n",
    "        - group and flip\n",
    "        - Cohen's D (compare TLE and control z/w score distributions within each vertex)\n",
    "    - between study 7T vs 3T comparison      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import utils_plots as uplots\n",
    "\n",
    "lab = True\n",
    "save = True\n",
    "verbose = True\n",
    "toPrint = True\n",
    "\n",
    "test = False\n",
    "test_frac = 0.1 # fraction of demo to use for testing if test=True\n",
    "\n",
    "includeBL = False # if should include bilateral TLE patients (with one side higher than other) in analyses\n",
    "\n",
    "if lab: # define root paths to source files\n",
    "    src_dir = \"/host/verges/tank/data/daniel/3T7T/z/data/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "    if save:\n",
    "        save_pth = save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs\"\n",
    "else:\n",
    "    src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "    if save:\n",
    "        save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "\n",
    "##### ANALYSIS SPECIFICATIONS #####\n",
    "\n",
    "# Demographics details\n",
    "demographics = {\n",
    "    \"df_pths_qc_pth\" : \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/03b_mapPths_QC_26Nov2025-125407.csv\", # NOTE: path to demographics file with merged QC cols produced by 02_demo.ipynb\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "# Study details\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/zbrains_clinical\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/zbrains_clinical\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "# Analysis details\n",
    "specs  = { # all spec values to be in lists to allow for iteration across these values\n",
    "    # directories\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/01_3T7T/z\", \n",
    "    'prjDir_outs' : \"/outputs\",\n",
    "    'prjDir_out_stats': \"/outputs/stats\",\n",
    "    'prjDir_out_figs': \"/outputs/figures\",\n",
    "    'prjDir_maps': \"/maps\", # output directory for smoothed cortical maps\n",
    "    'prjDir_dictLists': \"/maps/dictLists\",\n",
    "    'prjDir_mapPths' : \"/output/paths\",\n",
    "    'prjDir_maps_dfs': \"/outputs/dfs/04a_maps_dfs\",\n",
    "    'prjDir_parc_dfs': \"/outputs/dfs/04b_maps_parc\",\n",
    "    'prjDir_winComp_dfs': \"/outputs/dfs/05a_winComp\",\n",
    "    'prjDir_grpFlip_dfs': \"/outputs/dfs/05b_grpFlip\",\n",
    "    'prjDir_winD_dfs': \"/outputs/dfs/05c_winD\",\n",
    "    'prjDir_btwD_dfs': \"/outputs/dfs/05d_btwComp\",\n",
    "\n",
    "    # downsampling\n",
    "    'ds_study': ['PNI'], # list of study codes to apply downsampling to\n",
    "    'ds_foi': ['T1map'], # features to downsample\n",
    "    'ds_res': [0.8], # resolution (in mm) to downsample volumes to. NOTE. should be same length as ds_foi with each value corresponding to that in ds_foi \n",
    "    'ds_vol_dir': '/downsampled_vols', # name of directory within project dir root\n",
    "\n",
    "    # analysis regions\n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-32k', 'fsLR-5k'],\n",
    "    'parcellate_ctx': 'glasser', # parcellation to use, or None if no parcellation.\n",
    "    'parc_lbl_ctx': 'glasser_int', # what name to fetch for parcellation values\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['den-0p5mm'],\n",
    "    'parcellate_hipp': 'DK25',\n",
    "    'parc_lbl_hipp': 'idx',\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "        \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'winComp_stats': ['z'], # what stats to run for within study comparisons ('z' for z-scoring, 'w' for w-scoring)\n",
    "    'covars': [demographics['age'], demographics['sex']],\n",
    "\n",
    "    'ipsiTo' : 'L', # what hemisphere for controls ipsi should be mapped to\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7415fd6",
   "metadata": {},
   "source": [
    "# Clean data\n",
    "1. [removal]     Ensure that there is at least one QC_surf-vol column with a value above 0\n",
    "1. [amend]      Missing one hemisphere pair, make complimentary hemisphere NA (to prevent unbalanced analyses) \n",
    "1. [removal]     NA for all smoothed maps\n",
    "1. [removal]    Missing one study (3T or 7T) for a given ID-SES combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# LOAD\n",
    "pth = demographics[\"df_pths_qc_pth\"]\n",
    "df_pths = pd.read_csv(pth, dtype=str)\n",
    "print(f\"[main] df_pths loaded from {pth}\")\n",
    "\n",
    "# i. Ensure that all cases have usable data (QC value), data for both hemis present, each subject has data for both studies\n",
    "df_clean, df_cln_pth, df_rmv, df_rmv_pth = tsutil.clean_demoPths(df_pths, nStudies=2, \n",
    "                                                   save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", \n",
    "                                                   save_name = \"03c_demoPths\", verbose=False)\n",
    "# note can cause duplicated rows\n",
    "demographics['df_pths_qc_clean_pth'] = df_cln_pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b2572",
   "metadata": {},
   "source": [
    "# 4. Analysis\n",
    "## a. Downsample 7T - T1maps: check if T1map standard deviation differences are due to resolution and variation in segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample T1maps from 7T study -- see if T1map standard deviation differences are due to resolution\n",
    "# 3 Steps:\n",
    "# i. Downsample 7T maps\n",
    "# ii. Compute feature maps\n",
    "# iii. add map paths to df_pths\n",
    "# TODO can parallelize these functions to speed up computation\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "test = False\n",
    "reimport_src = True\n",
    "df_input_pth = \"/host/verges/tank/data/daniel/01_3T7T/z/outputs/03c_demoPths_clean_26Nov2025-125955.csv\"\n",
    "verbose = False\n",
    "override = False # if should override existing downsampled volumes / maps\n",
    "\n",
    "df_volPths_saveName = \"04b_dfPths_dsVols\"\n",
    "df_mapsPths_saveName = \"04c_dfPths_dsMaps\"\n",
    "\n",
    "if 'df_clean' not in globals() or df_clean is None or reimport_src == True:\n",
    "    df_clean = pd.read_csv(df_input_pth, dtype=str)\n",
    "#print(f\"df <{df_clean.shape}> {type(df_clean)} {df_clean.columns}\")\n",
    "\n",
    "if test:\n",
    "    df_clean_iter = df_clean.sample(frac=test_frac, random_state=42)\n",
    "else:\n",
    "    df_clean_iter = df_clean.copy()\n",
    "\n",
    "if test:\n",
    "    print(f\"TEST mode. Using fraction {test_frac} of data: {df_clean_iter.shape[0]} of {df_clean.shape[0]} rows.\")\n",
    "    df_volPths_saveName = \"TEST_\" + df_volPths_saveName\n",
    "    df_mapsPths_saveName = \"TEST_\" + df_mapsPths_saveName\n",
    "\n",
    "# i. Downsample\n",
    "df_clean_iter = tsutil.downsample_df(df = df_clean_iter, studies = studies, specs = specs,\n",
    "                             demographics = demographics,\n",
    "                             df_save_name = df_volPths_saveName,\n",
    "                             override = False, verbose = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "# ii. Map\n",
    "tsutil.get_dsMaps(df = df_clean_iter, \n",
    "                  specs = specs,\n",
    "                  studies = studies,\n",
    "                  demographics = demographics,\n",
    "                  verbose = verbose,\n",
    "                  override = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "df_clean_ds, df_svPth = tsutil.get_dsMaps_pths_iter(df_pths = df_clean_iter, specs = specs, \n",
    "                                                    demographics = demographics, studies=studies,\n",
    "                                                    save_name = df_mapsPths_saveName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af51eff",
   "metadata": {},
   "source": [
    "## b. Read in maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1486089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MAPS INTO DICTIONARY LISTS\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "save_name = \"04d_dl_maps\"\n",
    "test = False\n",
    "\n",
    "if 'df_clean_ds' not in globals() or df_clean_ds is None or reimport_src == True:\n",
    "    df_svPth = f\"{specs['prjDir_root'] + specs['prjDir_outs']}/04c_dfPths_dsMaps_26Nov2025-132106.csv\"\n",
    "    df_clean_ds = pd.read_csv(df_svPth, dtype=str)\n",
    "\n",
    "# find all map cols\n",
    "cols_L, cols_R = tsutil.get_mapCols(df_clean_ds.columns, verbose=True)\n",
    "\n",
    "# extract maps as appropriate\n",
    "if specs['ctx']:\n",
    "    ctx_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R,\n",
    "                               specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                               save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                               region = \"cortex\", verbose=True, test = test)\n",
    "else:\n",
    "    ctx_dl = []\n",
    "print(\"-\"*100)\n",
    "if specs['hipp']:\n",
    "    hipp_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R, \n",
    "                                specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                                save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                                region = \"hippocampus\", verbose=True, test = test)\n",
    "else:\n",
    "    hipp_dl = []\n",
    "\n",
    "# Create single dl \n",
    "dl = ctx_dl + hipp_dl\n",
    "\n",
    "len_unsmth = len([d for d in ctx_dl + hipp_dl if d['smth'] == 'NA'])\n",
    "len_smth = len([d for d in ctx_dl + hipp_dl if d['smth'] != 'NA'])\n",
    "print(f\"\\n[main] {len(dl)} dictionary items for this study-feature-label-surface pairs\\n\\t{len_unsmth} with smoothing == NA | {len_unsmth} with smoothing\")\n",
    "\n",
    "if save:\n",
    "    out_pth = tsutil.savePickle(obj = dl, root = save_pth, name = save_name, test = test)\n",
    "\n",
    "if toPrint:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl)\n",
    "\n",
    "# NOTE. columns with no rows are not kept in dictionary list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Check that hemispheres are:\n",
    "# 1. not identical\n",
    "# 2. correclty assigned\n",
    "# debug using z-brains outputted smoothed maps\n",
    "#input_df = '/host/verges/tank/data/daniel/01_3T7T/z/outputs/04c_dfPths_dsMaps_26Nov2025-132106.csv'\n",
    "\n",
    "# get path to z-brains smoothed maps and add to df_clean_ds\n",
    "\n",
    "def zbrainsMaps(study, id, ses, region, feat, lbl, surf, smth):\n",
    "    \"\"\"\n",
    "    Gets path to z-brains smoothed maps\n",
    "\n",
    "    Inputs:\n",
    "        study: dict\n",
    "            paths to directories including root, deriv, z-brains\n",
    "        id: str\n",
    "            participant ID (no sub-)\n",
    "        ses: str\n",
    "            session ID (no ses-)\n",
    "        region: str\n",
    "            'cortex'/'ctx' or 'hippocampus'/'hip'\n",
    "        feat: str\n",
    "            feature name\n",
    "        lbl: str\n",
    "            label name (ie. midthickness, white, inner, outer etc)\n",
    "        surf: str\n",
    "            surface name (fsLR-5k, fsLR-32k)\n",
    "        smth: int\n",
    "            smoothing value in mm\n",
    "\n",
    "    Returns L, R if both exist\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "    if region == 'ctx' or region == 'cortex':\n",
    "        region = 'cortex'\n",
    "    elif region == 'hip' or region == 'hippocampus':\n",
    "        region = 'hippocampus'\n",
    "    else:\n",
    "        raise ValueError(f\"region <{region}> not recognized. Should be 'cortex' or 'hippocampus'\")\n",
    "    \n",
    "    if smth == 'NA' or smth == 0: # should get unsmoothed path from micapipe outputs\n",
    "        root_mp = f\"{study['dir_root']}{study['dir_deriv']}{study['dir_mp']}/sub-{id}/ses-{ses}/maps\"\n",
    "        if feat == \"thickness\":\n",
    "            out_pth_L_filename = f\"hemi-L_surf-{surf}_label-{feat}\"\n",
    "            out_pth_R_filename = f\"hemi-R_surf-{surf}_label-{feat}\"\n",
    "        else:\n",
    "            out_pth_L_filename = f\"hemi-L_surf-{surf}_label-{lbl}_{feat}\"\n",
    "            out_pth_R_filename = f\"hemi-R_surf-{surf}_label-{lbl}_{feat}\"\n",
    "            \n",
    "        # ii. Paths to micapipe unsmoothed maps    \n",
    "        pth_L = f\"{root_mp}/sub-{id}_ses-{ses}_{out_pth_L_filename}.func.gii\"\n",
    "        pth_R = f\"{root_mp}/sub-{id}_ses-{ses}_{out_pth_R_filename}.func.gii\"\n",
    "\n",
    "    else: # get zbrains smoothed map paths\n",
    "        base_pth = f\"{study['dir_root']}{study['dir_deriv']}{study['dir_zb']}/sub-{id}/ses-{ses}/maps/{region}\"\n",
    "        if region == 'cortex':\n",
    "            pth_L = f\"{base_pth}/sub-{id}_ses-{ses}_hemi-L_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm.func.gii\"\n",
    "            pth_R = f\"{base_pth}/sub-{id}_ses-{ses}_hemi-R_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm.func.gii\"\n",
    "        else:\n",
    "            pth_L = f\"{base_pth}/sub-{id}_ses-{ses}_hemi-L_{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm.func.gii\"\n",
    "            pth_R = f\"{base_pth}/sub-{id}_ses-{ses}_hemi-R_{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm.func.gii\"\n",
    "\n",
    "    \n",
    "    if os.path.exists(pth_L) == True and os.path.exists(pth_R) == True:   \n",
    "        print(f\"[zbrainsMaps] \\tL: {pth_L}\\n\\t\\tR: {pth_R}\")\n",
    "        return pth_L, pth_R\n",
    "    else:\n",
    "        print(f\"[zbrainsMaps] NO EXIST \\t\\tL: {pth_L}\\n\\t\\t\\tR: {pth_R}\")\n",
    "        return np.nan, np.nan\n",
    "\n",
    "# add z-brains smoothed map paths to df_clean_ds\n",
    "reimport_src = False\n",
    "if 'df_clean_ds' not in globals() or df_clean_ds is None or reimport_src == True:\n",
    "    df_svPth = f\"{specs['prjDir_root'] + specs['prjDir_outs']}/04c_dfPths_dsMaps_26Nov2025-132106.csv\"\n",
    "    df_clean_ds = pd.read_csv(df_svPth, dtype=str)\n",
    "df_zb = df_clean_ds.copy()\n",
    "print(f'Initial shape df: {df_zb.shape}')\n",
    "for idx, row in df_zb.iterrows():\n",
    "    study_name = row['study']\n",
    "    if study_name == '3T':\n",
    "        study = MICs\n",
    "    elif study_name == '7T':\n",
    "        study = PNI\n",
    "    else:\n",
    "        raise ValueError(f\"study name <{study_name}> not recognized [index: {idx}]\")\n",
    "    \n",
    "    id_ = row[demographics['ID_3T']] if study_name == '3T' else row[demographics['ID_7T']]\n",
    "    ses = row['SES']\n",
    "\n",
    "    if specs['ctx']:\n",
    "        for feat in specs['ft_ctx']:\n",
    "            for lbl in specs['lbl_ctx']:\n",
    "                for surf in specs['surf_ctx']:\n",
    "                    for smth in specs['smth_ctx']:\n",
    "                        pth_L, pth_R = zbrainsMaps(study, id_, ses, 'cortex', feat, lbl, surf, smth)\n",
    "                        col_L = f\"zb_ctx_hemi-L_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm\"\n",
    "                        col_R = f\"zb_ctx_hemi-R_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm\"\n",
    "                        df_zb.at[idx, col_L] = pth_L\n",
    "                        df_zb.at[idx, col_R] = pth_R\n",
    "                        #assert 0 == 1, \"STOP\"\n",
    "\n",
    "    if specs['hipp']:\n",
    "        for feat in specs['ft_hipp']:\n",
    "            for lbl in specs['lbl_hipp']:\n",
    "                for surf in specs['surf_hipp']:\n",
    "                    for smth in specs['smth_hipp']:\n",
    "                        \n",
    "                        pth_L, pth_R = zbrainsMaps(study, id_, ses, 'hippocampus', feat, lbl, surf, smth)\n",
    "                        col_L = f\"zb_hipp_hemi-L_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm\"\n",
    "                        col_R = f\"zb_hipp_hemi-R_surf-{surf}_label-{lbl}_feature-{feat}_smooth-{smth}mm\"\n",
    "                        \n",
    "                        df_zb.at[idx, col_L] = pth_L\n",
    "                        df_zb.at[idx, col_R] = pth_R\n",
    "                        \n",
    "print(f'Final shape df: {df_zb.shape}')\n",
    "\n",
    "if 'UID_study_ses' in df_zb.columns:\n",
    "    try:\n",
    "        df_zb.drop(columns='UID_study_ses', inplace=True)\n",
    "    except:\n",
    "        print(\"[main] could not drop column UID_study_ses\")\n",
    "\n",
    "\n",
    "# save df_zb_clean\n",
    "out_pth = f\"{specs['prjDir_root'] + specs['prjDir_outs']}/debug/04c_dfPths_dsMaps_withZb_{datetime.datetime.now()cd}.csv\"\n",
    "df_zb.to_csv(out_pth, index=False)\n",
    "print(f\"[main] df_zb_clean saved to {out_pth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fb99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2f2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "test = False\n",
    "coi = [c for c in df_zb_clean.columns if c.startswith('zb')]\n",
    "cols_L, cols_R = tsutil.get_mapCols(coi, verbose=True)\n",
    "\n",
    "dl_hipp_zb = tsutil.extractMap(df_mapPaths = df_zb_clean, cols_L = cols_L, cols_R = cols_R, \n",
    "                                specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                                save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                                region = \"hippocampus\", verbose=True, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60788fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e41209",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 37\n",
    "idx_other = tsutil.get_pair(dl, idx = idx, mtch = ['region', 'surf', 'label', 'feature', 'smth', 'downsampledRed'], difdsRes=True, difStudy = True)\n",
    "tsutil.printItemMetadata(dl[idx], idx=idx)\n",
    "tsutil.printItemMetadata(dl[idx_other], idx = idx_other)\n",
    "tsutil.print_dict(dl, idx = [idx, idx_other], df_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a920d8",
   "metadata": {},
   "source": [
    "## c. Parcellate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af9524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcellate maps\n",
    "importlib.reload(tsutil)\n",
    "reimport_src = False\n",
    "save_name = \"04e_dl_maps_parcel\"\n",
    "test = False\n",
    "verbose = False\n",
    "\n",
    "if 'dl' not in globals() or dl is None or reimport_src:\n",
    "    src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04d_dl_maps_19Oct2025-153909.pkl\"\n",
    "    dl = tsutil.loadPickle(src_pth)\n",
    "\n",
    "#tsutil.print_dict(dl)\n",
    "\n",
    "if specs['parcellate_ctx'] is not None or specs['parcellate_hipp'] is not None: # for each item, create a df_parc   \n",
    "    region_parc = [{'region': 'cortex', \n",
    "                    'parcellate': specs.get('parcellate_ctx', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_ctx', None)}, \n",
    "                   \n",
    "                   {'region': 'hippocampus',\n",
    "                    'parcellate': specs.get('parcellate_hipp', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_hipp', None)}]\n",
    "    \n",
    "    # TODO. Also parcellate without summarizing accross parcels\n",
    "    dl_parcel, region_parc = tsutil.parcellate_items(dl, df_keys=['df_maps'], parcellationSpecs = region_parc, df_save_pth = specs['prjDir_root'] + specs['prjDir_parc_dfs'],\n",
    "                                                    stats = ['none', 'mean'],\n",
    "                                                    save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", save_name=save_name,\n",
    "                                                    verbose=verbose, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a29921",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_parc = tsutil.loadPickle(\"/host/verges/tank/data/daniel/3T7T/z/outputs/04e_dl_maps_parcel_20Oct2025-084257.pkl\")\n",
    "importlib.reload(tsutil)\n",
    "dl_parcel_foi = tsutil.filt_dl(dl_parc, key = 'feature', voi = ['thickness','T1map'])\n",
    "tsutil.print_dict(dl_parcel_foi, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS about vertices within parcels\n",
    "# To help select mean or median summarization\n",
    "\"\"\"\n",
    "# TODO. Appears broken\n",
    "import importlib\n",
    "import utils_parc as up\n",
    "importlib.reload(up)\n",
    "\n",
    "reimport_src = False\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-112622.pkl\"\n",
    "    dl_parcel = tsutil.loadPickle(pth)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04e_parcel_distr\"\n",
    "koi = \"df_maps_parc-dk25\"\n",
    "up.parcel_stats(dl = dl_parcel, key = koi, sv_root = save_pth, test = False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e693c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP MATRICES\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04f_maps_allPt/raw\"\n",
    "uplots.plotMatrices(dl = dl_parcel_foi, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'], \n",
    "                    cor = True, save_pth=fig_dir, test=False) # visualize smoothed maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868022e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uplots.plotLine(dl_parcel, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'],\n",
    "            name_append=\"line\", \n",
    "            parc=['glasser', 'DK25'], stat = ['mean', 'mean'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04f_maps_allPt/raw\",\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=False)\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_allPt\") # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b64e",
   "metadata": {},
   "source": [
    "# Within study, vertex/parcel-wise statistics (z-, w- scores)\n",
    "- compares _all_ participants to controls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z, w scores within studies (all participants vs control distribution)\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "# import smoothed maps\n",
    "reimport_src = False\n",
    "test = False\n",
    "save_name = \"05a_winStudy\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04e_dl_maps_parcel_20Oct2025-084257.pkl\"\n",
    "    dl = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "#tsutil.print_dict(dl_parcel, df_print=False)\n",
    "\n",
    "# calculate statistics\n",
    "dl_winComp = tsutil.winComp(dl = dl_parcel, demographics = demographics, keys_maps = ['df_maps', 'df_maps_parc-glsr', 'df_maps_parc-glsr_mean', 'df_maps_parc-dk25', 'df_maps_parc-dk25_mean'], \n",
    "                            col_grp = specs['col_grp'], ctrl_grp = ctrl_grp, \n",
    "                            out_df_save_pth = specs['prjDir_root'] + specs['prjDir_winComp_dfs'],\n",
    "                            stat=specs['winComp_stats'], covars = specs['covars'], key_demo = 'df_demo',\n",
    "                            save = True, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                            verbose = True, dlPrint = False, test=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879395f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z, w score maps\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = False\n",
    "test = False\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp/raw\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_20Oct2025-084311.pkl\"\n",
    "    dl_winComp = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] winComp dict list loaded from {pth}\")\n",
    "\n",
    "# TODO. Add smart plotting based on parameters listed in specs dictionary\n",
    "dfs_toPlot = ['df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z']\n",
    "\n",
    "uplots.plotMatrices(dl = dl_winComp, df_keys = dfs_toPlot, name_append=True, save_pth=fig_dir, test=test) # visualize winCompStat maps\n",
    "uplots.plotLine(dl_winComp, df_keys = dfs_toPlot, \n",
    "            parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=fig_dir,\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=test)\n",
    "\n",
    "# TODO. Allow integration of pdf for large images\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef774a1",
   "metadata": {},
   "source": [
    "# Select group of interest and ipsi/contra flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary list based on previous dl.\n",
    "# New dl will have the same number of dictionary items (one for each study, ft, label, surf, smth, region combination).\n",
    "#   Keys of each dictionary items may change. One df for each combination of [group[len(goi)] x lateralization[_R, _L, _ic] + 1 (ctrl)] x stat[<_z>, <_w>]] \n",
    "#   If df_{stat} is none, nothing regarding this statistic will be added to dict item.\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# import\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_20Oct2025-084311.pkl\"\n",
    "\n",
    "if 'dl_winComp' not in globals() or dl_winComp is None or reimport_src:\n",
    "    dl_winComp = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "goi = [\"TLE\"] # group(s) of interest. Store main diagnosis abrev in list to allow for multiple groups\n",
    "koi = ['df_maps_z', 'df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z'] # keys of dl_winComp to use\n",
    "test = False\n",
    "save_name = \"05b_stats_winStudy_grp\"\n",
    "verbose = True\n",
    "\n",
    "dl_grp_ic = tsutil.grp_flip(dl = dl_winComp, demographics = demographics, \n",
    "                            goi = goi, df_keys = koi,\n",
    "                    col_grp = specs['col_grp'], save_pth_df = specs['prjDir_root'] + specs['prjDir_grpFlip_dfs'],\n",
    "                    save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name, test=test, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea4932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tsutil.loadPickle(dl_winComp[5]['df_maps_parc-glsr_z'])\n",
    "indices = df_test.columns.tolist()\n",
    "print(f\"{len(indices)}: {indices}\")\n",
    "# print number of repeated indices\n",
    "print(f\"Number of repeated indices: {len(indices) - len(set(indices))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_20Oct2025-084554.pkl\"\n",
    "printDl = True\n",
    "\n",
    "test = False\n",
    "dfs_toPlot = ['df_maps_parc_glsr_mdn_z_TLE_ic', 'df_maps_parc_dk25_mdn_z_TLE_ic']\n",
    "foi = [\"thickness\", \"T1map\", 'flair'] # features of interest\n",
    "loi = ['midthickness', 'white', 'inner', 'outer'] # surfaces of interest\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStudy_grp/raw\"\n",
    "\n",
    "\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport_src:\n",
    "    dl_grp_ic = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "dl_interest = [d for d in dl_grp_ic if d['feature'] in foi and d['label'] in loi]\n",
    "\n",
    "if printDl:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl_interest, df_print=False)\n",
    "\n",
    "uplots.plotMatrices(dl = dl_interest, df_keys = dfs_toPlot, \n",
    "                    name_append=True, save_pth=fig_dir, test=test) # visualize z score maps\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStat_ic\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n",
    "uplots.plotLine(dl_interest, df_keys = dfs_toPlot,\n",
    "                name_append=\"line\",\n",
    "                parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "                hlines = [[60,120,240,300], None],\n",
    "                save_pth=fig_dir, spacing = None,\n",
    "                marks=False, alpha = 0.6,\n",
    "                test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb52c",
   "metadata": {},
   "source": [
    "# Within study Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "save = True\n",
    "save_name = \"05c_stats_winD\"\n",
    "\n",
    "koi = ['df_maps_z',  'df_maps_parc-glsr_mean_z', 'df_maps_parc-dk25_mean_z']\n",
    "goi = ['TLE_ic']\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_20Oct2025-084554.pkl\"\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport == True:\n",
    "    dl_grp_ic = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "winD = tsutil.winD(dl = dl_grp_ic, df_keys = koi, save_pth_df = specs['prjDir_root'] + specs['prjDir_winD_dfs'],\n",
    "                   ipsiTo = specs.get('ipsiTo', 'L'), \n",
    "                   save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                   verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63817138",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(winD, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1332b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsutil.loadPickle(winD[5]['df_maps_z_d_ic'])\n",
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrices\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD/raw\"\n",
    "uplots.plotMatrices(dl = winD, df_keys = 'df_d', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "uplots.plotMatrices(dl = winD, key = 'df_d_ic', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir = save_pth, output = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847ea6",
   "metadata": {},
   "source": [
    "# Between study: D-score differences\n",
    "- Identify pairs of dictionary items\n",
    "- Extract d scoring statitics and compute:\n",
    "- raw d dif\n",
    "- d dif / ctrl d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "verbose = True\n",
    "save_name = \"05d_btwD\"\n",
    "\n",
    "# import \n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05c_stats_winD_20Oct2025-110828.pkl\"\n",
    "if 'winD' not in globals() or winD is None or reimport == True:\n",
    "    winD = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "comps = tsutil.btwD(dl = winD, koi = [\"df_maps_z_d\", \"df_maps_z_d_ic\", \n",
    "                                           \"df_maps_parc-glsr_mean_z_d\", \"df_maps_parc-glsr_mean_z_d_ic\",\n",
    "                                           \"df_maps_parc-dk25_mean_z_d\", \"df_maps_parc-dk25_mean_z_d_ic\"], \n",
    "                    save_pth_df = specs['prjDir_root'] + specs['prjDir_btwD_dfs'],\n",
    "                    save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                    verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f3312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(comps, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comps[5]['comps_df_maps_z_d_ic']\n",
    "df = tsutil.loadPickle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa2ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
