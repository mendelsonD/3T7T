{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c70860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tTsTGrpUtils' from '/host/verges/tank/data/daniel/3T7T/z/code/analyses/tTsTGrpUtils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import pickle\n",
    "importlib.reload(tsutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49b54c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge plots for individual patients, import dictionary lists with raw maps\n",
    "# import dictionary lists with raw maps\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/maps/dictLists\"\n",
    "file = \"/01_maps_08Sep2025-100948.pkl\"\n",
    "\n",
    "with open(pth + file, \"rb\") as f:\n",
    "    dl = pickle.load(f)\n",
    "\n",
    "demographics = {\n",
    "    \"pth\" : \"/host/verges/tank/data/daniel/3T7T/z/data/pt/demo_27Aug2025.csv\",\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable of interest\n",
    "}\n",
    "#tsutil.print_dict(dl, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge plots\n",
    "for i in range(len(dl)):\n",
    "    df_demo = dl[i]['df_demo']\n",
    "    df_maps = dl[i]['df_maps']\n",
    "    label = dl[i]['label']\n",
    "    surface = dl[i]['surf']\n",
    "    region = dl[i]['region']\n",
    "    feature = dl[i]['feature']\n",
    "    study = dl[i]['study']\n",
    "    smth = dl[i]['smth']\n",
    "    print(f\"[{study}] {region}, {feature}, {label}, {surface} , {smth}\")\n",
    "\n",
    "    #print(df_maps.columns)\n",
    "    col_ID = tsutil.get_IDCol(study, demographics)\n",
    "\n",
    "    # rename col_ID as ID\n",
    "    df_demo.rename(columns={col_ID: 'id'}, inplace=True)\n",
    "\n",
    "    # remove ID, SES cols\n",
    "    df_maps['ID_SES'] = df_maps[col_ID].astype(str) + '_' + df_maps['SES'].astype(str) # concat ID and SES into single col\n",
    "    df_maps.set_index('ID_SES', inplace=True)\n",
    "    df_maps.drop([col_ID, 'SES'], axis=1, inplace=True)\n",
    "\n",
    "    df_maps.head()\n",
    "\n",
    "    # add a row to df_maps that randomly samples from a normal distribution centered around the mean of each column\n",
    "    means = df_maps.mean(axis=0)\n",
    "    stds = df_maps.std(axis=0)\n",
    "    random_row = np.random.normal(loc=means, scale=stds)\n",
    "    random_row_df = pd.DataFrame([random_row], index=['random_sample'], columns=df_maps.columns)\n",
    "    df_maps = pd.concat([df_maps, random_row_df])\n",
    "    # add also a row to df_demo with'grp_detailed' = 'random_sample'\n",
    "    df_demo = pd.concat([df_demo, pd.DataFrame({'grp_detailed': ['random_sample']})], ignore_index=True)\n",
    "    df_demo.set_index(df_maps.index, inplace=True)\n",
    "\n",
    "    # plot ridgeplot\n",
    "    # get range\n",
    "    min_val = means.mean() - 10 * stds.mean()\n",
    "    max_val = means.mean() + 10 * stds.mean()\n",
    "\n",
    "    tsutil.plot_ridgeplot(df_maps, matrix_df=df_demo[['id','SES','grp_detailed']], Range=(min_val, max_val), Xlab = f\"[{study}] {region}, {feature}, {label}, {surface}, {smth}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w(map_ctrl, demo_ctrl, map_test, demo_test, covars, verbose=False):\n",
    "    \"\"\"\n",
    "    Efficiently compute W-scores for patient maps based on control maps and demographics.\n",
    "    Supports 2D DataFrames for map_ctrl and map (n_subjects x n_vertices).\n",
    "\n",
    "    Input:\n",
    "        map_ctrl: DataFrame (n_controls x n_vertices)\n",
    "        demo_ctrl: DataFrame (n_controls x covariates)\n",
    "        map_test: DataFrame (n_subjects x n_vertices)\n",
    "        demo_test: DataFrame (n_subjects x covariates)\n",
    "        covars: list of covariate column names\n",
    "        verbose: bool, whether to print progress messages\n",
    "\n",
    "    Output:\n",
    "        w: DataFrame (n_subjects x n_vertices)\n",
    "        model: DataFrame (regression coefficients and residual std per vertex)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Prepare covariate matrices\n",
    "    X_ctrl = demo_ctrl[covars].values.astype(float)\n",
    "    X_ctrl = np.hstack([np.ones((X_ctrl.shape[0], 1)), X_ctrl])  # add intercept column\n",
    "\n",
    "    X_test = demo_test[covars].values.astype(float)\n",
    "    X_test = np.hstack([np.ones((X_test.shape[0], 1)), X_test])  # add intercept column\n",
    "\n",
    "    # Prepare output containers\n",
    "    models = pd.DataFrame(\n",
    "        index=['intercept'] + [str(c) for c in covars] + ['resid_std'], # creates n_covar + 2 rows\n",
    "        columns=map_test.columns # n_vertices columns\n",
    "    )\n",
    "    w = pd.DataFrame(index=map_test.index, columns=map_test.columns)\n",
    "\n",
    "    # Convert map_ctrl and map to numpy arrays\n",
    "    Y_ctrl = map_ctrl.values.astype(float)  # shape: n_controls x n_vertices\n",
    "    Y_test = map_test.values.astype(float)  # shape: n_subjects x n_vertices\n",
    "\n",
    "    # Efficient batch regression for each vertex\n",
    "    for i, col in enumerate(map_test.columns):\n",
    "        if verbose and i % 200 == 0:\n",
    "            print(f\"\\r\\t\\t {(100*(i+1) / len(map_test.columns)):.0f}%\\n\", end=\"\")\n",
    "\n",
    "        y_ctrl = Y_ctrl[:, i] # extract col i\n",
    "        if np.all(y_ctrl == 0):\n",
    "            if verbose:\n",
    "                print(f\"{col} fully 0 in control map. skipping.\")\n",
    "            w[col] = np.nan\n",
    "            models[col] = np.nan\n",
    "            continue\n",
    "\n",
    "        # Fit linear regression\n",
    "        coef, _, _, _ = np.linalg.lstsq(X_ctrl, y_ctrl, rcond=None)\n",
    "        predicted_ctrl = X_ctrl @ coef # shape: n_controls\n",
    "        resid = y_ctrl - predicted_ctrl # shape: n_controls\n",
    "        resid_std = np.std(resid) # shape: 1\n",
    "\n",
    "        # Store model\n",
    "        models.loc[models.index[:-1], col] = coef\n",
    "        models.loc['resid_std', col] = resid_std\n",
    "\n",
    "        # Predict expected values for all subjects\n",
    "        expected = X_test @ coef\n",
    "        w[col] = (Y_test[:, i] - expected) / resid_std # CAREFUL: may not be appropriate to divide by residual_std if fat tails\n",
    "\n",
    "    return w, models\n",
    "\n",
    "def convert_categorical_to_dummy(df, exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Convert categorical (string) columns to dummy codes.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame to process\n",
    "    exclude_cols: List of columns to exclude from conversion\n",
    "    \n",
    "    Returns:\n",
    "    df_converted: DataFrame with categorical variables converted to dummy codes\n",
    "    conversion_log: Dictionary logging all conversions made\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    \n",
    "    df_converted = df.copy()\n",
    "    conversion_log = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "            \n",
    "        # Check if column is non-numeric (contains strings)\n",
    "        if df[col].dtype == 'object' or df[col].dtype.name == 'category':\n",
    "            try:\n",
    "                # Try to convert to numeric first\n",
    "                pd.to_numeric(df[col], errors='raise')\n",
    "            except (ValueError, TypeError):\n",
    "                # Column contains non-numeric values, convert to dummy codes\n",
    "                unique_vals = df[col].dropna().unique()\n",
    "                \n",
    "                if len(unique_vals) == 2:\n",
    "                    # Binary variable - simple 0/1 encoding\n",
    "                    val_map = {unique_vals[0]: 0, unique_vals[1]: 1}\n",
    "                    df_converted[col] = df[col].map(val_map)\n",
    "                    conversion_log[col] = {\n",
    "                        'type': 'binary',\n",
    "                        'mapping': val_map,\n",
    "                        'original_values': list(unique_vals)\n",
    "                    }\n",
    "                    print(f\"[convert_categorical] Binary conversion for '{col}': {val_map}\")\n",
    "                    \n",
    "                elif len(unique_vals) > 2:\n",
    "                    # Multi-category variable - one-hot encoding\n",
    "                    dummies = pd.get_dummies(df[col], prefix=col, dummy_na=False)\n",
    "                    \n",
    "                    # Drop original column and add dummy columns\n",
    "                    df_converted = df_converted.drop(columns=[col])\n",
    "                    df_converted = pd.concat([df_converted, dummies], axis=1)\n",
    "                    \n",
    "                    conversion_log[col] = {\n",
    "                        'type': 'one_hot',\n",
    "                        'new_columns': list(dummies.columns),\n",
    "                        'original_values': list(unique_vals)\n",
    "                    }\n",
    "                    print(f\"[convert_categorical] One-hot encoding for '{col}': {list(unique_vals)} -> {list(dummies.columns)}\")\n",
    "    \n",
    "    return df_converted, conversion_log\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
