{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f4d360",
   "metadata": {},
   "source": [
    "# count number of missing FLAIR volumes\n",
    "\n",
    "Output:\n",
    "Table. Each UID is a row. Cols: # ses @ each study, # FLAIR images @ each study, # T1w/T1map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/02c_mapPths_QC_26Sep2025-104109.csv\"\n",
    "df = pd.read_csv(df_pth, dtype=str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nImgbyID(root, ID, voi, verbose=False):\n",
    "    \"\"\"\"\n",
    "    Count number of images by ID and session for each volume of interest.\n",
    "    Checks for existing files that contain the string in voi and end with '.nii.gz'\n",
    "\n",
    "    Input:\n",
    "        root:\n",
    "            root dir of study\n",
    "        study_id:\n",
    "            ID of participant in study\n",
    "        voi:\n",
    "            volumes of interest to count\n",
    "\n",
    "    Returns:\n",
    "        list with len(voi) with number of images for each volume\n",
    "    \"\"\"\n",
    "    # structure of BIDS:\n",
    "    ## /sub-{ID}/ -> list of sessions. For each of these folders, look for the voi files. Handle just anat files for now\n",
    "    import os\n",
    "    import glob\n",
    "    import pandas as pd\n",
    "    out = []\n",
    "\n",
    "    sub_dirs = glob.glob(f\"{root}/sub-{ID}/*/\") # get list of session dirs\n",
    "    nSes = len(sub_dirs)\n",
    "    if verbose:\n",
    "        print(\"-\"*40)\n",
    "        print(f\"[nImgbyID] {ID} has {nSes} sessions: {sub_dirs}\")\n",
    "    for v in voi:\n",
    "        nImg = 0\n",
    "        for ses in sub_dirs:\n",
    "            # look for files in ses/anat that contain v and end with .nii.gz\n",
    "            anat_dir = os.path.join(ses, 'anat')\n",
    "            if os.path.exists(anat_dir):\n",
    "                files = glob.glob(f\"{anat_dir}/*{v}*.nii*\")\n",
    "                if len(files) > 1:\n",
    "                    if verbose:\n",
    "                        print(f\"[nImgbyID] WARNING: {ID} {ses} found {len(files)} {v} files: {files}\")\n",
    "                    \n",
    "                    nImg += 1 # count only once\n",
    "                else: \n",
    "                    nImg += len(files)\n",
    "                if verbose:\n",
    "                    print(f\"[nImgbyID] {ID} {ses} {v}: found {len(files)} files: {files}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"[nImgbyID] {ID} {ses} has no anat dir: {anat_dir}\")\n",
    "        out.append(nImg)\n",
    "    if verbose:\n",
    "        print(f\"[nImgbyID] {ID}: {voi} = {out}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df_out with Each UID is a row. Cols: # ses @ each study\n",
    "studies = df['study'].unique()\n",
    "df_out = df[['UID', 'study', 'MICS_ID', 'PNI_ID']].drop_duplicates().reset_index(drop=True)\n",
    "voi = ['FLAIR', 'T1w', 'T1map'] # volumes of interest\n",
    "# create col study ID for each row\n",
    "df_out['study_ID'] = df_out.apply(lambda row: row['MICS_ID'] if row['study']=='3T' else row['PNI_ID'] if row['study']=='7T' else 'UNKNOWN STUDY', axis=1)\n",
    "\n",
    "roots = {\n",
    "    '3T': '/data/mica3/BIDS_MICs/rawdata',\n",
    "    '7T': '/data/mica3/BIDS_PNI/rawdata'\n",
    "}\n",
    "\n",
    "\n",
    "# include 3T, 7T IDs\n",
    "for study in studies:\n",
    "    df_study = df[df['study'] == study]\n",
    "    df_study_count = df_study.groupby('UID').size().reset_index(name=f'nSES_{study}')\n",
    "    df_out = df_out.merge(df_study_count, on='UID', how='left')\n",
    "    root = roots[study]\n",
    "    if study == '7T' and 'T1w' in voi:\n",
    "        voi_iterate = voi.copy()  # create a copy of the list\n",
    "        voi_iterate[voi_iterate.index('T1w')] = 'UNIT1'  # replace T1w with UNIT1 in PNI\n",
    "    else:\n",
    "        voi_iterate = voi\n",
    "\n",
    "    # count number of each raw volume \n",
    "    new_cols = [f'n{v}_{study}' for v in voi_iterate]\n",
    "    df_out[new_cols] = 0 # initialize cols\n",
    "    \n",
    "    ids = df_out[df_out['study'] == study]['study_ID'].unique()\n",
    "    for id in ids:\n",
    "        nVols = nImgbyID(root, id, voi_iterate, verbose=True)\n",
    "        df_out.loc[df_out['study_ID'] == id, new_cols] = nVols\n",
    "\n",
    "if save:\n",
    "    sv_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/flair_T1w_T1map_counts_byID_29Sep2025.csv\"\n",
    "    df_out.to_csv(sv_pth, index=False)\n",
    "    print(f\"[main] df_out saved to {sv_pth}\")\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae113a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
