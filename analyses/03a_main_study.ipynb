{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6e2da",
   "metadata": {},
   "source": [
    "# Comparisons betweeon studies\n",
    "\n",
    "Steps:   \n",
    "1. CLEAN DATA\n",
    "1. SELECT SESSIONS\n",
    "1. ANALYSES\n",
    "    - (visualize unsmoothed, smoothed maps)\n",
    "    - within study TLE vs CTRL comparison\n",
    "        - extract smoother maps\n",
    "        - compute z, w scores (values per participant)\n",
    "        - group and flip\n",
    "        - Cohen's D (compare TLE and control z/w score distributions within each vertex)\n",
    "    - between study 7T vs 3T comparison      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import tTsTGrpUtils as tsutil\n",
    "import utils_plots as uplots\n",
    "\n",
    "lab = True\n",
    "save = True\n",
    "verbose = True\n",
    "toPrint = True\n",
    "\n",
    "test = False\n",
    "test_frac = 0.1 # fraction of demo to use for testing if test=True\n",
    "\n",
    "includeBL = False # if should include bilateral TLE patients (with one side higher than other) in analyses\n",
    "\n",
    "if lab: # define root paths to source files\n",
    "    src_dir = \"/host/verges/tank/data/daniel/3T7T/z/data/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "    if save:\n",
    "        save_pth = save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs\"\n",
    "else:\n",
    "    src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "    if save:\n",
    "        save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "\n",
    "\n",
    "# For each sheet, must define NAME, PATH, SHEET, ID_7T, ID_3T. \n",
    "# All other keys are those to be extracted.\n",
    "# The same variables should have the same key names across sheets.\n",
    "PNI = {\n",
    "    'NAME': 'PNI',\n",
    "    'PATH': f'{src_dir}/MICA_PNI_06Oct2025.xlsx', # 7T controls\n",
    "    'SHEET': 'all', # name of sheet in file\n",
    "    'ID_7T': 'ID_PNI', \n",
    "    'ID_3T': 'ID_MICs',\n",
    "    'Ses_7T': 'session',\n",
    "    'Date_7T': 'scanDate',\n",
    "    'study': '7T',\n",
    "    'DOB': 'dob',\n",
    "    'Sex': 'sex',\n",
    "    'Gender': 'gender',\n",
    "    'Hand': 'handedness',\n",
    "    'Eth': 'ethnicity',\n",
    "    'Language': 'language',\n",
    "    'Job': 'employment',\n",
    "    'Edu': 'education',\n",
    "    'LastSz': 'lastSeizure',\n",
    "}\n",
    "\n",
    "MICs = {\n",
    "    'NAME': 'MICs',\n",
    "    'PATH': f'{src_dir}/MICA-MTL-3T_06Oct2025.xlsx', # 3T controls\n",
    "    'SHEET': 'Sheet1', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'Study_name',\n",
    "    'Ses_3T': 'Visit',\n",
    "    'Date_3T': 'Scan_Date (D.M.Y)',\n",
    "    'study': '3T',\n",
    "    'Hand': 'Handed', \n",
    "    'Sex': 'AssignedSex',\n",
    "    'Gender': 'GenderIdentity',\n",
    "    'Height': 'HeightApprox',\n",
    "    'Weight': 'WeightApprox',\n",
    "    'Eth': 'Ethnicity',\n",
    "    'Job': 'Employ',\n",
    "    'Edu': 'YoE',\n",
    "    'LastSz': 'Last seizure'\n",
    "}\n",
    "\n",
    "Clin = {\n",
    "    'NAME': 'Clin',\n",
    "    'PATH': f'{src_dir}/Clinical_06Oct2025.xlsx',\n",
    "    'SHEET': 'clinical-database-detailed', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'participant_id',\n",
    "    'Date_3T': None,\n",
    "    'Gender': 'Gender',\n",
    "    'Hand': 'Handedness',\n",
    "    'Language': 'Language',\n",
    "    'Job': 'Employment',\n",
    "    'Edu': 'Education',\n",
    "    'EpilepsyDxILAE': 'Epilepsy diagnosis based on ILAE',\n",
    "    'EpilepsyClass': 'Epilepsy classification:Focal,Generalized',\n",
    "    'FocusLat': 'Lateralization of epileptogenic focus',\n",
    "    'FocusConfirmed': 'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)',\n",
    "    'EMUDischargeDx': 'Dx at EMU discharge ',\n",
    "    'EMUAdmissionDate': 'EMU admission date(dd-mm-yy)',\n",
    "    'AdmissionDuration': 'Duration of admission',\n",
    "    'EpilepsyRiskFactors': 'Risk factors for epilepsy',\n",
    "    'SeizureOnsetYr': 'Seizure onset (yr)',\n",
    "    'DrugResistant': 'Drug resistant epilepsy at time of EMU admission',\n",
    "    'NumASMsPrior': '# of ASMs prior current EMU admission',\n",
    "    'PrevASMs': 'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission',\n",
    "    'NumASMOnAdmission': '# of ASM on admission',\n",
    "    'ASMsOnAdmission': 'ASMs  on admission (name, doses (mg per day)',\n",
    "    'GeneticTest': 'Genetic test (year,results)',\n",
    "    'FDGPET': 'FDG.PET',\n",
    "    'BaselineMRI': 'Baseline MRI (year,results)',\n",
    "    'InvasiveExplorations': 'Invasive explorations (Y/N)',\n",
    "    'NumSurgicalResections': '# of surgical resection/thermocoagulatin',\n",
    "    'SurgicalResectionDateSite': 'Surgical resection date and site',\n",
    "    'Histopathology': 'Histopatholgy',\n",
    "    'Engel6mo': 'Engel classification (seizure outcomes at the 6 month )',\n",
    "    'Engel1yr': 'Engel classification (seizure outcomes after 1 year from surgical resection)',\n",
    "    'ILAEOutcome1yr': 'ILAE outcome after surgical resection by 1 yr',\n",
    "    'NeuromodDevices': 'Neuromodulation devices'\n",
    "    }\n",
    "\n",
    "sheets = [PNI, MICs, Clin]\n",
    "\n",
    "# QC sheets\n",
    "PNI_QC= { # details of sheet with QC info on 7T surface segmentation\n",
    "    \"PATH\":f\"{src_dir}/7T_processing_26Sept2025.xlsx\",\n",
    "    \"SHEET\":\"Proc_newDays\",\n",
    "    \"ID_7T\": \"Subjec_ID\",\n",
    "    \"SES\": \"Session \",\n",
    "    \"QC_col\": \"Comments \" # NOTE values are free-form strings. Only present for some rows that should be checked myself. Other row's segmentations can be assumed good.\n",
    "}\n",
    "\n",
    "MICs_QC = { # details of sheet with QC info on 3T surface segmentation\n",
    "    \"PATH\":f\"{src_dir}/BIDS_MICs_QC_logs_26Sept2025.xlsx\", \n",
    "    \"SHEET\":\"Sheet1\",\n",
    "    \"ID_3T\": \"ID\",\n",
    "    \"SES\": \"ses\",\n",
    "    \"QC_col\": \"surface quality\" # NOTE 0 < values < 2 0=unacceptable, 2=acceptable\n",
    "}\n",
    "\n",
    "\n",
    "##### ANALYSIS SPECIFICATIONS #####\n",
    "\n",
    "# Demographics details\n",
    "demographics = {\n",
    "    \"df_pths_qc_pth\" : \"/host/verges/tank/data/daniel/3T7T/z/outputs/03b_mapPths_QC_18Oct2025-153753.csv\", # NOTE: path to demographics file with merged QC cols produced by 02_demo.ipynb\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "# Study details\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "# Analysis details\n",
    "specs  = { # all spec values to be in lists to allow for iteration across these values\n",
    "    # directories\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/3T7T/z\", \n",
    "    'prjDir_outs' : \"/outputs\",\n",
    "    'prjDir_out_stats': \"/outputs/stats\",\n",
    "    'prjDir_out_figs': \"/outputs/figures\",\n",
    "    'prjDir_maps': \"/maps\", # output directory for smoothed cortical maps\n",
    "    'prjDir_dictLists': \"/maps/dictLists\",\n",
    "    'prjDir_mapPths' : \"/output/paths\",\n",
    "    'prjDir_maps_dfs': \"/outputs/dfs/04a_maps_dfs\",\n",
    "    'prjDir_parc_dfs': \"/outputs/dfs/04b_maps_parc\",\n",
    "    'prjDir_winComp_dfs': \"/outputs/dfs/05a_winComp\",\n",
    "    'prjDir_grpFlip_dfs': \"/outputs/dfs/05b_grpFlip\",\n",
    "    'prjDir_winD_dfs': \"/outputs/dfs/05c_winD\",\n",
    "    'prjDir_btwD_dfs': \"/outputs/dfs/05d_btwComp\",\n",
    "\n",
    "    # downsampling\n",
    "    'ds_study': ['PNI'], # list of study codes to apply downsampling to\n",
    "    'ds_foi': ['T1map'], # features to downsample\n",
    "    'ds_res': [0.8], # resolution (in mm) to downsample volumes to. NOTE. should be same length as ds_foi with each value corresponding to that in ds_foi \n",
    "    'ds_vol_dir': '/downsampled_vols', # name of directory within project dir root\n",
    "\n",
    "    # analysis regions\n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-32k', 'fsLR-5k'],\n",
    "    'parcellate_ctx': 'glasser', # parcellation to use, or None if no parcellation.\n",
    "    'parc_lbl_ctx': 'glasser_int', # what name to fetch for parcellation values\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['den-0p5mm'],\n",
    "    'parcellate_hipp': 'DK25',\n",
    "    'parc_lbl_hipp': 'idx',\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "        \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'winComp_stats': ['z'], # what stats to run for within study comparisons ('z' for z-scoring, 'w' for w-scoring)\n",
    "    'covars': [demographics['age'], demographics['sex']],\n",
    "\n",
    "    'ipsiTo' : 'L', # what hemisphere for controls ipsi should be mapped to\n",
    "    'newQC': True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7415fd6",
   "metadata": {},
   "source": [
    "# Clean data\n",
    "1. [removal]     Ensure that there is at least one QC_surf-vol column with a value above 0\n",
    "1. [amend]      Missing one hemisphere pair, make complimentary hemisphere NA (to prevent unbalanced analyses) \n",
    "1. [removal]     NA for all smoothed maps\n",
    "1. [removal]    Missing one study (3T or 7T) for a given ID-SES combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# LOAD\n",
    "pth = demographics[\"df_pths_qc_pth\"]\n",
    "df_pths = pd.read_csv(pth, dtype=str)\n",
    "print(f\"[main] df_pths loaded from {pth}\")\n",
    "\n",
    "# i. Ensure that all cases have usable data (QC value), data for both hemis present, each subject has data for both studies\n",
    "df_clean, df_cln_pth, df_rmv, df_rmv_pth = tsutil.clean_demoPths(df_pths, nStudies=2, \n",
    "                                                   save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", \n",
    "                                                   save_name = \"03c_demoPths\", verbose=False)\n",
    "# note can cause duplicated rows\n",
    "demographics['df_pths_qc_clean_pth'] = df_cln_pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b2572",
   "metadata": {},
   "source": [
    "# 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample T1maps from 7T study\n",
    "# 3 Steps:\n",
    "# i. Downsample 7T maps\n",
    "# ii. Compute feature maps\n",
    "# iii. add map paths to df_pths\n",
    "# TODO can parallelize these functions to speed up computation\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "test = False\n",
    "reimport_src = True\n",
    "df_input_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/03c_demoPths_clean_17Oct2025-144320.csv\"\n",
    "verbose = False\n",
    "override = False # if should override existing downsampled volumes / maps\n",
    "\n",
    "df_volPths_saveName = \"04b_dfPths_dsVols\"\n",
    "df_mapsPths_saveName = \"04c_dfPths_dsMaps\"\n",
    "\n",
    "if 'df_clean' not in globals() or df_clean is None or reimport_src == True:\n",
    "    df_clean = pd.read_csv(df_input_pth, dtype=str)\n",
    "#print(f\"df <{df_clean.shape}> {type(df_clean)} {df_clean.columns}\")\n",
    "\n",
    "if test:\n",
    "    df_clean_iter = df_clean.sample(frac=test_frac, random_state=42)\n",
    "else:\n",
    "    df_clean_iter = df_clean.copy()\n",
    "\n",
    "if test:\n",
    "    print(f\"TEST mode. Using fraction {test_frac} of data: {df_clean_iter.shape[0]} of {df_clean.shape[0]} rows.\")\n",
    "    df_volPths_saveName = \"TEST_\" + df_volPths_saveName\n",
    "    df_mapsPths_saveName = \"TEST_\" + df_mapsPths_saveName\n",
    "\n",
    "# i. Downsample\n",
    "df_clean_iter = tsutil.downsample_df(df = df_clean_iter, studies = studies, specs = specs,\n",
    "                             demographics = demographics,\n",
    "                             df_save_name = df_volPths_saveName,\n",
    "                             override = False, verbose = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "# ii. Map\n",
    "tsutil.get_dsMaps(df = df_clean_iter, \n",
    "                  specs = specs,\n",
    "                  studies = studies,\n",
    "                  demographics = demographics,\n",
    "                  verbose = verbose,\n",
    "                  override = False)\n",
    "\n",
    "print(f\"\\n\" + (\"=\"*100) + f\"\\n\")\n",
    "\n",
    "df_clean_ds, df_svPth = tsutil.get_dsMaps_pths_iter(df_pths = df_clean_iter, specs = specs, \n",
    "                                                    demographics = demographics, studies=studies,\n",
    "                                                    save_name = df_mapsPths_saveName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af51eff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1486089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MAPS INTO DICTIONARY LISTS\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "save_name = \"04d_dl_maps\"\n",
    "\n",
    "if 'df_clean_ds' not in globals() or df_clean_ds is None or reimport_src == True:\n",
    "    df_svPth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dfPths_dsMaps_18Oct2025-153936.csv\"\n",
    "    df_clean_ds = pd.read_csv(df_svPth, dtype=str)\n",
    "\n",
    "# find all map cols\n",
    "cols_L, cols_R = tsutil.get_mapCols(df_clean_ds.columns, verbose=True)\n",
    "\n",
    "# extract maps as appropriate\n",
    "if specs['ctx']:\n",
    "    ctx_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R,\n",
    "                               specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                               save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                               region = \"cortex\", verbose=True, test = test)\n",
    "else:\n",
    "    ctx_dl = []\n",
    "print(\"-\"*100)\n",
    "if specs['hipp']:\n",
    "    hipp_dl = tsutil.extractMap(df_mapPaths = df_clean_ds, cols_L = cols_L, cols_R = cols_R, \n",
    "                                specs = specs, studies = studies, demographics = demographics, qc_thresh = 2,\n",
    "                                save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                                region = \"hippocampus\", verbose=True, test = test)\n",
    "else:\n",
    "    hipp_dl = []\n",
    "\n",
    "# Create single dl \n",
    "dl = ctx_dl + hipp_dl\n",
    "\n",
    "len_unsmth = len([d for d in ctx_dl + hipp_dl if d['smth'] == 'NA'])\n",
    "len_smth = len([d for d in ctx_dl + hipp_dl if d['smth'] != 'NA'])\n",
    "print(f\"\\n[main] {len(dl)} dictionary items for this study-feature-label-surface pairs\\n\\t{len_unsmth} with smoothing == NA | {len_unsmth} with smoothing\")\n",
    "\n",
    "if save:\n",
    "    out_pth = tsutil.savePickle(obj = dl, root = save_pth, name = save_name, test = test)\n",
    "\n",
    "if toPrint:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl)\n",
    "\n",
    "# NOTE. columns with no rows are not kept in dictionary list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = tsutil.loadPickle(\"/host/verges/tank/data/daniel/3T7T/z/outputs/04d_dl_maps_18Oct2025-154136.pkl\")\n",
    "tsutil.print_dict(dl, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a920d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcellate maps\n",
    "importlib.reload(tsutil)\n",
    "reimport_src = False\n",
    "save_name = \"04e_dl_maps_parcel\"\n",
    "test = False\n",
    "verbose = False\n",
    "\n",
    "if 'dl' not in globals() or dl is None or reimport_src:\n",
    "    src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04d_dl_maps_18Oct2025-143216.pkl\"\n",
    "    dl = tsutil.loadPickle(src_pth)\n",
    "\n",
    "#tsutil.print_dict(dl)\n",
    "\n",
    "if specs['parcellate_ctx'] is not None or specs['parcellate_hipp'] is not None: # for each item, create a df_parc   \n",
    "    region_parc = [{'region': 'cortex', \n",
    "                    'parcellate': specs.get('parcellate_ctx', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_ctx', None)}, \n",
    "                   \n",
    "                   {'region': 'hippocampus',\n",
    "                    'parcellate': specs.get('parcellate_hipp', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_hipp', None)}]\n",
    "    \n",
    "    # TODO. Also parcellate without summarizing accross parcels\n",
    "    dl_parcel, region_parc = tsutil.parcellate_items(dl, df_keys=['df_maps'], parcellationSpecs = region_parc, df_save_pth = specs['prjDir_root'] + specs['prjDir_parc_dfs'],\n",
    "                                                    stats = ['none', 'mean'],\n",
    "                                                    save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", save_name=save_name,\n",
    "                                                    verbose=verbose, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a29921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_parc = tsutil.loadPickle(\"/host/verges/tank/data/daniel/3T7T/z/outputs/04e_dl_maps_parcel_18Oct2025-145331.pkl\")\n",
    "importlib.reload(tsutil)\n",
    "dl_parcel_foi = tsutil.filt_dl(dl_parcel, key_ft = 'feature', foi = ['T1map'])\n",
    "tsutil.print_dict(dl_parcel_foi, df_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS about vertices within parcels\n",
    "# To help select mean or median summarization\n",
    "\"\"\"\n",
    "# TODO. Appears broken\n",
    "import importlib\n",
    "import utils_parc as up\n",
    "importlib.reload(up)\n",
    "\n",
    "reimport_src = False\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-112622.pkl\"\n",
    "    dl_parcel = tsutil.loadPickle(pth)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04e_parcel_distr\"\n",
    "koi = \"df_maps_parc-dk25\"\n",
    "up.parcel_stats(dl = dl_parcel, key = koi, sv_root = save_pth, test = False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e693c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP MATRICES\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "# create pngs\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04f_maps_allPt/raw\"\n",
    "uplots.plotMatrices(dl = dl_parcel, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'], save_pth=fig_dir, test=False) # visualize smoothed maps\n",
    "\n",
    "print(\"Should visually inspect maps, identifying feature-ID-SES combinations that are outliers. Mark for removal [editing <path/to/file name.xlsx> and rerun from step 3.\")\n",
    "print(\"=\"*75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uplots.plotLine(dl_parcel, df_keys = ['df_maps_parc-glsr_mean', 'df_maps_parc-dk25_mean'],\n",
    "            name_append=\"line\", \n",
    "            parc=['glasser', 'DK25'], stat = ['mean', 'mean'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04f_maps_allPt/raw\",\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=False)\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_allPt\") # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b64e",
   "metadata": {},
   "source": [
    "# Within study, vertex/parcel-wise statistics (z-, w- scores)\n",
    "- compares _all_ participants to controls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d881d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs['prjDir_root'] + specs['prjDir_winComp_dfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z, w scores within studies (all participants vs control distribution)\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "# import smoothed maps\n",
    "reimport_src = False\n",
    "test = False\n",
    "save_name = \"05a_winStudy\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-181931.pkl\"\n",
    "    dl = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "#tsutil.print_dict(dl_parcel, df_print=False)\n",
    "\n",
    "# calculate statistics\n",
    "dl_winComp = tsutil.winComp(dl = dl_parcel, demographics = demographics, keys_maps = ['df_maps', 'df_maps_parc_glsr_mdn', 'df_maps_parc_glsr_mean', 'df_maps_parc_dk25_mdn', 'df_maps_parc_dk25_mean'], col_grp = specs['col_grp'], ctrl_grp = ctrl_grp, \n",
    "                            out_df_save_pth = specs['prjDir_root'] + specs['prjDir_winComp_dfs'],\n",
    "                            stat=specs['winComp_stats'], covars = specs['covars'], key_demo = 'df_demo',\n",
    "                            save = True, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                            verbose = True, dlPrint = False, test=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924452",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(dl_winComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z, w score maps\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = True\n",
    "test = False\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp/raw\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_08Oct2025-110338.pkl\"\n",
    "    dl_winComp = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] winComp dict list loaded from {pth}\")\n",
    "\n",
    "# TODO. Add smart plotting based on parameters listed in specs dictionary\n",
    "dfs_toPlot = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z']\n",
    "\n",
    "uplots.plotMatrices(dl = dl_winComp, df_keys = dfs_toPlot, name_append=True, save_pth=fig_dir, test=test) # visualize winCompStat maps\n",
    "uplots.plotLine(dl_winComp, df_keys = dfs_toPlot, \n",
    "            parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=fig_dir,\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=test)\n",
    "\n",
    "# TODO. Allow integration of pdf for large images\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef774a1",
   "metadata": {},
   "source": [
    "# Select group of interest and ipsi/contra flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary list based on previous dl.\n",
    "# New dl will have the same number of dictionary items (one for each study, ft, label, surf, smth, region combination).\n",
    "#   Keys of each dictionary items may change. One df for each combination of [group[len(goi)] x lateralization[_R, _L, _ic] + 1 (ctrl)] x stat[<_z>, <_w>]] \n",
    "#   If df_{stat} is none, nothing regarding this statistic will be added to dict item.\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# import\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_08Oct2025-110338.pkl\"\n",
    "\n",
    "if 'dl_winComp' not in globals() or dl_winComp is None or reimport_src:\n",
    "    dl_winComp = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "goi = [\"TLE\"] # group(s) of interest. Store main diagnosis abrev in list to allow for multiple groups\n",
    "koi = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z', 'df_maps_parc_glsr_mean_z', 'df_maps_parc_dk25_mean_z'] # keys of dl_winComp to use\n",
    "test = False\n",
    "save_name = \"05b_stats_winStudy_grp\"\n",
    "verbose = True\n",
    "\n",
    "dl_grp_ic = tsutil.grp_flip(dl = dl_winComp, demographics = demographics, \n",
    "                            goi = goi, df_keys = koi,\n",
    "                    col_grp = specs['col_grp'], save_pth_df = specs['prjDir_root'] + specs['prjDir_grpFlip_dfs'],\n",
    "                    save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name, test=test, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_08Oct2025-110654.pkl\"\n",
    "printDl = True\n",
    "\n",
    "test = False\n",
    "dfs_toPlot = ['df_maps_parc_glsr_mdn_z_TLE_ic', 'df_maps_parc_dk25_mdn_z_TLE_ic']\n",
    "foi = [\"thickness\", \"T1map\", 'flair'] # features of interest\n",
    "loi = ['midthickness', 'white', 'inner', 'outer'] # surfaces of interest\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStudy_grp/raw\"\n",
    "\n",
    "\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport_src:\n",
    "    dl_grp_ic = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "dl_interest = [d for d in dl_grp_ic if d['feature'] in foi and d['label'] in loi]\n",
    "\n",
    "if printDl:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl_interest, df_print=False)\n",
    "\n",
    "uplots.plotMatrices(dl = dl_interest, df_keys = dfs_toPlot, \n",
    "                    name_append=True, save_pth=fig_dir, test=test) # visualize z score maps\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStat_ic\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n",
    "uplots.plotLine(dl_interest, df_keys = dfs_toPlot,\n",
    "                name_append=\"line\",\n",
    "                parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "                hlines = [[60,120,240,300], None],\n",
    "                save_pth=fig_dir, spacing = None,\n",
    "                marks=False, alpha = 0.6,\n",
    "                test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb52c",
   "metadata": {},
   "source": [
    "# Within study Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = True\n",
    "test = False\n",
    "toPrint = False\n",
    "save = True\n",
    "save_name = \"05c_stats_winD\"\n",
    "\n",
    "koi = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z']\n",
    "goi = ['TLE_ic']\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_08Oct2025-110654.pkl\"\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport == True:\n",
    "    dl_grp_ic = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "winD = tsutil.winD(dl = dl_grp_ic, df_keys = koi, save_pth_df = specs['prjDir_root'] + specs['prjDir_winD_dfs'],\n",
    "                   ipsiTo = specs.get('ipsiTo', 'L'), \n",
    "                   save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                   verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = winD[5]\n",
    "print(list(df_test.keys()))\n",
    "df_test.get('ipsiTo', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63817138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrices\n",
    "importlib.reload(tsutil)\n",
    "importlib.reload(uplots)\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD/raw\"\n",
    "uplots.plotMatrices(dl = winD[83], key = 'df_d', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "uplots.plotMatrices(dl = winD[83], key = 'df_d_ic', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir = save_pth, output = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847ea6",
   "metadata": {},
   "source": [
    "# Between study: D-score differences\n",
    "- Identify pairs of dictionary items\n",
    "- Extract d scoring statitics and compute:\n",
    "- raw d dif\n",
    "- d dif / ctrl d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "verbose = True\n",
    "save_name = \"05d_btwD\"\n",
    "\n",
    "# import \n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05c_stats_winD_08Oct2025-140529.pkl\"\n",
    "if 'winD' not in globals() or winD is None or reimport == True:\n",
    "    winD = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "comps = tsutil.btwD(dl = winD, save_pth_df = specs['prjDir_root'] + specs['prjDir_btwD_dfs'],\n",
    "                    save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                    verbose = verbose, test = test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
