{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea6e2da",
   "metadata": {},
   "source": [
    "# Comparisons betweeon studies\n",
    "\n",
    "Steps:   \n",
    "--- TO BE MOVED INTO 02_demo -------- \n",
    "1. DEMOGRAPHICS  \n",
    "    - Identify IDs with 3T and 7T    \n",
    "    - Extract clinical information for epilepsy patients  \n",
    "    - Extract demographic information for all participants  \n",
    "1. SMOOTH MAPS\n",
    "1. CLEAN DATA\n",
    "-------------------------------------\n",
    "\n",
    "1. SELECT SESSIONS\n",
    "1. ANALYSES\n",
    "    - (visualize unsmoothed, smoothed maps)\n",
    "    - within study TLE vs CTRL comparison\n",
    "        - extract smoother maps\n",
    "        - compute z, w scores (values per participant)\n",
    "        - group and flip\n",
    "        - Cohen's D (compare TLE and control z/w score distributions within each vertex)\n",
    "    - between study 7T vs 3T comparison      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58849394",
   "metadata": {},
   "source": [
    "# 1. DEMOGRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import datetime\n",
    "import utils_demo\n",
    "import tTsTGrpUtils as tsutil\n",
    "from genUtils import id, gen, t1\n",
    "\n",
    "lab = True\n",
    "save = True\n",
    "verbose = True\n",
    "toPrint = True\n",
    "\n",
    "test = False\n",
    "test_frac = 0.1 # fraction of demo to use for testing if test=True\n",
    "\n",
    "includeBL = False # if should include bilateral TLE patients (with one side higher than other) in analyses\n",
    "\n",
    "if lab: # define root paths to source files\n",
    "    src_dir = \"/host/verges/tank/data/daniel/3T7T/z/data/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/host/verges/tank/data/daniel/\")\n",
    "    if save:\n",
    "        save_pth = save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs\"\n",
    "else:\n",
    "    src_dir = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/PT/sources\" # path to directory with source pt sheets\n",
    "    sys.path.append(\"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/code\")\n",
    "    if save:\n",
    "        save_pth = \"/Users/danielmendelson/Library/CloudStorage/OneDrive-McGillUniversity/Documents/PhD/Boris/projects/3T7T/data/outputs\"\n",
    "\n",
    "\n",
    "# For each sheet, must define NAME, PATH, SHEET, ID_7T, ID_3T. \n",
    "# All other keys are those to be extracted.\n",
    "# The same variables should have the same key names across sheets.\n",
    "PNI = {\n",
    "    'NAME': 'PNI',\n",
    "    'PATH': f'{src_dir}/MICA_PNI_06Oct2025.xlsx', # 7T controls\n",
    "    'SHEET': 'all', # name of sheet in file\n",
    "    'ID_7T': 'ID_PNI', \n",
    "    'ID_3T': 'ID_MICs',\n",
    "    'Ses_7T': 'session',\n",
    "    'Date_7T': 'scanDate',\n",
    "    'study': '7T',\n",
    "    'DOB': 'dob',\n",
    "    'Sex': 'sex',\n",
    "    'Gender': 'gender',\n",
    "    'Hand': 'handedness',\n",
    "    'Eth': 'ethnicity',\n",
    "    'Language': 'language',\n",
    "    'Job': 'employment',\n",
    "    'Edu': 'education',\n",
    "    'LastSz': 'lastSeizure',\n",
    "}\n",
    "\n",
    "MICs = {\n",
    "    'NAME': 'MICs',\n",
    "    'PATH': f'{src_dir}/MICA-MTL-3T_06Oct2025.xlsx', # 3T controls\n",
    "    'SHEET': 'Sheet1', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'Study_name',\n",
    "    'Ses_3T': 'Visit',\n",
    "    'Date_3T': 'Scan_Date (D.M.Y)',\n",
    "    'study': '3T',\n",
    "    'Hand': 'Handed', \n",
    "    'Sex': 'AssignedSex',\n",
    "    'Gender': 'GenderIdentity',\n",
    "    'Height': 'HeightApprox',\n",
    "    'Weight': 'WeightApprox',\n",
    "    'Eth': 'Ethnicity',\n",
    "    'Job': 'Employ',\n",
    "    'Edu': 'YoE',\n",
    "    'LastSz': 'Last seizure'\n",
    "}\n",
    "\n",
    "Clin = {\n",
    "    'NAME': 'Clin',\n",
    "    'PATH': f'{src_dir}/Clinical_06Oct2025.xlsx',\n",
    "    'SHEET': 'clinical-database-detailed', # name of sheet in file\n",
    "    'ID_7T': None, \n",
    "    'ID_3T': 'participant_id',\n",
    "    'Date_3T': None,\n",
    "    'Gender': 'Gender',\n",
    "    'Hand': 'Handedness',\n",
    "    'Language': 'Language',\n",
    "    'Job': 'Employment',\n",
    "    'Edu': 'Education',\n",
    "    'EpilepsyDxILAE': 'Epilepsy diagnosis based on ILAE',\n",
    "    'EpilepsyClass': 'Epilepsy classification:Focal,Generalized',\n",
    "    'FocusLat': 'Lateralization of epileptogenic focus',\n",
    "    'FocusConfirmed': 'Epileptogenic focus confirmed by the information of (sEEG/ site of surgical resection/ Ictal EEG abnormalities +/. MRI findings): FLE=forntal lobe epilepsy and cingulate epilepsy, CLE:central/midline epilepsy,ILE: insular epilepsy, mTLE=mesio.temporal lobe epilepsy, nTLE=neocortical lobe epilepsy, PQLE=posterior quadrant lobe epilepsy , multifocal epilepsy,IGE=ideopathic lobe epilepsy,unclear)',\n",
    "    'EMUDischargeDx': 'Dx at EMU discharge ',\n",
    "    'EMUAdmissionDate': 'EMU admission date(dd-mm-yy)',\n",
    "    'AdmissionDuration': 'Duration of admission',\n",
    "    'EpilepsyRiskFactors': 'Risk factors for epilepsy',\n",
    "    'SeizureOnsetYr': 'Seizure onset (yr)',\n",
    "    'DrugResistant': 'Drug resistant epilepsy at time of EMU admission',\n",
    "    'NumASMsPrior': '# of ASMs prior current EMU admission',\n",
    "    'PrevASMs': 'Previous ASMs (name and doses (mg/d)) if applicable prior the current EMU admission',\n",
    "    'NumASMOnAdmission': '# of ASM on admission',\n",
    "    'ASMsOnAdmission': 'ASMs  on admission (name, doses (mg per day)',\n",
    "    'GeneticTest': 'Genetic test (year,results)',\n",
    "    'FDGPET': 'FDG.PET',\n",
    "    'BaselineMRI': 'Baseline MRI (year,results)',\n",
    "    'InvasiveExplorations': 'Invasive explorations (Y/N)',\n",
    "    'NumSurgicalResections': '# of surgical resection/thermocoagulatin',\n",
    "    'SurgicalResectionDateSite': 'Surgical resection date and site',\n",
    "    'Histopathology': 'Histopatholgy',\n",
    "    'Engel6mo': 'Engel classification (seizure outcomes at the 6 month )',\n",
    "    'Engel1yr': 'Engel classification (seizure outcomes after 1 year from surgical resection)',\n",
    "    'ILAEOutcome1yr': 'ILAE outcome after surgical resection by 1 yr',\n",
    "    'NeuromodDevices': 'Neuromodulation devices'\n",
    "    }\n",
    "\n",
    "sheets = [PNI, MICs, Clin]\n",
    "\n",
    "# QC sheets\n",
    "PNI_QC= { # details of sheet with QC info on 7T surface segmentation\n",
    "    \"PATH\":f\"{src_dir}/7T_processing_26Sept2025.xlsx\",\n",
    "    \"SHEET\":\"Proc_newDays\",\n",
    "    \"ID_7T\": \"Subjec_ID\",\n",
    "    \"SES\": \"Session \",\n",
    "    \"QC_col\": \"Comments \" # NOTE values are free-form strings. Only present for some rows that should be checked myself. Other row's segmentations can be assumed good.\n",
    "}\n",
    "\n",
    "MICs_QC = { # details of sheet with QC info on 3T surface segmentation\n",
    "    \"PATH\":f\"{src_dir}/BIDS_MICs_QC_logs_26Sept2025.xlsx\", \n",
    "    \"SHEET\":\"Sheet1\",\n",
    "    \"ID_3T\": \"ID\",\n",
    "    \"SES\": \"ses\",\n",
    "    \"QC_col\": \"surface quality\" # NOTE 0 < values < 2 0=unacceptable, 2=acceptable\n",
    "}\n",
    "\n",
    "\n",
    "##### ANALYSIS SPECIFICATIONS #####\n",
    "\n",
    "# Demographics details\n",
    "demographics = {\n",
    "    \"pth\" : \"/host/verges/tank/data/daniel/3T7T/z/outputs/01c_grpSummary_16Sep2025.csv\", # path to demographics file produced by 02_demo.ipynb\n",
    "    # column names:\n",
    "    'nStudies': True, # whether multiple studies are included\n",
    "    \"ID_7T\" : \"PNI_ID\", \n",
    "    \"ID_3T\" : \"MICS_ID\",\n",
    "    \"SES\" : \"SES\",\n",
    "    \"date\": \"Date\",\n",
    "    \"age\": \"age\",\n",
    "    \"sex\": \"sex\",\n",
    "    \"grp\" : \"grp_detailed\" # col name for participant grouping variable to use\n",
    "}\n",
    "\n",
    "# Study details\n",
    "MICs = {\n",
    "    \"name\": \"MICs\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_MICs\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"3T\",\n",
    "    \"ID_ctrl\" : [\"HC\"], # patterns for control IDs in demographics file\n",
    "    \"ID_Pt\" : [\"PX\"] # patterns for patient IDs in demographics file\n",
    "    }\n",
    "\n",
    "PNI = {\n",
    "    \"name\": \"PNI\",\n",
    "    \"dir_root\": \"/data/mica3/BIDS_PNI\",\n",
    "    \"dir_raw\": \"/rawdata\",\n",
    "    \"dir_deriv\": \"/derivatives\",\n",
    "    \"dir_mp\": \"/micapipe_v0.2.0\",\n",
    "    \"dir_hu\": \"/hippunfold_v1.3.0/hippunfold\",\n",
    "    \"dir_zb\": \"/DM_zb_37comp\",\n",
    "    \"study\": \"7T\",\n",
    "    \"ID_col\" : [\"PNC\", \"Pilot\"], # column for ID in demographics file\n",
    "    }\n",
    "\n",
    "studies = [MICs, PNI]\n",
    "\n",
    "ctrl_grp = {'ctrl' : ['CTRL']}\n",
    "\n",
    "# Analysis details\n",
    "specs  = { # all spec values to be in lists to allow for iteration across these values\n",
    "    # directories\n",
    "    'prjDir_root' : \"/host/verges/tank/data/daniel/3T7T/z\", \n",
    "    'prjDir_outs' : \"/outputs\",\n",
    "    'prjDir_out_stats': \"/outputs/stats\",\n",
    "    'prjDir_out_figs': \"/outputs/figures\",\n",
    "    'prjDir_maps' : \"/maps\", # output directory for smoothed cortical maps\n",
    "    'prjDir_dictLists': \"/maps/dictLists\",\n",
    "    'prjDir_mapPths' : \"/output/paths\",\n",
    "    'prjDir_maps_dfs': \"/outputs/dfs/04a_maps_dfs\",\n",
    "    'prjDir_parc_dfs': \"/outputs/dfs/04b_maps_parc\",\n",
    "    'prjDir_winComp_dfs': \"/outputs/dfs/05a_winComp\",\n",
    "    'prjDir_grpFlip_dfs': \"/outputs/dfs/05b_grpFlip\",\n",
    "    'prjDir_winD_dfs': \"/outputs/dfs/05c_winD\",\n",
    "    'prjDir_btwD_dfs': \"/outputs/dfs/05d_btwComp\",\n",
    "\n",
    "    'ctx': True, # whether to include cortical analyses\n",
    "    'surf_ctx': ['fsLR-5k'],\n",
    "    'parcellate_ctx': 'glasser', # parcellation to use, or None if no parcellation.\n",
    "    'parc_lbl_ctx': 'glasser_int', # what name to fetch for parcellation values\n",
    "    'lbl_ctx': ['midthickness', 'pial', 'white', 'swm1.0mm'], # pial, midthick, white, etc\n",
    "    'ft_ctx': ['thickness', 'T1map', 'flair', 'ADC', 'FA'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_ctx': [5, 10], # in mm\n",
    "    \n",
    "    'hipp': True, # whether to include hippocampal analyses\n",
    "    'surf_hipp': ['den-0p5mm'],\n",
    "    'parcellate_hipp': 'DK25',\n",
    "    'parc_lbl_hipp': 'idx',\n",
    "    'lbl_hipp': ['midthickness', \"inner\", \"outer\"], # outer, inner, midthickness, etc\n",
    "    'ft_hipp': ['thickness', 'T1map', 'flair', 'ADC', 'FA'], # features: T1map, flair, thickness, FA, ADC\n",
    "    'smth_hipp': [2, 5], # in mm\n",
    "    \n",
    "    # within study comparisons\n",
    "    'col_grp': 'grp_detailed',  # column in df_demo with group labels\n",
    "    'winComp_stats': ['z'], # what stats to run for within study comparisons ('z' for z-scoring, 'w' for w-scoring)\n",
    "    'covars': [demographics['age'], demographics['sex']],\n",
    "\n",
    "    'ipsiTo' : 'L', # what hemisphere for controls ipsi should be mapped to\n",
    "    'newQC': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Make proper Table 1\n",
    "importlib.reload(utils_demo)\n",
    "\n",
    "df_demo = pd.read_csv(demographics['pth'])\n",
    "utils_demo.grp_summary(df_demo, col_grp='grp_detailed', save_pth=save_pth)\n",
    "print(\"-\"*100)\n",
    "print(\"MEDIAN AGE by group\")\n",
    "df_demo.groupby(['grp_detailed', 'study'])['age'].median().sort_index(level='grp_detailed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9417a3",
   "metadata": {},
   "source": [
    "# ANALYSIS SPECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd443ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure demo file loaded\n",
    "if 'df_demo' not in globals() or df_demo is None:\n",
    "    df_demo = pd.read_csv(\"/host/verges/tank/data/daniel/3T7T/z/outputs/01b_demo_16Sep2025-154209.csv\")\n",
    "    print(f\"[main] Demo file loaded from {demographics['pth']}\")\n",
    "    \n",
    "print(df_demo[['UID','MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'grp_detailed']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026a6a0",
   "metadata": {},
   "source": [
    "# 2. SMOOTH MAPS - DEPRECATED. SEE 02_demo.ipynb\n",
    "Strategy:\n",
    "Add paths to relevant maps to df containing demographic information. Each row is one participant at a unique session.\n",
    "\n",
    "Hippocampal maps: identify path to smoothed hippocampal maps, add to row-wise df\n",
    "Cortical maps: take raw maps from micapipe, apply smoothing then save these maps in project directory and add path of the smoothed map to the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED. SEE 02_demo.ipynb\n",
    "importlib.reload(tsutil)\n",
    "df_pths, out_pth, log_pth = tsutil.idToMap(df_demo = df_demo, studies = studies, dict_demo = demographics, specs = specs, \n",
    "                              save = save, save_pth=f\"{specs['prjDir_root']}{specs['prjDir_outs']}\", save_name = \"02a_mapPths\", \n",
    "                              test=test, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cd8265",
   "metadata": {},
   "source": [
    "# 3. CLEAN DATA\n",
    "DEPRECATED. See 02_demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED. See 02_demo.ipynb\n",
    "# ensure demo file loaded\n",
    "reimport = False\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/01a_mapPths_12Sep2025-171142.csv\"\n",
    "toPrint = True\n",
    "if 'df_pths' not in globals() or df_pths is None or reimport == True:\n",
    "    df_pths_clean_final = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "if test:\n",
    "    filename = \"/host/verges/tank/data/daniel/3T7T/z/maps/paths/\" + \"demo_pths_04Sep2025-135322.csv\"\n",
    "    df_pths = pd.read_csv(filename, dtype=str)\n",
    "    # take a random 10% subset of demo for testing\n",
    "    df_pths = df_pths.sample(frac=test_frac).reset_index(drop=True)\n",
    "    df_pths = df_pths.dropna(axis=1, how='all') # drop empty columns\n",
    "    print(f\"[TEST MODE] Running on random {test_frac *100}% subset of demographics ({df_pths.shape[0]} rows).\")\n",
    "\n",
    "print(f\"Unique participants: {df_pths['MICS_ID'].nunique()}\")\n",
    "print(df_demo[['UID','MICS_ID', 'PNI_ID', 'study', 'SES', 'Date', 'grp_detailed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5169f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO. Change method to ensure df not highly fragmented\n",
    "# Get a summary of errors in df_pths\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "ERR_sv_root = f\"{specs['prjDir_root']}{specs['prjDir_outs']}\"\n",
    "\n",
    "# Create error summary\n",
    "cols = tsutil.get_mapCols(df_pths.columns, split=False, verbose=True)\n",
    "error_summary, ERR_sv_pth = tsutil.countErrors(df_pths, cols, save=ERR_sv_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7415fd6",
   "metadata": {},
   "source": [
    "# QC STEPS\n",
    "1. Check RAW data for each volume related to feature of interest\n",
    "    - Use bash script 'qc_vols.sh' with csv of ID, SES to check and will automatically load raw volumes to check\n",
    "2. Check surface segmentations\n",
    "    - TODO. Create bash script that loads the T1w volumes and surfaces that are all in a common space [Hippunfold surfaces as well?]\n",
    "3. Merge QC columns (takes lowest value of raw data and segmentation QC). Use this column in selecting final session by feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33094db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED. See 02_demo.ipynb\n",
    "import utils_demo as ud\n",
    "importlib.reload(ud)\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = True\n",
    "specs['newQC'] = True\n",
    "#pth = dfPths_out_pth\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/02a_mapPths_06Oct2025-202345.csv\"\n",
    "\n",
    "save_name = \"03a_qc_table\"\n",
    "save_pth = specs['prjDir_root'] + specs['prjDir_outs']\n",
    "\n",
    "if specs['newQC']: # create new QC sheet\n",
    "    \n",
    "    if 'df_pths' not in globals() or df_pths is None or reimport_src: # load\n",
    "        df_pths = pd.read_csv(pth, dtype=str)\n",
    "        print(f\"[main] df_pths loaded from {pth}\")\n",
    "    \n",
    "    qc_sheet, pth = ud.mk_qcSheet(df = df_pths, fts = specs['ft_ctx'] + specs['ft_hipp'], \n",
    "                                  studies = studies, ctx_surf_qc = qc_sheets,\n",
    "                                  save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE SUMMARY QC COLUMN FOR EACH FEATURE\n",
    "# Take min value of either above column. If one col is a string, assume 1\n",
    "if 'qc_sheet' not in globals() or qc_sheet is None:\n",
    "    qc_sheet_completed_pth = \"02b_qc_table_06Oct2025-205727_surfQC.csv\"\n",
    "    qc_sheet = pd.read_csv(f\"{specs['prjDir_root']}{specs['prjDir_outs']}/{qc_sheet_completed_pth}\", dtype=str)\n",
    "\n",
    "def convert_qc(val):\n",
    "    if pd.isna(val) or val in ['', 'NA', 'NaN']:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(val)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "vol_names = tsutil.get_RawVolumeNames(specs['ft_ctx'] + specs['ft_hipp'])\n",
    "for vol in vol_names:\n",
    "    if vol in qc_sheet.columns:\n",
    "        qc_sheet[f\"QC_{vol}_surf\"] = qc_sheet.apply(\n",
    "            lambda row: min(\n",
    "                convert_qc(row[vol]) if not pd.isna(convert_qc(row[vol])) else 2,\n",
    "                convert_qc(row['surf_QC']) if not pd.isna(convert_qc(row['surf_QC'])) else 2\n",
    "            ) if (not pd.isna(convert_qc(row[vol])) or not pd.isna(convert_qc(row['surf_QC']))) else 'NA',\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[main] Volume {vol} not found in QC sheet columns.\")\n",
    "if save:\n",
    "    qc_sheet.to_csv(f\"{specs['prjDir_root']}{specs['prjDir_outs']}/02c_qc_table_merge_{datetime.datetime.now().strftime('%d%b%Y-%H%M%S')}.csv\", index=False, na_rep='NaN')\n",
    "    print(f\"QC sheet with combined QC values saved to {specs['prjDir_root']}{specs['prjDir_outs']}/02b_qc_table_25Sep2025-141754_surfQC_combined.csv\")\n",
    "\n",
    "\n",
    "# add QC values to df_pths\n",
    "df_pths_cp = df_pths.copy()\n",
    "# add vol_pths and vol_QC columns to df_pths\n",
    "match_on = ['UID', 'study', 'Date']\n",
    "vol_names = tsutil.get_RawVolumeNames(specs['ft_ctx'] + specs['ft_hipp'])\n",
    "\n",
    "# Rename QC columns by adding '_raw_QC' suffix to volume names\n",
    "qc_sheet = qc_sheet.rename(columns={vol: f'{vol}_raw_QC' for vol in vol_names if vol in qc_sheet.columns})\n",
    "\n",
    "# Merge QC and path columns\n",
    "df_pths_cp = df_pths_cp.merge(qc_sheet[[col for col in qc_sheet.columns if col.endswith(('_raw_QC', '_pth')) or col in match_on]], on=match_on, how='left')\n",
    "\n",
    "# Reorder columns\n",
    "qc_path_cols = [col for col in df_pths_cp.columns if col.endswith(('_raw_QC', '_pth', \"_surf\"))]\n",
    "other_cols = [col for col in df_pths_cp.columns if not col.endswith(('_raw_QC', '_pth', \"_surf\")) and not col.startswith(('ctx', 'hip'))]\n",
    "ctx_hip_cols = [col for col in df_pths_cp.columns if col.startswith(('ctx', 'hipp'))]\n",
    "\n",
    "df_pths_cp = df_pths_cp[other_cols + qc_path_cols + ctx_hip_cols]\n",
    "\n",
    "print(f\"{len(df_pths_cp.columns)} columns: {list(df_pths_cp.columns)}\")\n",
    "\n",
    "# save\n",
    "if save:\n",
    "    out_pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}/02c_mapPths_QC_{datetime.datetime.now().strftime('%d%b%Y-%H%M%S')}.csv\"\n",
    "    df_pths_cp.to_csv(out_pth, index=False)\n",
    "    print(f\"[main] df_pths with QC values for raw volumes saved to {out_pth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aac145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN SESSIONS\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# LOAD\n",
    "if 'df_paths' not in globals() or df_pths is None:\n",
    "    df_pths_name = \"02a_mapPths_06Oct2025-202345.csv\"\n",
    "    df_pths = pd.read_csv(f\"{specs['prjDir_root']}{specs['prjDir_outs']}/{df_pths_name}\", dtype=str)\n",
    "    print(f\"[main] df_pths loaded from {specs['prjDir_root']}{specs['prjDir_outs']}/{df_pths_name}\")\n",
    "                                    \n",
    "# i. Ensure both hemisphere maps present, each subject has data for both studies\n",
    "clean_sv_pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}\"\n",
    "df_pths_clean, df_pths_rmv = tsutil.clean_demoPths(df_pths, nStudies=2, save=clean_sv_pth, verbose=False) # missing hemisphere pairs, missing study pairs\n",
    "\n",
    "# TODO. ii. Remove cases marked for exclusion in seperate file or feature-ID-SES combinations to remove (eg., due to imaging artifacts like motion)\n",
    "# consider merged QC value when optimizing selection of sessions\n",
    "\n",
    "# iii. Choose a single session per participant\n",
    "importlib.reload(tsutil)\n",
    "df_pths_clean_final, paths_clean_pth = tsutil.clean_ses(df_pths_clean, col_ID=\"UID\", save = clean_sv_pth, col_study='study', verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b2572",
   "metadata": {},
   "source": [
    "# 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4338a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load maps, save into new list of dictionary items.\n",
    "# Drop cases with missing values in the current map col\n",
    "\n",
    "import pickle\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "save = True\n",
    "save_pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}\"\n",
    "save_name = \"04a_dl_maps\"\n",
    "test = False\n",
    "verbose = True\n",
    "toPrint = False\n",
    "  \n",
    "reimport = True\n",
    "pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}/03d_ses_clean_06Oct2025-210313.csv\"\n",
    "\n",
    "if 'df_pths_clean_final' not in globals() or df_pths_clean_final is None or reimport == True:\n",
    "    df_pths_clean_final =pd.read_csv(pth, dtype=str)\n",
    "\n",
    "print(f\"shape: {df_pths_clean_final.shape}\")\n",
    "print(f\"columns: {list(df_pths_clean_final.columns)}\")\n",
    "\n",
    "print(f\"Reading in maps, creating dictionary list (each combo of: study-feature-label-surface-smoothing).\\n\\tNote. Not seperating groups yet.\")\n",
    "\n",
    "# find all map cols\n",
    "cols_L, cols_R = tsutil.get_mapCols(df_pths_clean_final.columns, verbose=True)\n",
    "\n",
    "# extract maps as appropriate\n",
    "ctx_dl = []\n",
    "hipp_dl = []\n",
    "\n",
    "if specs['ctx']:\n",
    "    ctx_dl = tsutil.extractMap(df_mapPaths = df_pths_clean_final, cols_L = cols_L, cols_R = cols_R, \n",
    "                               studies = studies, demographics = demographics, \n",
    "                               save_name = save_name, save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                               region = \"cortex\", verbose=True, test = test)\n",
    "    \n",
    "if specs['hipp']:\n",
    "    hipp_dl = tsutil.extractMap(df_mapPaths = df_pths_clean_final, cols_L = cols_L, cols_R = cols_R, \n",
    "                                studies = studies, demographics = demographics, \n",
    "                                save_name = save_name, save_df_pth = specs['prjDir_root'] + specs['prjDir_maps_dfs'], log_save_pth = specs['prjDir_root'] + specs['prjDir_outs'],\n",
    "                                region = \"hippocampus\", verbose=True, test = test)\n",
    "\n",
    "# Create single dl \n",
    "dl = ctx_dl + hipp_dl\n",
    "\n",
    "len_unsmth = len([d for d in ctx_dl + hipp_dl if d['smth'] == 'NA'])\n",
    "len_smth = len([d for d in ctx_dl + hipp_dl if d['smth'] != 'NA'])\n",
    "print(f\"\\n[main] {len(dl)} dictionary items for this study-feature-label-surface pairs\\n\\t{len_unsmth} with smoothing == NA | {len_unsmth} with smoothing\")\n",
    "\n",
    "if save:\n",
    "    out_pth = tsutil.savePickle(obj = dl, root = save_pth, name = save_name, test = test)\n",
    "\n",
    "if toPrint:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl)\n",
    "\n",
    "# NOTE. columns with no rows are not kept in dictionary list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48281f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcellate maps\n",
    "importlib.reload(tsutil)\n",
    "reimport_src = False\n",
    "save_name = \"04b_dl_maps_parcel\"\n",
    "save_pth = f\"{specs['prjDir_root']}{specs['prjDir_outs']}\"\n",
    "test = False\n",
    "verbose = False\n",
    "\n",
    "if 'dl' not in globals() or dl is None or reimport_src:\n",
    "    src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04a_dl_maps_08Oct2025-104443.pkl\"\n",
    "    dl = tsutil.loadPickle(src_pth)\n",
    "\n",
    "#tsutil.print_dict(dl)\n",
    "\n",
    "if specs['parcellate_ctx'] is not None or specs['parcellate_hipp'] is not None: # for each item, create a df_parc   \n",
    "    region_parc = [{'region': 'cortex', \n",
    "                    'parcellate': specs.get('parcellate_ctx', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_ctx', None)}, \n",
    "                   {'region': 'hippocampus',\n",
    "                    'parcellate': specs.get('parcellate_hipp', False),\n",
    "                    'parc_lbl': specs.get('parc_lbl_hipp', None)}]\n",
    "    \n",
    "    # TODO. Also parcellate without summarizing accross parcels\n",
    "    dl_parcel, region_parc = tsutil.parcellate_items(dl, df_keys=['df_maps'], parcellationSpecs = region_parc, df_save_pth = specs['prjDir_root'] + specs['prjDir_parc_dfs'],\n",
    "                                                     stats = [None, 'mdn', 'mean'],\n",
    "                                                    save_pth=save_pth, save_name=save_name,\n",
    "                                                    verbose=verbose, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a29921",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "tsutil.print_dict(dl_parcel, df_print=False)\n",
    "#item_test = dl_parcel[0]['df_maps_parc_glsr_mdn']\n",
    "#item_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS about vertices within parcels\n",
    "# TODO. Appears broken\n",
    "import importlib\n",
    "import utils_parc as up\n",
    "importlib.reload(up)\n",
    "\n",
    "reimport_src = False\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-112622.pkl\"\n",
    "    dl_parcel = tsutil.loadPickle(pth)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04c_parcel_distr\"\n",
    "koi = \"df_maps_parc_dk25\"\n",
    "up.parcel_stats(dl = dl_parcel, key = koi, sv_root = save_pth, test = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43580c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP MATRICES\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# create pngs\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_allPt/raw\"\n",
    "tsutil.plotMatrices(dl = dl_parcel, df_keys = ['df_maps_parc_glsr_mdn', 'df_maps_parc_dk25_mdn'], save_pth=fig_dir, test=False) # visualize smoothed maps\n",
    "\n",
    "print(\"Should visually inspect maps, identifying feature-ID-SES combinations that are outliers. Mark for removal [editing <path/to/file name.xlsx> and rerun from step 3.\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "tsutil.plotLine(dl_parcel, df_keys = ['df_maps_parc_glsr_mdn', 'df_maps_parc_dk25_mdn'],\n",
    "            name_append=\"line\", \n",
    "            parc=['glasser', 'DK25'], stat = ['mdn', 'mdn'],\n",
    "            hline_idx = [[60,120,240,300], None],\n",
    "            save_pth=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/04c_maps_allPt/raw\",\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=False)\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/maps_allPt\") # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492b64e",
   "metadata": {},
   "source": [
    "# Within study, vertex/parcel-wise statistics (z-, w- scores)\n",
    "- compares _all_ participants to controls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d881d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs['prjDir_root'] + specs['prjDir_winComp_dfs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute z, w scores within studies (all participants vs control distribution)\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# import smoothed maps\n",
    "reimport_src = False\n",
    "test = False\n",
    "save_name = \"05a_winStudy\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/04c_dl_maps_parcel_07Oct2025-181931.pkl\"\n",
    "    dl = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] Dict list with parcellated map values loaded from {pth}\")\n",
    "\n",
    "#tsutil.print_dict(dl_parcel, df_print=False)\n",
    "\n",
    "# calculate statistics\n",
    "dl_winComp = tsutil.winComp(dl = dl_parcel, demographics = demographics, keys_maps = ['df_maps', 'df_maps_parc_glsr_mdn', 'df_maps_parc_glsr_mean', 'df_maps_parc_dk25_mdn', 'df_maps_parc_dk25_mean'], col_grp = specs['col_grp'], ctrl_grp = ctrl_grp, \n",
    "                            out_df_save_pth = specs['prjDir_root'] + specs['prjDir_winComp_dfs'],\n",
    "                            stat=specs['winComp_stats'], covars = specs['covars'], key_demo = 'df_demo',\n",
    "                            save = True, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                            verbose = True, dlPrint = False, test=test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb924452",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsutil.print_dict(dl_winComp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z, w score maps\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = True\n",
    "test = False\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp/raw\"\n",
    "\n",
    "if 'dl_parcel' not in globals() or dl_parcel is None or reimport_src:\n",
    "    pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_08Oct2025-110338.pkl\"\n",
    "    dl_winComp = tsutil.loadPickle(pth, verbose = False)\n",
    "    print(f\"[main] winComp dict list loaded from {pth}\")\n",
    "\n",
    "# TODO. Add smart plotting based on parameters listed in specs dictionary\n",
    "dfs_toPlot = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z']\n",
    "\n",
    "tsutil.plotMatrices(dl = dl_winComp, df_keys = dfs_toPlot, name_append=True, save_pth=fig_dir, test=test) # visualize winCompStat maps\n",
    "tsutil.plotLine(dl_winComp, df_keys = dfs_toPlot, \n",
    "            parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "            hlines = [[60,120,240,300], None],\n",
    "            save_pth=fig_dir,\n",
    "            marks = False, alpha = 0.6,\n",
    "            test=test)\n",
    "\n",
    "# TODO. Allow integration of pdf for large images\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05a_winComp\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef774a1",
   "metadata": {},
   "source": [
    "# Select group of interest and ipsi/contra flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dictionary list based on previous dl.\n",
    "# New dl will have the same number of dictionary items (one for each study, ft, label, surf, smth, region combination).\n",
    "#   Keys of each dictionary items may change. One df for each combination of [group[len(goi)] x lateralization[_R, _L, _ic] + 1 (ctrl)] x stat[<_z>, <_w>]] \n",
    "#   If df_{stat} is none, nothing regarding this statistic will be added to dict item.\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "# import\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05a_winStudy_08Oct2025-110338.pkl\"\n",
    "\n",
    "if 'dl_winComp' not in globals() or dl_winComp is None or reimport_src:\n",
    "    dl_winComp = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "importlib.reload(tsutil)\n",
    "goi = [\"TLE\"] # group(s) of interest. Store main diagnosis abrev in list to allow for multiple groups\n",
    "koi = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z', 'df_maps_parc_glsr_mean_z', 'df_maps_parc_dk25_mean_z'] # keys of dl_winComp to use\n",
    "test = False\n",
    "save_name = \"05b_stats_winStudy_grp\"\n",
    "verbose = True\n",
    "\n",
    "dl_grp_ic = tsutil.grp_flip(dl = dl_winComp, demographics = demographics, \n",
    "                            goi = goi, df_keys = koi,\n",
    "                    col_grp = specs['col_grp'], save_pth_df = specs['prjDir_root'] + specs['prjDir_grpFlip_dfs'],\n",
    "                    save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name, test=test, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport_src = False\n",
    "src_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_08Oct2025-110654.pkl\"\n",
    "printDl = True\n",
    "\n",
    "test = False\n",
    "dfs_toPlot = ['df_maps_parc_glsr_mdn_z_TLE_ic', 'df_maps_parc_dk25_mdn_z_TLE_ic']\n",
    "foi = [\"thickness\", \"T1map\", 'flair'] # features of interest\n",
    "loi = ['midthickness', 'white', 'inner', 'outer'] # surfaces of interest\n",
    "fig_dir = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStudy_grp/raw\"\n",
    "\n",
    "\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport_src:\n",
    "    dl_grp_ic = tsutil.loadPickle(src_pth, verbose = True)\n",
    "\n",
    "dl_interest = [d for d in dl_grp_ic if d['feature'] in foi and d['label'] in loi]\n",
    "\n",
    "if printDl:\n",
    "    print(\"=\"*100)\n",
    "    tsutil.print_dict(dl_interest, df_print=False)\n",
    "\n",
    "tsutil.plotMatrices(dl = dl_interest, df_keys = dfs_toPlot, \n",
    "                    name_append=True, save_pth=fig_dir, test=test) # visualize z score maps\n",
    "\n",
    "#tsutil.pngs2pdf(fig_dir, output=\"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05b_winStat_ic\", verbose = True) # group pngs of same comparisons with different smoothing to single pdf\n",
    "tsutil.plotLine(dl_interest, df_keys = dfs_toPlot,\n",
    "                name_append=\"line\",\n",
    "                parc= ['glasser', 'DK25'], stat = ['z', 'z'],\n",
    "                hlines = [[60,120,240,300], None],\n",
    "                save_pth=fig_dir, spacing = None,\n",
    "                marks=False, alpha = 0.6,\n",
    "                test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb52c",
   "metadata": {},
   "source": [
    "# Within study Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = True\n",
    "test = False\n",
    "toPrint = False\n",
    "save = True\n",
    "save_name = \"05c_stats_winD\"\n",
    "\n",
    "koi = ['df_maps_parc_glsr_mdn_z', 'df_maps_parc_dk25_mdn_z']\n",
    "goi = ['TLE_ic']\n",
    "\n",
    "# import\n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05b_stats_winStudy_grp_08Oct2025-110654.pkl\"\n",
    "if 'dl_grp_ic' not in globals() or dl_grp_ic is None or reimport == True:\n",
    "    dl_grp_ic = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "winD = tsutil.winD(dl = dl_grp_ic, df_keys = koi, save_pth_df = specs['prjDir_root'] + specs['prjDir_winD_dfs'],\n",
    "                   ipsiTo = specs.get('ipsiTo', 'L'), \n",
    "                   save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                   verbose = verbose, test = test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed35df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = winD[5]\n",
    "print(list(df_test.keys()))\n",
    "df_test.get('ipsiTo', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63817138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize matrices\n",
    "importlib.reload(tsutil)\n",
    "save_pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD/raw\"\n",
    "tsutil.plotMatrices(dl = winD[83], key = 'df_d', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.plotMatrices(dl = winD[83], key = 'df_d_ic', save_pth=save_pth) # Visualize unsmoothed maps\n",
    "tsutil.pngs2pdf(fig_dir = save_pth, output = \"/host/verges/tank/data/daniel/3T7T/z/outputs/figs/05c_winD\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54847ea6",
   "metadata": {},
   "source": [
    "# Between study: D-score differences\n",
    "- Identify pairs of dictionary items\n",
    "- Extract d scoring statitics and compute:\n",
    "- raw d dif\n",
    "- d dif / ctrl d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tsutil)\n",
    "\n",
    "reimport = False\n",
    "test = False\n",
    "toPrint = False\n",
    "verbose = True\n",
    "save_name = \"05d_btwD\"\n",
    "\n",
    "# import \n",
    "pth = \"/host/verges/tank/data/daniel/3T7T/z/outputs/05c_stats_winD_08Oct2025-140529.pkl\"\n",
    "if 'winD' not in globals() or winD is None or reimport == True:\n",
    "    winD = tsutil.loadPickle(pth, dlPrint=toPrint)\n",
    "\n",
    "comps = tsutil.btwD(dl = winD, save_pth_df = specs['prjDir_root'] + specs['prjDir_btwD_dfs'],\n",
    "                    save = save, save_pth = specs['prjDir_root'] + specs['prjDir_outs'], save_name = save_name,\n",
    "                    verbose = verbose, test = test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tTsT_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
